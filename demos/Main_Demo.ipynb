{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln4S4Ts3XL_u"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/TransformerLensOrg/TransformerLens/blob/main/demos/Main_Demo.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U01RrYowXL_7"
      },
      "source": [
        "# Transformer Lens Main Demo Notebook\n",
        "\n",
        "<b style=\"color: red\">To use this notebook, go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.</b>\n",
        "\n",
        "This is a reference notebook covering the main features of the [TransformerLens](https://github.com/TransformerLensOrg/TransformerLens) library for mechanistic interpretability. See [Callum McDougall's tutorial](https://transformerlens-intro.streamlit.app/TransformerLens_&_induction_circuits) for a more structured and gentler introduction to the library"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xhF46UoHnrjP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjTFqKh6XL_9"
      },
      "source": [
        "**Tips for reading this Colab:**\n",
        "* You can run all this code for yourself!\n",
        "* The graphs are interactive!\n",
        "* Use the table of contents pane in the sidebar to navigate\n",
        "* Collapse irrelevant sections with the dropdown arrows\n",
        "* Search the page using the search in the sidebar, not CTRL+F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTvfmW-6XMAC"
      },
      "source": [
        "# Setup\n",
        "(No need to read)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6L0yPzZXMAD",
        "outputId": "2c76e0b8-c391-4bfb-f9ae-631bbd459d2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Collecting transformer_lens\n",
            "  Downloading transformer_lens-2.15.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (1.5.2)\n",
            "Collecting beartype<0.15.0,>=0.14.1 (from transformer_lens)\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting better-abc<0.0.4,>=0.0.3 (from transformer_lens)\n",
            "  Downloading better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting datasets>=2.7.1 (from transformer_lens)\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.8.1)\n",
            "Collecting fancy-einsum>=0.0.3 (from transformer_lens)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting jaxtyping>=0.2.11 (from transformer_lens)\n",
            "  Downloading jaxtyping-0.3.1-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (2.2.2)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (13.9.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.2.0)\n",
            "Requirement already satisfied: torch>=2.2 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.67.1)\n",
            "Requirement already satisfied: transformers>=4.43 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.50.3)\n",
            "Collecting transformers-stream-generator<0.0.6,>=0.0.5 (from transformer_lens)\n",
            "  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typeguard<5.0,>=4.2 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.13.1)\n",
            "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.19.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.30.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.7.1->transformer_lens)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (3.11.15)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping>=0.2.11->transformer_lens)\n",
            "  Downloading wadler_lindig-0.1.4-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.6.0->transformer_lens) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.2->transformer_lens)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.2->transformer_lens)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.2->transformer_lens)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.2->transformer_lens)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.2->transformer_lens)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.2->transformer_lens)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.2->transformer_lens)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.2->transformer_lens)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.2->transformer_lens)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.2->transformer_lens)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.2->transformer_lens) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43->transformer_lens) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43->transformer_lens) (0.21.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (5.29.4)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (2.11.2)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (2.25.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (75.2.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.12)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.2->transformer_lens) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.2)\n",
            "Downloading transformer_lens-2.15.0-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.2/189.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Downloading jaxtyping-0.3.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/27/94/3266821f65b92b3138631e9c8e7fe1fb513804ac934485a8d05776e1dd43/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl\u001b[0m\u001b[33m\n",
            "\u001b[0mDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.4-py3-none-any.whl (20 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers-stream-generator\n",
            "  Building wheel for transformers-stream-generator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers-stream-generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12426 sha256=d41a11908616219d6020b66c13b6f0fac5180c016bd5676f9c273e178986ebb9\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/e8/f0/b3c58c12d1ffe60bcc8c7d121115f26b2c1878653edfca48db\n",
            "Successfully built transformers-stream-generator\n",
            "Installing collected packages: better-abc, xxhash, wadler-lindig, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, fancy-einsum, dill, beartype, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jaxtyping, nvidia-cusolver-cu12, datasets, transformers-stream-generator, transformer_lens\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed beartype-0.14.1 better-abc-0.0.3 datasets-3.5.0 dill-0.3.8 fancy-einsum-0.0.3 fsspec-2024.12.0 jaxtyping-0.3.1 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 transformer_lens-2.15.0 transformers-stream-generator-0.0.5 wadler-lindig-0.1.4 xxhash-3.5.0\n",
            "Collecting circuitsvis\n",
            "  Downloading circuitsvis-1.43.3-py3-none-any.whl.metadata (983 bytes)\n",
            "Requirement already satisfied: importlib-metadata>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from circuitsvis) (8.6.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from circuitsvis) (2.0.2)\n",
            "Requirement already satisfied: torch>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from circuitsvis) (2.6.0+cu124)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=5.1.0->circuitsvis) (3.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.1->circuitsvis) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.1->circuitsvis) (3.0.2)\n",
            "Downloading circuitsvis-1.43.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: circuitsvis\n",
            "Successfully installed circuitsvis-1.43.3\n",
            "\n",
            "\u001b[31m================================================================================\u001b[m\n",
            "\u001b[31m================================================================================\u001b[m\n",
            "\n",
            "  \u001b[1m\u001b[33m                            DEPRECATION WARNING                            \u001b[m\n",
            "\n",
            "    \u001b[1m\u001b[4m Node.js 16.x is no longer actively supported!\u001b[m\n",
            "\n",
            "  \u001b[1mYou will not receive security or critical stability updates\u001b[m for this version.\n",
            "\n",
            "  You should migrate to a supported version of Node.js as soon as possible.\n",
            "  Use the installation script that corresponds to the version of Node.js you\n",
            "  wish to install. e.g.\n",
            "  \n",
            "   * \u001b[31mhttps://deb.nodesource.com/setup_16.x — Node.js 16 \"Gallium\" \u001b[1m(deprecated)\u001b[m\n",
            "   * \u001b[32mhttps://deb.nodesource.com/setup_18.x — Node.js 18 \"Hydrogen\" (Maintenance)\u001b[m\n",
            "   * \u001b[31mhttps://deb.nodesource.com/setup_19.x — Node.js 19 \"Nineteen\" \u001b[1m(deprecated)\u001b[m\n",
            "   * \u001b[1m\u001b[32mhttps://deb.nodesource.com/setup_20.x — Node.js 20 LTS \"Iron\" (recommended)\u001b[m\n",
            "   * \u001b[32mhttps://deb.nodesource.com/setup_21.x — Node.js 21 \"Iron\" (current)\u001b[m\n",
            "   \n",
            "\n",
            "\n",
            "  Please see \u001b[1mhttps://github.com/nodejs/Release\u001b[m for details about which\n",
            "  version may be appropriate for you.\n",
            "\n",
            "  The \u001b[32m\u001b[1mNodeSource\u001b[m Node.js distributions repository contains\n",
            "  information both about supported versions of Node.js and supported Linux\n",
            "  distributions. To learn more about usage, see the repository:\n",
            "   \u001b[4m\u001b[1mhttps://github.com/nodesource/distributions\u001b[m\n",
            "\n",
            "\u001b[31m================================================================================\u001b[m\n",
            "\u001b[31m================================================================================\u001b[m\n",
            "\n",
            "Continuing in 10 seconds ...\n",
            "\n",
            "\u001b[38;5;79m2025-04-10 07:37:03 - Installing pre-requisites\u001b[0m\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,383 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,824 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,688 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,099 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,788 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,000 kB]\n",
            "Get:18 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [34.3 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,542 kB]\n",
            "Fetched 26.0 MB in 3s (7,933 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ca-certificates is already the newest version (20240203~22.04.1).\n",
            "curl is already the newest version (7.81.0-1ubuntu1.20).\n",
            "gnupg is already the newest version (2.2.27-3ubuntu2.3).\n",
            "gnupg set to manually installed.\n",
            "The following NEW packages will be installed:\n",
            "  apt-transport-https\n",
            "0 upgraded, 1 newly installed, 0 to remove and 47 not upgraded.\n",
            "Need to get 1,510 B of archives.\n",
            "After this operation, 170 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 apt-transport-https all 2.4.13 [1,510 B]\n",
            "Fetched 1,510 B in 0s (7,711 B/s)\n",
            "Selecting previously unselected package apt-transport-https.\n",
            "(Reading database ... 126213 files and directories currently installed.)\n",
            "Preparing to unpack .../apt-transport-https_2.4.13_all.deb ...\n",
            "Unpacking apt-transport-https (2.4.13) ...\n",
            "Setting up apt-transport-https (2.4.13) ...\n",
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:4 https://deb.nodesource.com/node_16.x nodistro InRelease [12.1 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://deb.nodesource.com/node_16.x nodistro/main amd64 Packages [7,253 B]\n",
            "Fetched 19.4 kB in 2s (11.2 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "\u001b[1;32m2025-04-10 07:37:19 - Repository configured successfully. To install Node.js, run: apt-get install nodejs -y\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  nodejs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 47 not upgraded.\n",
            "Need to get 27.5 MB of archives.\n",
            "After this operation, 128 MB of additional disk space will be used.\n",
            "Get:1 https://deb.nodesource.com/node_16.x nodistro/main amd64 nodejs amd64 16.20.2-1nodesource1 [27.5 MB]\n",
            "Fetched 27.5 MB in 1s (54.0 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package nodejs.\n",
            "(Reading database ... 126217 files and directories currently installed.)\n",
            "Preparing to unpack .../nodejs_16.20.2-1nodesource1_amd64.deb ...\n",
            "Unpacking nodejs (16.20.2-1nodesource1) ...\n",
            "Setting up nodejs (16.20.2-1nodesource1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "DEVELOPMENT_MODE = False\n",
        "# Detect if we're running in Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Install if in Colab\n",
        "if IN_COLAB:\n",
        "    %pip install transformer_lens\n",
        "    %pip install circuitsvis\n",
        "    # Install a faster Node version\n",
        "    !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs  # noqa\n",
        "\n",
        "# Hot reload in development mode & not running on the CD\n",
        "if not IN_COLAB:\n",
        "    from IPython import get_ipython\n",
        "    ip = get_ipython()\n",
        "    if not ip.extension_manager.loaded:\n",
        "        ip.extension_manager.load('autoreload')\n",
        "        %autoreload 2\n",
        "\n",
        "IN_GITHUB = os.getenv(\"GITHUB_ACTIONS\") == \"true\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNDwkcOwXMAH",
        "outputId": "1762b8cc-4264-4a6a-9c40-c7ae4d841f03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using renderer: colab\n"
          ]
        }
      ],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import plotly.io as pio\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "Vm1lZJTlXMAP",
        "outputId": "9b4fd79b-1bde-4e85-bba9-95604de3102c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x7b882e2c9390>"
            ],
            "text/html": [
              "<div id=\"circuits-vis-2b7c0098-ac36\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, Hello } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-2b7c0098-ac36\",\n",
              "      Hello,\n",
              "      {\"name\": \"Neel\"}\n",
              "    )\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import circuitsvis as cv\n",
        "# Testing that the library works\n",
        "cv.examples.hello(\"Neel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wFKADnPsXMAR"
      },
      "outputs": [],
      "source": [
        "# Import stuff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "import tqdm.auto as tqdm\n",
        "import plotly.express as px\n",
        "\n",
        "from jaxtyping import Float\n",
        "from functools import partial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "r2n29xN2XMAS"
      },
      "outputs": [],
      "source": [
        "# import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, FactoredMatrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7bZvR6MXMAW"
      },
      "source": [
        "We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlNNq4BIXMAX",
        "outputId": "2d7698ac-9337-4fe0-9101-214fe4a5bc6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7b87639dfb10>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "torch.set_grad_enabled(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jOfSkLaXMAY"
      },
      "source": [
        "Plotting helper functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4zVJxFeTXMAZ"
      },
      "outputs": [],
      "source": [
        "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.line(utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
        "    x = utils.to_numpy(x)\n",
        "    y = utils.to_numpy(y)\n",
        "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnVU-wnDXMAb"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBLfT3ZJXMAc"
      },
      "source": [
        "This is a demo notebook for [TransformerLens](https://github.com/TransformerLensOrg/TransformerLens), **a library I ([Neel Nanda](https://neelnanda.io)) wrote for doing [mechanistic interpretability](https://distill.pub/2020/circuits/zoom-in/) of GPT-2 Style language models.** The goal of mechanistic interpretability is to take a trained model and reverse engineer the algorithms the model learned during training from its weights. It is a fact about the world today that we have computer programs that can essentially speak English at a human level (GPT-3, PaLM, etc), yet we have no idea how they work nor how to write one ourselves. This offends me greatly, and I would like to solve this! Mechanistic interpretability is a very young and small field, and there are a *lot* of open problems - if you would like to help, please try working on one! **If you want to skill up, check out [my guide to getting started](https://neelnanda.io/getting-started), and if you want to jump into an open problem check out my sequence [200 Concrete Open Problems in Mechanistic Interpretability](https://neelnanda.io/concrete-open-problems).**\n",
        "\n",
        "I wrote this library because after I left the Anthropic interpretability team and started doing independent research, I got extremely frustrated by the state of open source tooling. There's a lot of excellent infrastructure like HuggingFace and DeepSpeed to *use* or *train* models, but very little to dig into their internals and reverse engineer how they work. **This library tries to solve that**, and to make it easy to get into the field even if you don't work at an industry org with real infrastructure! The core features were heavily inspired by [Anthropic's excellent Garcon tool](https://transformer-circuits.pub/2021/garcon/index.html). Credit to Nelson Elhage and Chris Olah for building Garcon and showing me the value of good infrastructure for accelerating exploratory research!\n",
        "\n",
        "The core design principle I've followed is to enable exploratory analysis - one of the most fun parts of mechanistic interpretability compared to normal ML is the extremely short feedback loops! The point of this library is to keep the gap between having an experiment idea and seeing the results as small as possible, to make it easy for **research to feel like play** and to enter a flow state. This notebook demonstrates how the library works and how to use it, but if you want to see how well it works for exploratory research, check out [my notebook analysing Indirect Objection Identification](https://neelnanda.io/exploratory-analysis-demo) or [my recording of myself doing research](https://www.youtube.com/watch?v=yo4QvDn-vsU)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEc0DWdVXMAc"
      },
      "source": [
        "## Loading and Running Models\n",
        "\n",
        "TransformerLens comes loaded with >40 open source GPT-style models. You can load any of them in with `HookedTransformer.from_pretrained(MODEL_NAME)`. For this demo notebook we'll look at GPT-2 Small, an 80M parameter model, see the Available Models section for info on the rest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ahZ2TzqtXMAc"
      },
      "outputs": [],
      "source": [
        "device = utils.get_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452,
          "referenced_widgets": [
            "43cd0b33ca9c466485f03bf50e9141f3",
            "80bd8efd5d3c40fe99ce06e8c23dbb0f",
            "293ffe3f2f5f424d9411df7d1009fcaa",
            "9ef6ee5be48c42bfa3cbfd3b796a70f7",
            "7475273ff53b4de58b9caf1b5edd9081",
            "b52aa3f56dad4dd5829c494253247e7d",
            "65957d50c9ac4792b694d34dc327cc0b",
            "34b8971066fc45b0b27889c4ff8d75ea",
            "571ada3caee24dfca05b13fa1eb120b2",
            "6aebc419e8364dfc904e4aae05c77bab",
            "008bf292c9a3414797f19c44a20f48a9",
            "3a0658f6d1704d858ba5092255361f46",
            "27af9271f6fd4b9db308f3a103a91d3d",
            "4ce58fddf2d84307868174bd4bc888ae",
            "740382a84674498e9a7745260c4cbe5c",
            "1139ba895d784871b74882e31ae3d3f9",
            "1fee90c5b1a44e3189f7dba265a3aba6",
            "c6272b4a70de49e0b6510e7ba6691f0b",
            "1dbafc3a471b4a54808cc8dbe440e266",
            "7cf41517920b4bd7810e09d1a246f637",
            "221dc13faec442f999f257e1c727cb7d",
            "760afdd9ecf4429c99e110e527f169b6",
            "9e595c76f97b42c197551272f919ddf8",
            "a1658ea3a7f44c1da4a3b97504946793",
            "07284d28626d490b9774cc744111245f",
            "dcfac4378bd24d59a8f7a7e8186eae26",
            "109ec2de5ca0425fac33c40f7de83e4b",
            "7b30f37728cb46e4a6b8bfb8e034dd45",
            "2cf8899304324911960210999a330fe7",
            "d955ae0965bd47f1b7027ca6d5fa0355",
            "6548edfe79d44f0e863e6b24ee08d285",
            "ff603d44b07348c18f89cc844ff91efa",
            "1a15fc4962834aa5aeb6ee6fc79bc0f0",
            "c067a4118242408786694746418375f6",
            "0913c57c32e64399b23461924961cf42",
            "2cfc395895fb40ab963004900e5a71e8",
            "21b1369bc4b34bb7bac6fe450fdec214",
            "ea617c52c3544041bb539ff962369985",
            "4c6c8c07e7a44677a1c420bc9a4972e2",
            "a4e8a322b6cd4482a3557050a2f6c108",
            "2b560e13f2c24d2e8d57afe1f12d2a04",
            "3f397e9aae274f36a6e9352569db4005",
            "e8656fc80d2f48fab3fdc1a4e47da333",
            "862dec4fdb16463b9384fc9f6ddf475b",
            "eccb3e044a2541cea77d4d20ad072d6b",
            "6ba02eee14ac471abf8b459af297c4c3",
            "37d752ab8b5042a48afd0eff4a147148",
            "70fbcbe2639841b7b234f7047bd7a702",
            "ee33dcf5dfb04c30992db0cee602c73b",
            "e3d8a83cee884c7a990fb0cc98149f62",
            "e571d20332bf41988cd6aa4a0eaec4bb",
            "6d7bc80752364b1fb9bede6f0238cdd5",
            "654ab34c049c4b69b2954065b42cf99e",
            "3c7473afbebd4a96a015e4b6664bb0c2",
            "3fc5f8f1af8343b5a5bc768b06a814e7",
            "c2fc0056de1b49dca7167669df172663",
            "9c3d3eb95aef4555b04ea4ab5566a9b1",
            "b3bd2bb5e809469bbf45b0a117358266",
            "06a49a3971cd40c885d09153ec784185",
            "1aa3882c02074c8f8ea0a39b6d7ce6a4",
            "38d902ed4ad2452891ea992edddfa9c0",
            "67440f1c148c4f75a584a3e65fbcc66a",
            "4a7a8d2d9d1343bfb1c4cde1891dbdc8",
            "1e2b4cb6183940ef8f2eae86b221d56a",
            "7a0c32fce0a44a50bc5b9ca5810e04fe",
            "5b940d21b0f940a49066dd2fe973c215",
            "25fe3524a5b040cea7e8d8d3f9597084",
            "a77d29ab4d9e4abeb25751cf0f0ec228",
            "abc2adb5616e4f449f29e10bcc036e8b",
            "788b88ff567d4c4aa6615f0ef45ae2d9",
            "7aeec7a31adc44c79dd6e0b6c11f93d0",
            "2e4a1e68e12f4e05ae61bda4d997b9b1",
            "9da9b719afb54bc98cdf2ccbb93e39e3",
            "7aec3bc18d284ca28f09186ffa0a0dce",
            "27f1df92a8a046849539cb34e3182db1",
            "517f1bb51eab4bf5b83b9bf1e7270b2b",
            "9ec056376427430eb53f6865b29c5270"
          ]
        },
        "id": "nk9Km2P9XMAd",
        "outputId": "18f558dc-0f75-4239-ae5e-fe9d0875393b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning:\n",
            "\n",
            "\n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43cd0b33ca9c466485f03bf50e9141f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a0658f6d1704d858ba5092255361f46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e595c76f97b42c197551272f919ddf8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c067a4118242408786694746418375f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eccb3e044a2541cea77d4d20ad072d6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2fc0056de1b49dca7167669df172663"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25fe3524a5b040cea7e8d8d3f9597084"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model gpt2-small into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "# NBVAL_IGNORE_OUTPUT\n",
        "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FFJthBoXMAe"
      },
      "source": [
        "To try the model out, let's find the loss on this text! Models can be run on a single string or a tensor of tokens (shape: [batch, position], all integers), and the possible return types are:\n",
        "* \"logits\" (shape [batch, position, d_vocab], floats),\n",
        "* \"loss\" (the cross-entropy loss when predicting the next token),\n",
        "* \"both\" (a tuple of (logits, loss))\n",
        "* None (run the model, but don't calculate the logits - this is faster when we only want to use intermediate activations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRGm4AsIXMAf",
        "outputId": "5b630db0-c1ae-4706-d04f-c89ff1260155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loss: tensor(4.1758)\n",
            "Model logits: torch.Size([1, 140, 50257])\n"
          ]
        }
      ],
      "source": [
        "model_description_text = \"\"\"## Loading Models\n",
        "\n",
        "HookedTransformer comes loaded with >40 open source GPT-style models. You can load any of them in with `HookedTransformer.from_pretrained(MODEL_NAME)`. See my explainer for documentation of all supported models, and this table for hyper-parameters and the name used to load them. Each model is loaded into the consistent HookedTransformer architecture, designed to be clean, consistent and interpretability-friendly.\n",
        "\n",
        "For this demo notebook we'll look at GPT-2 Small, an 80M parameter model. To try the model the model out, let's find the loss on this paragraph!\"\"\"\n",
        "loss = model(model_description_text, return_type=\"loss\")\n",
        "logits = model(model_description_text, return_type=\"logits\")\n",
        "print(\"Model loss:\", loss)\n",
        "print(\"Model logits:\", logits.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sdKRkIAXMAf"
      },
      "source": [
        "## Caching all Activations\n",
        "\n",
        "The first basic operation when doing mechanistic interpretability is to break open the black box of the model and look at all of the internal activations of a model. This can be done with `logits, cache = model.run_with_cache(tokens)`. Let's try this out on the first line of the abstract of the GPT-2 paper.\n",
        "\n",
        "<details><summary>On `remove_batch_dim`</summary>\n",
        "\n",
        "Every activation inside the model begins with a batch dimension. Here, because we only entered a single batch dimension, that dimension is always length 1 and kinda annoying, so passing in the `remove_batch_dim=True` keyword removes it. `gpt2_cache_no_batch_dim = gpt2_cache.remove_batch_dim()` would have achieved the same effect.\n",
        "</details?>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5z587B0hXMAg",
        "outputId": "3e1f7cb8-33ba-4f53-f32f-c4fd6853f75b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "torch.Size([1, 33, 50257])\n",
            "torch.Size([12, 33, 33])\n"
          ]
        }
      ],
      "source": [
        "gpt2_text = \"Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets.\"\n",
        "gpt2_tokens = model.to_tokens(gpt2_text)\n",
        "print(gpt2_tokens.device)\n",
        "gpt2_logits, gpt2_cache = model.run_with_cache(gpt2_tokens, remove_batch_dim=True)\n",
        "print(gpt2_logits.shape)\n",
        "print(gpt2_cache[\"pattern\", 0, \"attn\"].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYfSeie4XMAg"
      },
      "source": [
        "Let's visualize the attention pattern of all the heads in layer 0, using [Alan Cooney's CircuitsVis library](https://github.com/alan-cooney/CircuitsVis) (based on [Anthropic's PySvelte library](https://github.com/anthropics/PySvelte)).\n",
        "\n",
        "We look this the attention pattern in `gpt2_cache`, an `ActivationCache` object, by entering in the name of the activation, followed by the layer index (here, the activation is called \"attn\" and the layer index is 0). This has shape [head_index, destination_position, source_position], and we use the `model.to_str_tokens` method to convert the text to a list of tokens as strings, since there is an attention weight between each pair of tokens.\n",
        "\n",
        "This visualization is interactive! Try hovering over a token or head, and click to lock. The grid on the top left and for each head is the attention pattern as a destination position by source position grid. It's lower triangular because GPT-2 has **causal attention**, attention can only look backwards, so information can only move forwards in the network.\n",
        "\n",
        "See the ActivationCache section for more on what `gpt2_cache` can do."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUk4hqmpXMAg",
        "outputId": "6b19ffe5-d8dd-466f-e5e5-c718cf29bdc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformer_lens.ActivationCache.ActivationCache'>\n",
            "torch.Size([12, 33, 33])\n",
            "['<|endoftext|>', 'Natural', ' language', ' processing', ' tasks', ',', ' such', ' as', ' question', ' answering', ',', ' machine', ' translation', ',', ' reading', ' comprehension', ',', ' and', ' summar', 'ization', ',', ' are', ' typically', ' approached', ' with', ' supervised', ' learning', ' on', ' tasks', 'pe', 'cific', ' datasets', '.']\n"
          ]
        }
      ],
      "source": [
        "print(type(gpt2_cache))\n",
        "attention_pattern = gpt2_cache[\"pattern\", 0, \"attn\"]\n",
        "print(attention_pattern.shape)\n",
        "gpt2_str_tokens = model.to_str_tokens(gpt2_text)\n",
        "print(gpt2_str_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "-JMeiBFBXMAh",
        "outputId": "3aefea26-7a50-437e-9397-736f60ca99ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 0 Head Attention Patterns:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x7b86db9a1290>"
            ],
            "text/html": [
              "<div id=\"circuits-vis-f0743b87-f165\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-f0743b87-f165\",\n",
              "      AttentionPatterns,\n",
              "      {\"tokens\": [\"<|endoftext|>\", \"Natural\", \" language\", \" processing\", \" tasks\", \",\", \" such\", \" as\", \" question\", \" answering\", \",\", \" machine\", \" translation\", \",\", \" reading\", \" comprehension\", \",\", \" and\", \" summar\", \"ization\", \",\", \" are\", \" typically\", \" approached\", \" with\", \" supervised\", \" learning\", \" on\", \" tasks\", \"pe\", \"cific\", \" datasets\", \".\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639418721199036, 0.03605814278125763, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8389372825622559, 0.11828784644603729, 0.042774830013513565, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4743613004684448, 0.13382022082805634, 0.27371740341186523, 0.1181010901927948, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3560643494129181, 0.10184912383556366, 0.23054225742816925, 0.20397400856018066, 0.10757029801607132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6660143136978149, 0.1686638593673706, 0.04535672813653946, 0.03885500505566597, 0.06775479763746262, 0.0133552560582757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.38626962900161743, 0.2851092219352722, 0.07609009742736816, 0.05908381938934326, 0.07223352789878845, 0.039796341210603714, 0.08141744136810303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3775394856929779, 0.1883881837129593, 0.11723991483449936, 0.0868559405207634, 0.0666918084025383, 0.03500015661120415, 0.09693009406328201, 0.03135443851351738, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4869752824306488, 0.06781316548585892, 0.07952877879142761, 0.08480790257453918, 0.1590261608362198, 0.029577815905213356, 0.02568591758608818, 0.016474612057209015, 0.05011039599776268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29065507650375366, 0.0401349775493145, 0.14614856243133545, 0.09940596669912338, 0.1538919061422348, 0.03900161758065224, 0.024988971650600433, 0.03184131532907486, 0.10222820937633514, 0.07170344144105911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39624103903770447, 0.09694176912307739, 0.027270672842860222, 0.02355135791003704, 0.03723450377583504, 0.006502409465610981, 0.08118758350610733, 0.013088470324873924, 0.06990595906972885, 0.24043095111846924, 0.007645336911082268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24864788353443146, 0.1380205750465393, 0.0923532247543335, 0.0867612287402153, 0.1381969153881073, 0.05914194881916046, 0.03223859891295433, 0.03158240392804146, 0.030489441007375717, 0.038734838366508484, 0.06671839952468872, 0.037114497274160385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1914844512939453, 0.1617259532213211, 0.07445938140153885, 0.07740944623947144, 0.021961113438010216, 0.03392127901315689, 0.05125021934509277, 0.01951923966407776, 0.03132447972893715, 0.04020152986049652, 0.03874269127845764, 0.21578852832317352, 0.04221167042851448, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.37043169140815735, 0.08681419491767883, 0.02458467148244381, 0.021616321057081223, 0.03238872066140175, 0.005422735586762428, 0.07275225222110748, 0.011272803880274296, 0.06329693645238876, 0.217268168926239, 0.006367161870002747, 0.02960382215678692, 0.050998471677303314, 0.007182058412581682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19737647473812103, 0.046039972454309464, 0.0439998134970665, 0.13373452425003052, 0.054248202592134476, 0.02547571435570717, 0.027563493698835373, 0.02157093770802021, 0.05171824246644974, 0.06458097696304321, 0.028064634650945663, 0.23551598191261292, 0.019129790365695953, 0.029963519424200058, 0.021017687395215034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08907235413789749, 0.01928834617137909, 0.16653531789779663, 0.07281260192394257, 0.04738641902804375, 0.024487903341650963, 0.02898733876645565, 0.019370365887880325, 0.02667303942143917, 0.0731663927435875, 0.025704577565193176, 0.04242357611656189, 0.05869462341070175, 0.02893270179629326, 0.18119071424007416, 0.0952736958861351, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.281672865152359, 0.06441289186477661, 0.018008548766374588, 0.01616962067782879, 0.02318389154970646, 0.0037532944697886705, 0.05472246930003166, 0.00790976732969284, 0.046164702624082565, 0.1694725900888443, 0.004361644387245178, 0.021011359989643097, 0.03549070656299591, 0.004932567942887545, 0.09555221349000931, 0.1472633183002472, 0.005917447619140148, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2130548059940338, 0.0591236874461174, 0.03382088243961334, 0.027476875111460686, 0.028393540531396866, 0.008422899059951305, 0.040085308253765106, 0.011629271320998669, 0.05295189097523689, 0.1540464162826538, 0.00983181782066822, 0.036101944744586945, 0.04737287014722824, 0.011069186963140965, 0.09972471743822098, 0.13971354067325592, 0.013185334391891956, 0.013994951732456684, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15871694684028625, 0.04387889429926872, 0.08712150156497955, 0.08998466283082962, 0.030738575384020805, 0.034148938953876495, 0.0249172393232584, 0.03139195218682289, 0.0248238705098629, 0.01979033090174198, 0.03625483810901642, 0.020694417878985405, 0.04284067824482918, 0.038208987563848495, 0.06234658509492874, 0.10919704288244247, 0.0413760170340538, 0.04916759952902794, 0.05440091714262962, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10485511273145676, 0.12122288346290588, 0.06487482041120529, 0.08768720179796219, 0.03434052690863609, 0.017483947798609734, 0.034151818603277206, 0.015289152041077614, 0.023312130942940712, 0.02830648608505726, 0.0187204722315073, 0.028111929073929787, 0.04190531745553017, 0.0209895521402359, 0.046785082668066025, 0.08659634739160538, 0.02363184094429016, 0.024273181334137917, 0.16702403128147125, 0.010438220575451851, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22901973128318787, 0.05184381082653999, 0.013585193082690239, 0.012337246909737587, 0.01800544001162052, 0.0027703631203621626, 0.04238129034638405, 0.0058562601916491985, 0.036144886165857315, 0.13039223849773407, 0.0031534284353256226, 0.015672583132982254, 0.027800407260656357, 0.0035543241538107395, 0.07460814714431763, 0.11298281699419022, 0.00427227234467864, 0.006832204293459654, 0.18569739162921906, 0.018073637038469315, 0.005016355309635401, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18869920074939728, 0.03438711538910866, 0.022344758734107018, 0.019972747191786766, 0.016354041174054146, 0.006856544874608517, 0.020859047770500183, 0.005696007516235113, 0.034159161150455475, 0.07260986417531967, 0.00785721093416214, 0.0180402509868145, 0.026904471218585968, 0.009020394645631313, 0.06876447051763535, 0.1757873296737671, 0.01072007231414318, 0.009284541942179203, 0.1925639510154724, 0.025180324912071228, 0.01263907365500927, 0.021299351006746292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1195831149816513, 0.022259404882788658, 0.032947149127721786, 0.02017025649547577, 0.03565331548452377, 0.013459899462759495, 0.017516469582915306, 0.010057872161269188, 0.025856446474790573, 0.059559550136327744, 0.01508451346307993, 0.015008737333118916, 0.05317465960979462, 0.016597602516412735, 0.04155528545379639, 0.13129332661628723, 0.019296662881970406, 0.015855051577091217, 0.17925086617469788, 0.016183823347091675, 0.02229553461074829, 0.01546340249478817, 0.10187702625989914, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14615531265735626, 0.02672751434147358, 0.016624554991722107, 0.01898769475519657, 0.06278639286756516, 0.015317168086767197, 0.01979224570095539, 0.014227775856852531, 0.02545814774930477, 0.04530351981520653, 0.01636434532701969, 0.03749305382370949, 0.013288660906255245, 0.01749655045568943, 0.0399458110332489, 0.058817531913518906, 0.01926097832620144, 0.024616044014692307, 0.03821968287229538, 0.02157779224216938, 0.02094990201294422, 0.07973216474056244, 0.05017606168985367, 0.17068105936050415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11321669816970825, 0.03674635291099548, 0.01178658101707697, 0.010274861939251423, 0.020370660349726677, 0.005243885796517134, 0.015918835997581482, 0.005266787484288216, 0.024891739711165428, 0.06593260169029236, 0.005933654960244894, 0.018209027126431465, 0.021020209416747093, 0.006667498033493757, 0.034828800708055496, 0.13742125034332275, 0.007927052676677704, 0.008618668653070927, 0.11377192288637161, 0.013557428494095802, 0.009277831763029099, 0.026121370494365692, 0.08499343693256378, 0.19073913991451263, 0.011263744905591011, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13337713479995728, 0.02621660940349102, 0.038271527737379074, 0.0715256780385971, 0.053177691996097565, 0.013925840146839619, 0.007084188051521778, 0.013450142927467823, 0.009841453284025192, 0.011789786629378796, 0.013537588529288769, 0.03815499693155289, 0.04193305969238281, 0.013882278464734554, 0.03707147389650345, 0.13838453590869904, 0.014846325851976871, 0.03156952187418938, 0.05598176643252373, 0.015536676160991192, 0.01595636084675789, 0.045455560088157654, 0.016699673607945442, 0.025325771421194077, 0.0367189422249794, 0.08028544485569, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10608974099159241, 0.019107727333903313, 0.024468647316098213, 0.027496375143527985, 0.016365813091397285, 0.0050114234909415245, 0.010413103736937046, 0.006081144325435162, 0.005301064345985651, 0.011143162846565247, 0.004565386101603508, 0.018969912081956863, 0.004321118351072073, 0.00481497822329402, 0.02940940298140049, 0.028682013973593712, 0.005097254645079374, 0.007234351709485054, 0.03412593528628349, 0.010370595380663872, 0.005643266253173351, 0.007283586077392101, 0.029389571398496628, 0.01003879401832819, 0.009134513325989246, 0.546663224697113, 0.012777911499142647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10467307269573212, 0.03321940079331398, 0.015341237187385559, 0.009373540058732033, 0.026595454663038254, 0.005787800066173077, 0.013571344316005707, 0.00455488683655858, 0.028058892115950584, 0.02610723115503788, 0.006353443488478661, 0.013315824791789055, 0.02662823349237442, 0.006888873875141144, 0.062047477811574936, 0.05890703946352005, 0.008068048395216465, 0.007557098288089037, 0.08522788435220718, 0.01707574538886547, 0.009256887249648571, 0.019695738330483437, 0.12617804110050201, 0.13061514496803284, 0.011351024731993675, 0.0898437574505806, 0.04638151824474335, 0.007325290702283382, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08561894297599792, 0.02143894135951996, 0.05641259625554085, 0.05706658959388733, 0.01980220153927803, 0.006727494299411774, 0.005809155758470297, 0.00451626256108284, 0.0031647509895265102, 0.01761520467698574, 0.006174600217491388, 0.08767974376678467, 0.012299856171011925, 0.006350455805659294, 0.017522133886814117, 0.14295217394828796, 0.006585482973605394, 0.00787569023668766, 0.030078914016485214, 0.013907486572861671, 0.007376696448773146, 0.007684790994971991, 0.022160828113555908, 0.01238502562046051, 0.011890066787600517, 0.08669780194759369, 0.19902536273002625, 0.013594485819339752, 0.029586223885416985, 0.0, 0.0, 0.0, 0.0], [0.1406458467245102, 0.013298697769641876, 0.01570296101272106, 0.017357872799038887, 0.02233150787651539, 0.02967226319015026, 0.04172082990407944, 0.018995430320501328, 0.038277123123407364, 0.04863560199737549, 0.03094690851867199, 0.016023898497223854, 0.02088090032339096, 0.032438237220048904, 0.030558133497834206, 0.022808346897363663, 0.035377588123083115, 0.031451594084501266, 0.034971147775650024, 0.018679115921258926, 0.03821910172700882, 0.022578874602913857, 0.06819558888673782, 0.04214096814393997, 0.028620852157473564, 0.037750035524368286, 0.0185780618339777, 0.03376871347427368, 0.03641697019338608, 0.012956843711435795, 0.0, 0.0, 0.0], [0.07168618589639664, 0.06924440711736679, 0.01930689997971058, 0.014161988161504269, 0.01682320423424244, 0.0193806029856205, 0.019257429987192154, 0.02200368233025074, 0.013706534169614315, 0.0357837900519371, 0.01846517249941826, 0.05207168683409691, 0.02008516900241375, 0.019862132146954536, 0.020662108436226845, 0.047251589596271515, 0.021076735109090805, 0.036787249147892, 0.024324078112840652, 0.003827548585832119, 0.02392066828906536, 0.00853323470801115, 0.026241622865200043, 0.027380075305700302, 0.034612007439136505, 0.022884182631969452, 0.10047898441553116, 0.06913501769304276, 0.025474585592746735, 0.06495603919029236, 0.030615346506237984, 0.0, 0.0], [0.0691077932715416, 0.03701226785778999, 0.03862114995718002, 0.05933321639895439, 0.015923552215099335, 0.007918553426861763, 0.010371049866080284, 0.006615662947297096, 0.0025200797244906425, 0.0260193832218647, 0.007905225269496441, 0.029652034863829613, 0.04000624269247055, 0.00845133513212204, 0.010741152800619602, 0.050275616347789764, 0.009428860619664192, 0.013601029291749, 0.05036922171711922, 0.03176712244749069, 0.010793033987283707, 0.0072168041951954365, 0.006478430237621069, 0.0148005997762084, 0.021585972979664803, 0.15769490599632263, 0.08884759247303009, 0.019016938284039497, 0.029729334637522697, 0.03316134959459305, 0.050883643329143524, 0.0341508574783802, 0.0], [0.14375509321689606, 0.016811035573482513, 0.009386667050421238, 0.006830308586359024, 0.01165685337036848, 0.0015672279987484217, 0.019711481407284737, 0.0023980382829904556, 0.02123589813709259, 0.04683678224682808, 0.0016905140364542603, 0.005827190354466438, 0.011979990638792515, 0.0018251386936753988, 0.042313333600759506, 0.054913729429244995, 0.002178653609007597, 0.002417013281956315, 0.09604069590568542, 0.0057528759352862835, 0.002557790372520685, 0.007121228612959385, 0.08889926970005035, 0.10852088779211044, 0.005179052706807852, 0.03657734394073486, 0.024719927459955215, 0.003734763478860259, 0.03107706643640995, 0.016887929290533066, 0.094508595764637, 0.07171524316072464, 0.0033723211381584406]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0004246659518685192, 0.9995753169059753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005621908348985016, 0.01640728861093521, 0.9830306172370911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0011627586791291833, 0.0216820165514946, 0.003762046108022332, 0.9733933210372925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.724443740793504e-05, 0.0001720233412925154, 0.0002814398321788758, 0.0027421461418271065, 0.9967671632766724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00826844573020935, 0.00023985578445717692, 7.36189613235183e-05, 6.437728006858379e-05, 0.00017566324095241725, 0.9911779761314392, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0012215046444907784, 0.00540045415982604, 0.0016716319369152188, 0.00040775653906166553, 0.0006163661018945277, 0.0010931191500276327, 0.9895892143249512, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001245975960046053, 0.0009121220791712403, 0.0005976713728159666, 0.00013656872033607215, 0.0003304101701360196, 0.0015722772805020213, 0.003880807664245367, 0.9913241863250732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00028217461658641696, 0.004068182315677404, 0.0026605194434523582, 0.0013093105517327785, 0.008030476048588753, 0.0002879090898204595, 0.00022922919015400112, 0.0003948427038267255, 0.9827372431755066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.47393324773293e-05, 0.00039538476266898215, 0.00013272723299451172, 0.00025852309772744775, 0.0010855591390281916, 9.198043699143454e-05, 0.00032670784275978804, 0.0005427454598248005, 0.006105933338403702, 0.9910256266593933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0033785076811909676, 5.090876584290527e-05, 1.6452078853035346e-05, 1.6926183889154345e-05, 4.181411713943817e-05, 0.49394041299819946, 0.0001298127754125744, 0.0008837342611514032, 3.221200677216984e-05, 2.7252099243924022e-05, 0.5014819502830505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.416055788984522e-05, 0.0013417234877124429, 0.0012613608269020915, 0.0021450743079185486, 0.004042360465973616, 0.0004830540856346488, 0.0001158266604761593, 0.00015203609655145556, 2.6925305064651184e-05, 0.00012675137259066105, 0.00031289938488043845, 0.9899077415466309, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00037822307785972953, 0.000983756734058261, 0.03934124484658241, 0.0027322471141815186, 0.00366801954805851, 0.00011039181117666885, 0.00012931021046824753, 0.00021743500838056207, 0.00010623285197652876, 0.0007748190546408296, 6.647672853432596e-05, 0.0003148665127810091, 0.9511770009994507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00210172007791698, 2.4436882085865363e-05, 7.788777111272793e-06, 8.651618372823577e-06, 2.0140030756010674e-05, 0.29971376061439514, 7.525253022322431e-05, 0.0004898309707641602, 1.8459460989106447e-05, 1.534453986096196e-05, 0.32833874225616455, 4.175802678219043e-05, 6.469185791502241e-06, 0.3691376745700836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00014968313917052, 0.00011296597222099081, 0.0003629484854172915, 0.00018591186380945146, 0.00016460877668578178, 4.1432256693951786e-05, 2.8764718081220053e-05, 7.786935748299584e-05, 0.0009200984495691955, 0.010340185835957527, 2.7572339604375884e-05, 1.7833221136243083e-05, 0.0003305449790786952, 2.4375704015255906e-05, 0.9872152805328369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00010753796232165769, 0.002178182825446129, 0.002042605308815837, 0.004251915030181408, 0.006989872083067894, 2.5118699340964667e-05, 0.0007779006846249104, 0.0005783525411970913, 0.002937830751761794, 0.03322531282901764, 1.719921601761598e-05, 0.0008936444064602256, 0.0015238532796502113, 1.4656765415566042e-05, 0.006222618278115988, 0.9382133483886719, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0013634879142045975, 1.3226036571722943e-05, 4.013935267721536e-06, 4.803057436220115e-06, 1.0257443136652e-05, 0.19665947556495667, 4.527255077846348e-05, 0.00027762597892433405, 1.1714434549503494e-05, 9.47331227507675e-06, 0.22919593751430511, 2.6430629077367485e-05, 4.1018447518581524e-06, 0.26576098799705505, 8.515356967109255e-06, 4.536017513601109e-06, 0.30660009384155273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0008924750727601349, 0.00013490796845871955, 4.779836308443919e-05, 5.803714520880021e-05, 0.00010480164200998843, 0.012799101881682873, 0.0007168236770667136, 0.032579515129327774, 2.6449932192917913e-05, 0.00011185064067831263, 0.011884260922670364, 4.010270276921801e-05, 5.5553988204337656e-05, 0.01237786840647459, 0.00010783460311358795, 5.404365947470069e-05, 0.013122137635946274, 0.9148864150047302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [5.075309672974981e-06, 4.396138319862075e-05, 3.398504850338213e-05, 7.940286013763398e-05, 5.4779007768956944e-05, 7.921543101474526e-07, 9.313333066529594e-06, 7.727078809693921e-06, 8.597262058174238e-05, 0.0001227404281962663, 5.141488941262651e-07, 1.702793611002562e-06, 3.834182643913664e-05, 4.450971005098836e-07, 0.00013928208500146866, 0.0003275803755968809, 3.994800863438286e-07, 3.948134235542966e-06, 0.999043881893158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.346216393169016e-05, 0.001839574659243226, 0.0025233160704374313, 0.01808728091418743, 0.0029363802168518305, 0.00027335836784914136, 4.872979116044007e-05, 0.00042127820779569447, 0.00015624375373590738, 0.0009748361771926284, 0.00020533644419629127, 0.0010228854371234775, 0.001954806037247181, 0.00019470401457510889, 0.0011294216383248568, 0.0016656133811920881, 0.0001873407600214705, 0.0009503461769782007, 0.0004455185553524643, 0.9648895859718323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010859699686989188, 8.512331987731159e-06, 2.530730625949218e-06, 3.0625258204963757e-06, 5.9751278058683965e-06, 0.13292624056339264, 3.345325603731908e-05, 0.00018891270156018436, 8.477753908664454e-06, 6.540426056744764e-06, 0.16445893049240112, 1.8130069292965345e-05, 3.0627477372036083e-06, 0.19719161093235016, 6.429846507671755e-06, 3.444732328716782e-06, 0.2331714779138565, 0.0022796255070716143, 3.7134359445190057e-06, 3.528808520059101e-05, 0.268558531999588, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0004197950765956193, 0.00011805014219135046, 0.0001424048823537305, 3.796788223553449e-05, 0.00019043161591980606, 0.0017651217058300972, 0.0005709825200028718, 0.0005008853622712195, 8.840746158966795e-05, 0.0001420867774868384, 0.0016639818204566836, 3.3481079299235716e-05, 2.441395918140188e-05, 0.0017546487506479025, 6.520311580970883e-05, 2.414262417005375e-05, 0.0018299140501767397, 0.001569102518260479, 3.9748771087033674e-05, 0.00015712401363998652, 0.0018554466078057885, 0.9870065450668335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.501784421037883e-05, 0.0014379840577021241, 6.345157453324646e-05, 0.00010864839714486152, 0.00015633183647878468, 3.2101231681735953e-06, 0.002203276613727212, 0.0002207657671533525, 5.2403069275896996e-05, 4.88158839289099e-05, 2.264461500089965e-06, 1.5327248547691852e-05, 4.157144758210052e-06, 2.0228408175171353e-06, 6.2968028942123055e-06, 4.8486737796338275e-05, 1.992900934055797e-06, 3.247004497097805e-05, 0.0012695139739662409, 1.96326454897644e-05, 1.8090934190695407e-06, 0.0005810291040688753, 0.9936450719833374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.450144039466977e-05, 0.0006139380275271833, 0.0009361191187053919, 0.0008487799786962569, 0.002850631484761834, 1.0365030902903527e-05, 0.00021614256547763944, 0.00017397513147443533, 0.002050836570560932, 0.0058052996173501015, 8.055229955061805e-06, 8.086584421107545e-05, 0.0007702436414547265, 7.288177130249096e-06, 0.001057614921592176, 0.002275596372783184, 6.663255135208601e-06, 0.0001162100670626387, 0.0005972448270767927, 8.736289601074532e-05, 6.332331849989714e-06, 6.0964473959757015e-05, 6.090577517170459e-05, 0.9812840819358826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005848738364875317, 0.0001590918836882338, 1.0836472029041033e-05, 7.365470082731918e-05, 0.00011349524720571935, 0.0008256656583398581, 0.00031910985126160085, 0.01852995902299881, 1.0226591257378459e-05, 4.9587179091759026e-05, 0.0007716414402239025, 4.4548200094141066e-05, 9.86501618172042e-06, 0.0008067172020673752, 2.2673864805256017e-05, 1.246411648025969e-05, 0.0008449104498140514, 0.008790099062025547, 3.579234180506319e-05, 3.662859307951294e-05, 0.0008917524828575552, 0.001079176552593708, 0.000370846304576844, 0.00010837137961061671, 0.9654980301856995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.6459925973322242e-05, 0.00017152438522316515, 3.2083211408462375e-05, 0.00010234182263957337, 0.0026318759191781282, 9.886184670904186e-06, 3.2508516596863046e-05, 3.741757609532215e-05, 0.00012631528079509735, 4.9912112444872037e-05, 8.302548849314917e-06, 8.443414844805375e-05, 3.127968739136122e-05, 7.633363566128537e-06, 1.0101362931891344e-05, 5.6673809012863785e-05, 7.442136393365217e-06, 2.7689680791809224e-05, 1.841835728555452e-05, 2.8794345325877657e-06, 6.840427886345424e-06, 4.279879249224905e-06, 0.0004317661514505744, 0.00017617484263610095, 8.995590906124562e-05, 0.9958257675170898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.6368023100076243e-05, 0.00018008674669545144, 0.00018082918541040272, 0.0003046466445084661, 0.0003939079470001161, 4.674831507145427e-05, 2.7231642889091745e-05, 4.8734815209172666e-05, 0.000291316129732877, 0.0004206165031064302, 3.804632797255181e-05, 0.0002524509036447853, 5.606727427220903e-05, 3.820361598627642e-05, 0.0015365086728706956, 0.0012537215370684862, 3.593418296077289e-05, 2.3036574930301867e-05, 0.0001803622581064701, 0.00012266065459698439, 3.517777076922357e-05, 6.924665649421513e-05, 0.00011267283844063058, 0.0008507365128025413, 0.0001436186139471829, 0.0002352791343582794, 0.9930958151817322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0007048248080536723, 5.6753891840344295e-05, 3.3512924346723594e-06, 7.472657671314664e-06, 1.785946005838923e-05, 0.0008156524272635579, 4.952948074787855e-05, 0.0013530971482396126, 3.741763430298306e-05, 0.00014378006744664162, 0.0007639332907274365, 9.991685146815144e-06, 2.8844385724369204e-06, 0.0007552222232334316, 0.00010159601515624672, 3.120541123280418e-06, 0.0008060948457568884, 0.0011406756239011884, 1.4343104339786805e-05, 9.910167136695236e-06, 0.0008649178198538721, 8.663265907671303e-05, 3.4695473004831e-05, 0.00010265821038046852, 0.007663471158593893, 4.1878953197738156e-05, 3.4908730413008016e-06, 0.9844048619270325, 0.0, 0.0, 0.0, 0.0, 0.0], [2.0288294763304293e-05, 2.9542699849116616e-05, 5.0375034334138036e-05, 0.0009778320090845227, 0.3728252649307251, 6.66130017634714e-06, 1.573364352225326e-05, 3.981243571615778e-05, 0.00022353220265358686, 0.00012674322351813316, 5.118435637996299e-06, 0.00024116132408380508, 1.2973826414963696e-05, 4.800686838279944e-06, 2.3321617845795117e-05, 7.723527232883498e-05, 4.5934334593766835e-06, 1.9647124645416625e-05, 0.00021129944070708007, 1.1453501429059543e-05, 4.380481641419465e-06, 1.4442671272263397e-05, 3.676746564451605e-05, 0.000118453215691261, 3.7977195461280644e-05, 0.0007802759064361453, 0.0004048359696753323, 1.042955591401551e-05, 0.6236649751663208, 0.0, 0.0, 0.0, 0.0], [2.058288737316616e-05, 8.831225568428636e-05, 0.00020454842888284475, 0.00030188896926119924, 8.223879558499902e-05, 1.970437733689323e-05, 0.0001408507232554257, 2.8963118893443607e-05, 7.669370461371727e-06, 3.724609632627107e-05, 1.6736737961764447e-05, 6.404684245353565e-05, 0.0006910574156790972, 1.6027539459173568e-05, 0.0001560363598400727, 0.00014825885591562837, 1.5700039512012154e-05, 9.155373118119314e-05, 8.525074372300878e-05, 4.904507932224078e-06, 1.5784366041771136e-05, 5.293096910463646e-05, 0.0005298344185575843, 0.0005658384179696441, 6.167318497318774e-05, 6.729484448442236e-05, 0.000307743699522689, 1.0369129086029716e-05, 6.79933000355959e-05, 0.9960988759994507, 0.0, 0.0, 0.0], [1.3371331988309976e-05, 0.0009821540443226695, 0.0004154812777414918, 0.0001144233756349422, 0.0003873077221214771, 5.660860551870428e-06, 0.0012746269349008799, 0.0005708065000362694, 0.0006383624277077615, 0.0005776658072136343, 4.127733518544119e-06, 9.161743037111592e-06, 9.142841736320406e-05, 3.774864126171451e-06, 1.3575295270129573e-05, 0.0002916179655585438, 3.4474890071578557e-06, 7.899177580839023e-05, 0.003189122537150979, 4.885083853878314e-06, 3.165286670991918e-06, 1.4087455383560155e-05, 0.0001567144354339689, 0.00035448907874524593, 0.00017265455971937627, 0.0013050627894699574, 0.00021867647592443973, 2.6776719096233137e-05, 0.00026460207300260663, 1.3334529285202734e-05, 0.9888005256652832, 0.0, 0.0], [2.745508936641272e-05, 0.00016438262537121773, 7.996430940693244e-05, 0.001191497198306024, 0.0007883626385591924, 2.658417088241549e-06, 3.0057650292292237e-05, 7.457976153091295e-06, 0.00014940995606593788, 2.885718822653871e-05, 1.8738293192654965e-06, 0.0003328806778881699, 5.16086547577288e-05, 1.7577482367414632e-06, 0.00012656577746383846, 0.00014267012011259794, 1.6954487591647194e-06, 2.1952595488983206e-05, 0.00023040804080665112, 4.4293432438280433e-05, 1.6103322195704095e-06, 2.7008076358470134e-05, 0.0002388486755080521, 0.0001904603559523821, 9.49615514400648e-06, 0.00044664356391876936, 0.00022095811436884105, 5.379181402531685e-06, 0.0006956409779377282, 0.00015470781363546848, 0.0002548544143792242, 0.9943286776542664, 0.0], [0.006231046747416258, 9.722806862555444e-05, 6.871596269775182e-06, 2.1151136024855077e-05, 5.828053326695226e-05, 0.007238905411213636, 2.098789809679147e-05, 0.00025459096650592983, 6.243865209398791e-05, 2.09246627491666e-05, 0.007872136309742928, 5.5853244703030214e-05, 9.868757842923515e-06, 0.009169397875666618, 7.203003042377532e-05, 7.068680588417919e-06, 0.010345976799726486, 0.0013096530456095934, 3.803680374403484e-05, 8.022697147680447e-05, 0.012053255923092365, 4.071998773724772e-05, 3.6860749332845444e-06, 3.471342279226519e-05, 0.0005061830161139369, 8.918932871893048e-05, 2.9112088668625802e-05, 0.0012772815534844995, 8.489656465826556e-05, 0.00018447409092914313, 0.00013425741053652018, 6.813048094045371e-05, 0.9425214529037476]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.943029522895813, 0.05697045475244522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9185556173324585, 0.03280003368854523, 0.04864436388015747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8779287934303284, 0.05643429234623909, 0.04271192103624344, 0.022925030440092087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.804131805896759, 0.02909821644425392, 0.07556727528572083, 0.05643591657280922, 0.034766778349876404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4943104684352875, 0.02018355205655098, 0.02796657383441925, 0.01831907592713833, 0.0314420685172081, 0.40777820348739624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6057478189468384, 0.029242414981126785, 0.09491509944200516, 0.07609348744153976, 0.06614662706851959, 0.08705782145261765, 0.04079665243625641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.44838201999664307, 0.04542431980371475, 0.07401479780673981, 0.06864849478006363, 0.09376626461744308, 0.0877426341176033, 0.06534271687269211, 0.11667871475219727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4916927218437195, 0.13782072067260742, 0.03955019265413284, 0.061533186584711075, 0.04539967328310013, 0.04073144495487213, 0.06228701025247574, 0.05861866474151611, 0.06236641854047775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5404125452041626, 0.044426657259464264, 0.03957854583859444, 0.04188805818557739, 0.07529857754707336, 0.0466950349509716, 0.0484752394258976, 0.05500519275665283, 0.08293059468269348, 0.025289513170719147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28273555636405945, 0.014234174974262714, 0.017647748813033104, 0.011433064937591553, 0.021741721779108047, 0.266653835773468, 0.015403537079691887, 0.047349292784929276, 0.01776754856109619, 0.013926065526902676, 0.29110750555992126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.344966322183609, 0.046116799116134644, 0.05771547183394432, 0.11131860315799713, 0.11289367079734802, 0.027930330485105515, 0.038591887801885605, 0.05656527727842331, 0.05864057317376137, 0.0664859265089035, 0.026114365085959435, 0.05266084149479866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4699217975139618, 0.03201570361852646, 0.10772896558046341, 0.02700677700340748, 0.044658832252025604, 0.02277354709804058, 0.023117078468203545, 0.025491517037153244, 0.04950270056724548, 0.02657395601272583, 0.019708868116140366, 0.06337954849004745, 0.08812075853347778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20661760866641998, 0.010379291139543056, 0.012261935509741306, 0.00831909291446209, 0.016007086262106895, 0.1952774077653885, 0.01145328488200903, 0.03475673869252205, 0.01307358592748642, 0.010938980616629124, 0.21602492034435272, 0.005866493564099073, 0.02364230342209339, 0.23538129031658173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3399347960948944, 0.029161639511585236, 0.09540718793869019, 0.03395186364650726, 0.08440461754798889, 0.012559536844491959, 0.02935863845050335, 0.024564174935221672, 0.10622431337833405, 0.04689214378595352, 0.011469585821032524, 0.006369189824908972, 0.11145279556512833, 0.011317994445562363, 0.056931477040052414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4040881395339966, 0.024195684120059013, 0.03891001269221306, 0.014727428555488586, 0.024456579238176346, 0.038450006395578384, 0.039230331778526306, 0.037171389907598495, 0.06030002608895302, 0.041985440999269485, 0.037167154252529144, 0.016391245648264885, 0.03928966447710991, 0.03772980347275734, 0.13448576629161835, 0.01142128836363554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15876436233520508, 0.008203903213143349, 0.009295260533690453, 0.006221720017492771, 0.011793217621743679, 0.15069788694381714, 0.008851953782141209, 0.026313554495573044, 0.010186922736465931, 0.008433726616203785, 0.1676223874092102, 0.004420032259076834, 0.018211789429187775, 0.18350806832313538, 0.02092733606696129, 0.006447782274335623, 0.2001000940799713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1753920167684555, 0.020569654181599617, 0.018291426822543144, 0.009298018179833889, 0.01737789437174797, 0.04253477230668068, 0.020701566711068153, 0.050443943589925766, 0.02543802745640278, 0.01721823401749134, 0.043115369975566864, 0.01334981806576252, 0.028528621420264244, 0.045972537249326706, 0.034088198095560074, 0.01983419992029667, 0.04992840066552162, 0.3679172992706299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26033326983451843, 0.017148379236459732, 0.03745277225971222, 0.07594801485538483, 0.04674705117940903, 0.018068520352244377, 0.03134645149111748, 0.037415143102407455, 0.07175806909799576, 0.05872539058327675, 0.017078710719943047, 0.040305912494659424, 0.05706358328461647, 0.0171135775744915, 0.10491336137056351, 0.04670536145567894, 0.017230205237865448, 0.024682141840457916, 0.01996397040784359, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30547067523002625, 0.05190495401620865, 0.043468963354825974, 0.021846864372491837, 0.02101719379425049, 0.03390473127365112, 0.04190473258495331, 0.03909287974238396, 0.028871947899460793, 0.023003434762358665, 0.0320579931139946, 0.023334499448537827, 0.07110598683357239, 0.03290087729692459, 0.06164192408323288, 0.03183261677622795, 0.033767662942409515, 0.04571490362286568, 0.03501521423459053, 0.022141896188259125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12242947518825531, 0.006105298176407814, 0.006670295726507902, 0.004581778310239315, 0.00933779589831829, 0.11381791532039642, 0.006783361081033945, 0.019719919189810753, 0.007580864708870649, 0.006613645236939192, 0.12765930593013763, 0.0035026560071855783, 0.014002328738570213, 0.14000985026359558, 0.015684885904192924, 0.005092608276754618, 0.1533621847629547, 0.03527417406439781, 0.022465622052550316, 0.006954459473490715, 0.1723516285419464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20538491010665894, 0.034778520464897156, 0.014682922512292862, 0.03118332475423813, 0.030931271612644196, 0.021952766925096512, 0.032908644527196884, 0.05740534886717796, 0.05587517097592354, 0.04864276573061943, 0.023520752787590027, 0.01510855183005333, 0.027386317029595375, 0.024518456310033798, 0.060604527592659, 0.03477614372968674, 0.026137834414839745, 0.05168437957763672, 0.06281402707099915, 0.020291468128561974, 0.028601735830307007, 0.09081020206212997, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23978590965270996, 0.03132351115345955, 0.05037754774093628, 0.01586943119764328, 0.03901459649205208, 0.022805538028478622, 0.04285356402397156, 0.02888232097029686, 0.04046262055635452, 0.034107256680727005, 0.022644517943263054, 0.03923071548342705, 0.07238573580980301, 0.022345516830682755, 0.049581050872802734, 0.03193335607647896, 0.023325590416789055, 0.04521363228559494, 0.03055436909198761, 0.022876493632793427, 0.024732299149036407, 0.05549483001232147, 0.014199567027390003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2358168214559555, 0.020558306947350502, 0.04375005513429642, 0.0297048669308424, 0.03703878074884415, 0.014953462406992912, 0.040043093264102936, 0.027184367179870605, 0.04576181620359421, 0.03809260576963425, 0.014181884005665779, 0.03789154440164566, 0.06518244743347168, 0.014182931743562222, 0.054894935339689255, 0.023720962926745415, 0.014592780731618404, 0.025570042431354523, 0.07356180250644684, 0.039182357490062714, 0.014925516210496426, 0.046288661658763885, 0.02780105359852314, 0.015118876472115517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14254961907863617, 0.012010164558887482, 0.016881290823221207, 0.020742563530802727, 0.03245177119970322, 0.029626021161675453, 0.03029518760740757, 0.056208718568086624, 0.02960873395204544, 0.029481830075383186, 0.03263988345861435, 0.010038227774202824, 0.04078619182109833, 0.03462786599993706, 0.03391636908054352, 0.020155729725956917, 0.03684321045875549, 0.06064695864915848, 0.04744711145758629, 0.03252530097961426, 0.04040035605430603, 0.05947759747505188, 0.03129401057958603, 0.04792545735836029, 0.0714198648929596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22229067981243134, 0.059111349284648895, 0.0370267890393734, 0.04059012234210968, 0.027254492044448853, 0.01917477883398533, 0.03171537071466446, 0.020462162792682648, 0.03811328113079071, 0.019927892833948135, 0.01853892207145691, 0.015436709858477116, 0.04536491632461548, 0.0193557720631361, 0.05035829171538353, 0.03328137844800949, 0.020179763436317444, 0.03679434582591057, 0.043313875794410706, 0.028476420789957047, 0.021317342296242714, 0.04771285504102707, 0.013107025995850563, 0.026336045935750008, 0.03021138906478882, 0.03454805910587311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28438133001327515, 0.023870114237070084, 0.04641878232359886, 0.010260084643959999, 0.033909864723682404, 0.018301473930478096, 0.02370886504650116, 0.02476685121655464, 0.0257677361369133, 0.022968832403421402, 0.016735466197133064, 0.013406947255134583, 0.045986615121364594, 0.016673246398568153, 0.08106391131877899, 0.05033260956406593, 0.01672617346048355, 0.019904818385839462, 0.03032534383237362, 0.01014631986618042, 0.017318226397037506, 0.01904095895588398, 0.011081119067966938, 0.052046407014131546, 0.033353518694639206, 0.038808856159448624, 0.012695521116256714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11854352056980133, 0.013350939378142357, 0.013422021642327309, 0.0302731990814209, 0.026162942871451378, 0.020776191726326942, 0.021280208602547646, 0.037989355623722076, 0.03536440432071686, 0.03665180504322052, 0.022004010155797005, 0.015380024909973145, 0.030023114755749702, 0.02329968847334385, 0.03000754863023758, 0.014861365780234337, 0.0245219599455595, 0.03999800980091095, 0.03900158032774925, 0.03600766882300377, 0.026851218193769455, 0.06795872002840042, 0.03893132507801056, 0.05725807696580887, 0.06659837067127228, 0.03075684979557991, 0.023343218490481377, 0.059382691979408264, 0.0, 0.0, 0.0, 0.0, 0.0], [0.25091859698295593, 0.011351891793310642, 0.023033946752548218, 0.01884976029396057, 0.013208831660449505, 0.016430387273430824, 0.03763696178793907, 0.02151942066848278, 0.03823147714138031, 0.031223101541399956, 0.01608109287917614, 0.017179002985358238, 0.0823965072631836, 0.015775403007864952, 0.049693115055561066, 0.03397902101278305, 0.016469139605760574, 0.025656115263700485, 0.053269315510988235, 0.024380968883633614, 0.017032910138368607, 0.03106255829334259, 0.014834254048764706, 0.04310779646039009, 0.0278183463960886, 0.015127943828701973, 0.012749834917485714, 0.026852663606405258, 0.014129591174423695, 0.0, 0.0, 0.0, 0.0], [0.19256944954395294, 0.022833673283457756, 0.014495889656245708, 0.028055019676685333, 0.03290428966283798, 0.018577082082629204, 0.02377673052251339, 0.014988926239311695, 0.027755478397011757, 0.01995215192437172, 0.018426889553666115, 0.02680845372378826, 0.040261976420879364, 0.018957344815135002, 0.01998024247586727, 0.039050307124853134, 0.01949433796107769, 0.030714334920048714, 0.07932320982217789, 0.03619769960641861, 0.020379599183797836, 0.023319294676184654, 0.018723847344517708, 0.05692766606807709, 0.02392755076289177, 0.039243265986442566, 0.021783530712127686, 0.020374223589897156, 0.041788313537836075, 0.008409240283071995, 0.0, 0.0, 0.0], [0.18919387459754944, 0.014352075755596161, 0.0278293676674366, 0.018936043605208397, 0.054552335292100906, 0.024302400648593903, 0.020752547308802605, 0.03050178848206997, 0.016900410875678062, 0.029904045164585114, 0.02311178483068943, 0.021664844825863838, 0.0333598330616951, 0.023050503805279732, 0.027927033603191376, 0.026253478601574898, 0.024257969111204147, 0.02439497970044613, 0.017666680738329887, 0.022081071510910988, 0.02544151246547699, 0.023996727541089058, 0.015941409394145012, 0.021863479167222977, 0.048762742429971695, 0.010234068147838116, 0.025762980803847313, 0.061923276633024216, 0.06737106293439865, 0.018184129148721695, 0.00952551607042551, 0.0, 0.0], [0.27111953496932983, 0.05460578203201294, 0.03970597684383392, 0.03512894734740257, 0.020313767716288567, 0.008183852769434452, 0.022556617856025696, 0.014036444947123528, 0.026198463514447212, 0.03235536068677902, 0.007185027468949556, 0.01081349328160286, 0.05162609741091728, 0.007057543378323317, 0.04232776165008545, 0.018505984917283058, 0.006952994968742132, 0.012550849467515945, 0.037855181843042374, 0.014787377789616585, 0.007130765821784735, 0.018956730142235756, 0.010758972726762295, 0.02354053035378456, 0.01625620760023594, 0.007915407419204712, 0.03652311861515045, 0.014562279917299747, 0.019251449033617973, 0.010911819525063038, 0.0343967080116272, 0.06592902541160583, 0.0], [0.14836539328098297, 0.014506885781884193, 0.007646287325769663, 0.01103874109685421, 0.02630249410867691, 0.013194814324378967, 0.027184873819351196, 0.017392195761203766, 0.016122113913297653, 0.03288079425692558, 0.014050282537937164, 0.007167341653257608, 0.0161200612783432, 0.01464702095836401, 0.018450897186994553, 0.013102118857204914, 0.015283250249922276, 0.014542998746037483, 0.05961218848824501, 0.022383900359272957, 0.016796976327896118, 0.10928261280059814, 0.07263996452093124, 0.08393712341785431, 0.02524900995194912, 0.03774847835302353, 0.01622692681849003, 0.02495388500392437, 0.042165789753198624, 0.004525812342762947, 0.01449135784059763, 0.019145702943205833, 0.02284165285527706]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09646999090909958, 0.903529942035675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.043252408504486084, 0.08177754282951355, 0.8749701380729675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09995390474796295, 0.025312701240181923, 0.020108036696910858, 0.854625403881073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024889355525374413, 0.00320735527202487, 0.0018421602435410023, 0.022361503913998604, 0.9476996660232544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10732372850179672, 0.01784166693687439, 0.01955333724617958, 0.0433332584798336, 0.10211502760648727, 0.7098329663276672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006426361855119467, 0.0004479786439333111, 0.00014756617019884288, 0.00046936815488152206, 0.001441190019249916, 0.0038596985395997763, 0.98720782995224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010354582918807864, 0.0001990183664020151, 0.0001602039410499856, 6.937277794349939e-05, 0.000386741739930585, 0.005171590019017458, 0.8964056372642517, 0.09657198190689087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0012883353047072887, 0.0003233459428884089, 0.0002652723924256861, 0.00025490688858553767, 0.00020129882614128292, 0.00010049015691038221, 0.0005700902547687292, 0.00040913093835115433, 0.9965871572494507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0001874162262538448, 1.619654540263582e-05, 4.2281080823158845e-06, 0.0002875888312701136, 1.1125715900561772e-05, 9.805656191019807e-06, 0.0001556719362270087, 7.632971392013133e-05, 0.0034869094379246235, 0.9957647323608398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015741519629955292, 0.0006393605144694448, 0.0004571522295009345, 0.0009912526002153754, 0.0021140349563211203, 0.018089747056365013, 0.0471203550696373, 0.07010902464389801, 0.061528366059064865, 0.27690407633781433, 0.5063050389289856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.000616659817751497, 0.0005207078065723181, 4.61151976196561e-05, 0.001461300882510841, 0.0005623759934678674, 4.4476037146523595e-05, 0.00036539699067361653, 0.0002860168751794845, 0.004506122786551714, 0.005816523917019367, 0.0007244537118822336, 0.9850499033927917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010478587355464697, 3.062820542254485e-05, 0.00017345046217087656, 5.423139737104066e-05, 6.388442125171423e-05, 1.12611596705392e-05, 1.7169008060591295e-05, 1.3931321518612094e-05, 0.002076044213026762, 0.0002692685811780393, 0.00015268517017830163, 0.0036844443529844284, 0.992405116558075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010746264830231667, 0.0002535430248826742, 0.00015322912076953799, 0.0002928699250333011, 0.0005376791814342141, 0.004423539154231548, 0.00988432765007019, 0.012843023985624313, 0.012738605961203575, 0.05966855585575104, 0.10772986710071564, 0.024745658040046692, 0.07808699458837509, 0.6778957843780518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00041218000114895403, 2.6218713173875585e-05, 1.77559231815394e-05, 0.00019181902462150902, 3.2979460229398683e-06, 3.912674856110243e-06, 1.043809788825456e-05, 4.906844878860284e-06, 0.000586855923756957, 0.0030381556134670973, 3.693124745041132e-05, 0.0007724311435595155, 0.009622619487345219, 0.00016094425518531352, 0.9851114153862, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00010886562085943297, 3.58454167326272e-06, 5.191652689973125e-06, 3.083834599237889e-05, 1.840872755565215e-05, 7.954750458338822e-07, 3.353204192535486e-06, 6.574371127499035e-06, 0.0007270933128893375, 0.0018232447328045964, 7.853259376133792e-06, 0.00030627453816123307, 0.006975044962018728, 3.4850869269575924e-05, 0.0282927043735981, 0.9616552591323853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006073995493352413, 8.815199544187635e-05, 4.583775080391206e-05, 8.250488463090733e-05, 0.00012720438826363534, 0.000931252259761095, 0.0016700000269338489, 0.0019381919410079718, 0.002101697726175189, 0.010131681337952614, 0.016047311946749687, 0.003835386596620083, 0.012242159806191921, 0.10037077963352203, 0.07853133976459503, 0.10997357219457626, 0.6558089256286621, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002186299068853259, 1.189292743219994e-05, 1.6735941244405694e-05, 2.081546699628234e-05, 2.1162548364372924e-05, 0.0007714926614426076, 0.0008652099058963358, 0.0005560303688980639, 0.00015655897732358426, 0.0019499945919960737, 0.010891207493841648, 0.00039543010643683374, 0.001514473813585937, 0.06916320323944092, 0.004308105446398258, 0.004035164602100849, 0.4939698576927185, 0.4091663956642151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.9797989807557315e-05, 4.972393412572274e-07, 9.165694869750496e-09, 1.3230416584519844e-07, 5.601832597790235e-08, 1.1903876995233986e-08, 6.153105118755775e-07, 4.068542835966582e-08, 4.517441993812099e-06, 1.4017764442542102e-05, 1.6456900198136282e-07, 1.0863833495022845e-06, 7.444068614859134e-06, 1.00566455785156e-06, 2.7594995117397048e-05, 0.00031378038693219423, 6.20114269622718e-06, 8.213378350774292e-06, 0.9995948672294617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [6.497162758023478e-06, 8.692020401213085e-07, 1.405140778842906e-06, 3.770490479837463e-07, 3.3291667023149785e-07, 6.104973948595216e-08, 2.542995680698823e-08, 1.1067781713336444e-07, 3.6708741390611976e-05, 5.70481461181771e-07, 6.172353437250422e-07, 0.00015627966786269099, 0.0001473798620281741, 3.0103849439910846e-06, 6.130666588433087e-05, 0.00177699641790241, 1.8545975763117895e-05, 3.4263168345205486e-05, 0.9233516454696655, 0.07440308481454849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0036490089260041714, 3.749436655198224e-05, 1.7470789316575974e-05, 2.8449203455238603e-05, 3.312428088975139e-05, 0.00019569222058635205, 0.0002647594374138862, 0.00024690417922101915, 0.0002803316747304052, 0.0013949201675131917, 0.0017910292372107506, 0.00042467910679988563, 0.0014623713213950396, 0.009717762470245361, 0.008053941652178764, 0.013200568035244942, 0.06315956264734268, 0.07152795046567917, 0.0752311572432518, 0.024205081164836884, 0.7250778079032898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0006410888745449483, 3.925701548723737e-06, 1.1607372698563267e-06, 1.5375495650005178e-06, 9.072633133655472e-07, 8.058204912231304e-06, 1.3223946552898269e-05, 4.619919764081715e-06, 3.678829671116546e-05, 4.5651795517187566e-05, 7.577831274829805e-05, 2.2741733118891716e-05, 5.6684690207475796e-05, 0.0004737513663712889, 0.0003640766954049468, 0.00042400186066515744, 0.003757331520318985, 0.00436313496902585, 0.007395221386104822, 0.005022627301514149, 0.05575621873140335, 0.9215314984321594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.000537768064532429, 8.122559620460379e-07, 2.3018583306111395e-06, 1.47003993333783e-06, 1.8703644855122548e-06, 6.024494041412254e-07, 4.127825377508998e-06, 1.6705714642739622e-06, 2.0471920834097546e-06, 7.43004638934508e-05, 3.5942262002208736e-06, 7.171494871727191e-06, 3.052817555726506e-05, 1.892773616418708e-05, 0.0002543877635616809, 0.0001949636498466134, 0.00012626526586245745, 0.0001823053607949987, 0.0037352198269218206, 0.000672711234074086, 0.001579830888658762, 0.011177674867212772, 0.9813894629478455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.512824570061639e-05, 4.870875613960379e-07, 1.2458967830752954e-06, 2.0811336298720562e-07, 1.9242880000547302e-07, 3.70403121507934e-08, 4.5552522465186485e-07, 5.504545796952698e-08, 1.532037913420936e-06, 5.083314590592636e-06, 2.1401001504273154e-07, 1.4595307220588438e-06, 1.4768388609809335e-05, 1.063502395481919e-06, 2.9461507438099943e-05, 5.7288165407953784e-05, 6.615693564526737e-06, 7.84422445576638e-06, 0.00015063813771121204, 0.00022636937501374632, 7.97359534772113e-05, 0.00013040847261436284, 0.010868419893085957, 0.9883312582969666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00041663245065137744, 2.2503695618070196e-06, 5.270543169899611e-06, 2.7549147489480674e-05, 3.9630536775803193e-05, 7.51473589843954e-06, 8.100932973320596e-06, 1.1581341823330149e-05, 1.3205953109718394e-05, 6.750722968718037e-05, 2.5212764739990234e-05, 1.4860672308714129e-05, 7.52170235500671e-05, 0.00011457463551778346, 0.00025745289167389274, 0.00036668599932454526, 0.0006904734764248133, 0.0014518474927172065, 0.003246019361540675, 0.0006353409844450653, 0.008745579980313778, 0.015190845355391502, 0.01815016381442547, 0.13303308188915253, 0.8174033761024475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.6739300917834044e-05, 8.245334015555272e-08, 3.25739257789337e-08, 2.8737504820242066e-08, 1.621771161808283e-07, 1.5275413156601303e-09, 2.327868919849152e-08, 5.576728856482305e-09, 1.2825790918213897e-07, 1.342952486993454e-07, 6.160572496582972e-09, 2.5232574785150064e-07, 3.205760094715515e-06, 2.627727724302531e-08, 7.619977395734168e-07, 7.901960088929627e-06, 1.3940493204245286e-07, 1.9552594210381358e-07, 0.0003202258376404643, 8.173685728252167e-07, 1.5630005236744182e-06, 3.763166887438274e-06, 0.0007450513658113778, 0.003715230617672205, 3.9344242395600304e-05, 0.995144248008728, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00023842263908591121, 5.040105861553457e-06, 1.320860292253201e-06, 8.599827197031118e-06, 5.166048595128814e-06, 1.347093672166011e-07, 6.710809543619689e-07, 2.6996977453563886e-07, 6.345730525936233e-06, 4.417830496095121e-05, 2.7445037176221376e-07, 2.0171210053376853e-05, 1.6526657418580726e-05, 8.122790404740954e-07, 0.00010771022061817348, 0.00012397441605571657, 3.5075884170510108e-06, 8.505847290507518e-06, 6.980274338275194e-05, 0.0002681366167962551, 2.8792892408091575e-05, 0.00011957916285609826, 0.0001296167611144483, 0.007425940595567226, 0.0007109721773304045, 0.005815021228045225, 0.984840452671051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00040899476152844727, 6.095366416047909e-07, 1.9963897557317978e-06, 9.310323548561428e-06, 3.7690506360377185e-06, 1.9876508758898126e-06, 4.5765477807435673e-07, 1.06907145891455e-06, 3.0871688068145886e-06, 9.211416909238324e-06, 4.724366135633318e-06, 1.2070046295775683e-06, 5.095616870676167e-06, 1.8047086996375583e-05, 4.857865860685706e-05, 4.1693794628372416e-05, 0.00010537506022956222, 0.00022466850350610912, 0.00011528616596478969, 0.0002492897037882358, 0.0013673118082806468, 0.0016190301394090056, 0.00132751592900604, 0.0034917863085865974, 0.06305655837059021, 0.006469059269875288, 0.09512630850076675, 0.8262879252433777, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003180466592311859, 1.4181814549374394e-06, 3.1855009297032666e-07, 2.7823105028801365e-06, 5.388593490351923e-05, 4.300602540752152e-08, 5.38626068191661e-07, 8.497841008647811e-08, 5.999703489578678e-07, 4.110322151973378e-06, 7.099385612718834e-08, 8.454292128590168e-07, 2.526610387576511e-06, 2.1983822762194904e-07, 6.098234734963626e-06, 2.112996662617661e-05, 9.41176608648675e-07, 9.950366575139924e-07, 3.041357376787346e-05, 2.976983751068474e-06, 8.453844202449545e-06, 2.600699008326046e-05, 0.00023055807105265558, 0.001338335918262601, 0.00021758218645118177, 0.007014384958893061, 0.017923979088664055, 0.000530267134308815, 0.9722622632980347, 0.0, 0.0, 0.0, 0.0], [1.8505296850435116e-07, 5.565692351439111e-09, 7.262711543276623e-10, 7.745998509278706e-09, 1.507951097323712e-08, 8.228537295984495e-10, 1.7915484651354063e-09, 1.7345679337310571e-09, 1.096253487986587e-08, 5.0033129639359686e-08, 3.9228313930550485e-09, 1.001394380750753e-07, 2.333783655217303e-08, 1.6555286919128775e-08, 5.171339623188942e-08, 1.614605764643784e-07, 9.827901692460728e-08, 2.707459714201832e-07, 5.411987331171986e-06, 2.5083886612264905e-07, 1.1806023394456133e-06, 2.8004308205709094e-06, 4.61038098364952e-06, 0.00022679254470858723, 5.794259050162509e-05, 0.0004519563226494938, 0.00011976490350207314, 0.00023980853438843042, 0.001874009263701737, 0.9970145225524902, 0.0, 0.0, 0.0], [4.347461799625307e-05, 2.968866283481475e-06, 3.919368225524522e-07, 9.117064223573834e-07, 4.3644891434269084e-07, 4.686581345225704e-09, 9.240376641628245e-08, 1.241937130913584e-08, 7.188949524561394e-08, 6.304542807811231e-07, 6.1088996083924485e-09, 1.9987159305401292e-07, 1.4578700984202442e-06, 1.4727342012577083e-08, 1.7957290765480138e-07, 2.6422658265801147e-05, 5.112665846240816e-08, 4.710682333097793e-08, 0.001576117007061839, 2.1989408196532167e-06, 3.333985034714715e-07, 2.1814789761265274e-06, 0.0001624042197363451, 0.0017777644097805023, 1.174922817881452e-05, 0.00361609342508018, 6.199476774781942e-05, 3.516826109262183e-05, 0.001148871029727161, 0.016085602343082428, 0.975442111492157, 0.0, 0.0], [0.0011562933214008808, 6.199030394782312e-06, 6.137789227977919e-07, 3.1026631859276677e-06, 8.228416277233919e-07, 4.36601119702118e-08, 9.36323729661126e-08, 2.7735437058140633e-08, 5.109505423206429e-07, 1.2355309308986762e-06, 3.825297056891941e-08, 1.1272275060036918e-06, 1.9008989511348773e-06, 8.714057031511402e-08, 5.398172561399406e-06, 7.3934234023909084e-06, 3.1288666946238664e-07, 3.0146313179102435e-07, 0.0001359532616334036, 1.334382250206545e-05, 2.3996476556931157e-06, 3.871273293043487e-05, 0.0008219640585593879, 0.0006131274858489633, 2.151845910702832e-05, 0.004140730947256088, 0.0008760871132835746, 0.00011684626952046528, 0.0021590713877230883, 0.02752530761063099, 0.04434975981712341, 0.9179997444152832, 0.0], [0.003194286022335291, 4.6816610847599804e-05, 3.499119702610187e-05, 2.7043071895604953e-05, 1.400027576892171e-05, 1.708509080344811e-05, 8.051882105064578e-06, 3.9098295019357465e-06, 1.0716913493524771e-05, 1.793078990885988e-05, 1.4207491403794847e-05, 2.6911246095551178e-05, 2.6411986254970543e-05, 3.1100214982870966e-05, 1.1198586435057223e-05, 5.485487054102123e-05, 0.00011474463099148124, 0.00010493670561118051, 0.00028063016361556947, 0.00020839045464526862, 0.0009329259628430009, 0.0018989999080076814, 0.0011267592199146748, 0.0019257249077782035, 0.003917154390364885, 0.007499453146010637, 0.0106959268450737, 0.023199843242764473, 0.03039816953241825, 0.12729336321353912, 0.04325321689248085, 0.17668063938617706, 0.5669296383857727]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.25308626890182495, 0.7469137907028198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30671602487564087, 0.3290638327598572, 0.36422017216682434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07416975498199463, 0.16189667582511902, 0.05432593822479248, 0.7096075415611267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16688226163387299, 0.03901785984635353, 0.03822459653019905, 0.21398362517356873, 0.5418916344642639, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1948363482952118, 0.21119245886802673, 0.05150560662150383, 0.08703835308551788, 0.229995459318161, 0.22543172538280487, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13900133967399597, 0.02974863536655903, 0.038606978952884674, 0.051332734525203705, 0.19284239411354065, 0.08012380450963974, 0.46834418177604675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08969774097204208, 0.04080598056316376, 0.034733086824417114, 0.08414526283740997, 0.09911048412322998, 0.07059450447559357, 0.13616575300693512, 0.4447471797466278, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05986514315009117, 0.020190445706248283, 0.018785327672958374, 0.10584729164838791, 0.057948824018239975, 0.027517717331647873, 0.0566631518304348, 0.08226766437292099, 0.5709145069122314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010379279963672161, 0.004698257893323898, 0.004143994301557541, 0.007291416637599468, 0.0062567018903791904, 0.003318049944937229, 0.00917502585798502, 0.018754417076706886, 0.03393152728676796, 0.9020513892173767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0727011114358902, 0.04776482656598091, 0.01050033699721098, 0.0161594208329916, 0.04617820680141449, 0.05249457061290741, 0.05184565857052803, 0.21189527213573456, 0.035158224403858185, 0.17267188429832458, 0.28263047337532043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015126868151128292, 0.004731183405965567, 0.002322629326954484, 0.006575732491910458, 0.01836243085563183, 0.003339658956974745, 0.008784198202192783, 0.007409723941236734, 0.006289792712777853, 0.07638929039239883, 0.012003449723124504, 0.8386650681495667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.032331958413124084, 0.010628974065184593, 0.0026151672936975956, 0.0011762939393520355, 0.0030932873487472534, 0.00150555360596627, 0.007079716771841049, 0.0028344711754471064, 0.005003888159990311, 0.01203258614987135, 0.003987773787230253, 0.05187242105603218, 0.8658378720283508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.050455864518880844, 0.026538824662566185, 0.005783269181847572, 0.00808729324489832, 0.021799379959702492, 0.025670353323221207, 0.022779015824198723, 0.09139913320541382, 0.015017377212643623, 0.07093919813632965, 0.12448625266551971, 0.12668342888355255, 0.061021383851766586, 0.34933918714523315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05474120005965233, 0.05296842381358147, 0.00398812722414732, 0.012351608835160732, 0.004415616393089294, 0.0035962751135230064, 0.011385679244995117, 0.00982806459069252, 0.01474972628057003, 0.07078820466995239, 0.011209171265363693, 0.051640551537275314, 0.19734397530555725, 0.027129260823130608, 0.4738641083240509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007163074798882008, 0.0049638510681688786, 0.0027692264411598444, 0.0019424431957304478, 0.010544744320213795, 0.0014144869055598974, 0.0036636609584093094, 0.0031499466858804226, 0.005481296218931675, 0.021614039316773415, 0.003922193311154842, 0.07935071736574173, 0.2247791737318039, 0.009166942909359932, 0.027402691543102264, 0.5926714539527893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03461107611656189, 0.015296346507966518, 0.003095124149695039, 0.003899093484506011, 0.009989401325583458, 0.011446869932115078, 0.009189348667860031, 0.03356512635946274, 0.005761214066296816, 0.025581039488315582, 0.043846841901540756, 0.045213643461465836, 0.020553411915898323, 0.11962327361106873, 0.15673257410526276, 0.13173453509807587, 0.32986098527908325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.017253858968615532, 0.004397520795464516, 0.004968684632331133, 0.007064307574182749, 0.006634886842221022, 0.006910951808094978, 0.011386895552277565, 0.01617850922048092, 0.02031775750219822, 0.020396798849105835, 0.023422079160809517, 0.01890912838280201, 0.0402420274913311, 0.06200673431158066, 0.1164536327123642, 0.07975101470947266, 0.16864453256130219, 0.37506064772605896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002459116280078888, 0.00024919791030697525, 3.400469358894043e-05, 0.0002113294176524505, 0.00020066798606421798, 0.00012589257676154375, 0.00036506823380477726, 0.0003735981590580195, 0.00013798549480270594, 0.0004702214209828526, 0.00027151801623404026, 0.0034170830622315407, 0.0006049814983271062, 0.0005454604397527874, 0.0008937679813243449, 0.0015852140495553613, 0.0012150746770203114, 0.0028212708421051502, 0.9840186238288879, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00015282449021469802, 0.03892357647418976, 0.00047151927719824016, 0.0003731812466867268, 3.271793684689328e-05, 1.0635613762133289e-05, 3.82458756575943e-06, 1.324470758845564e-05, 6.418924022000283e-05, 2.7344371119397692e-05, 2.8319987904978916e-05, 0.0022295680828392506, 0.0013866389635950327, 7.163518603192642e-05, 0.00014025568088982254, 0.00824644137173891, 0.00019678636454045773, 0.00020546688756439835, 0.8976381421089172, 0.049783799797296524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02645810879766941, 0.010410881601274014, 0.0021332567557692528, 0.0024560168385505676, 0.005542594939470291, 0.005954573396593332, 0.004195827059447765, 0.01345154270529747, 0.002351952949538827, 0.009471964091062546, 0.015433412045240402, 0.014804958365857601, 0.006865768227726221, 0.03787313401699066, 0.04744938015937805, 0.04547279700636864, 0.10199157148599625, 0.08666396886110306, 0.06470183283090591, 0.1016075611114502, 0.3947088420391083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021157877519726753, 0.00354843121021986, 0.001744113047607243, 0.0035093037877231836, 0.004201893694698811, 0.0025777805130928755, 0.004015853628516197, 0.004599003586918116, 0.003955155145376921, 0.0064558410085737705, 0.005907890386879444, 0.0037331627681851387, 0.009013410657644272, 0.013927983120083809, 0.029895808547735214, 0.020082315430045128, 0.03804437443614006, 0.06883098930120468, 0.0815289169549942, 0.038340236991643906, 0.1516025811433792, 0.4833270013332367, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0014211690286174417, 0.0004069015849381685, 0.0002714423753786832, 0.0014869242440909147, 0.0006475155241787434, 0.0002567152841947973, 0.00027297638007439673, 0.0005059854011051357, 0.00017537508392706513, 0.0012059608707204461, 0.0005902891862206161, 0.0004307391936890781, 0.0003699962398968637, 0.0013322837185114622, 0.0007594277849420905, 0.002518308814615011, 0.003599978983402252, 0.0047567193396389484, 0.011892938055098057, 0.0034102171193808317, 0.013851102441549301, 0.05907326936721802, 0.8907637596130371, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005058860406279564, 0.000882354099303484, 0.0015358275268226862, 0.0016909866826608777, 0.0013438730966299772, 0.0004949701833538711, 0.0006572249112650752, 0.000552159093786031, 0.000581209606025368, 0.002054559765383601, 0.0008380856597796082, 0.0010067481780424714, 0.0011300848564133048, 0.001613991684280336, 0.00502287270501256, 0.014576866291463375, 0.0037143270019441843, 0.00468147499486804, 0.00791381485760212, 0.00677838921546936, 0.01229135412722826, 0.02773299440741539, 0.10214640945196152, 0.7957004904747009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004004694987088442, 0.00045769716962240636, 0.0015645220410078764, 0.003137202700600028, 0.001993744168430567, 0.0003789264301303774, 0.0004957786295562983, 0.0005698024178855121, 0.0010052063735201955, 0.0023432238958775997, 0.0005772150470875204, 0.0016756131080910563, 0.0030787368305027485, 0.0012285251868888736, 0.005278326105326414, 0.006328050512820482, 0.003151729004457593, 0.005319306161254644, 0.021383114159107208, 0.006147704552859068, 0.012332224287092686, 0.0740215927362442, 0.12114027142524719, 0.5611116290092468, 0.16127507388591766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001128658070228994, 4.988930231775157e-05, 4.129138324060477e-05, 9.24963824218139e-05, 5.51363846170716e-05, 3.8617330574197695e-05, 5.59204381715972e-05, 0.0001489632559241727, 5.509230959432898e-06, 6.817452958784997e-05, 3.6204492062097415e-05, 4.623966015060432e-05, 0.0010655045043677092, 5.919886825722642e-05, 7.787275535520166e-05, 0.00038421317003667355, 0.00011692449334077537, 0.00022428261581808329, 0.0005083996220491827, 0.000156281515955925, 0.0003233152092434466, 0.0007086835685186088, 0.0009207437979057431, 0.000855972757562995, 0.004414450377225876, 0.9884170889854431, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0024299686774611473, 0.0036596376448869705, 0.0006344975554384291, 0.0006202647928148508, 0.0029876769986003637, 0.0003476363781373948, 0.0005059159593656659, 0.0004114970506634563, 0.0002132159424945712, 0.0006509348750114441, 0.00039556872798129916, 0.16986438632011414, 0.00218889769166708, 0.0006812370265834033, 0.0008683771593496203, 0.008905136026442051, 0.001463850843720138, 0.0013394582783803344, 0.006495129782706499, 0.00763870682567358, 0.004619393032044172, 0.0031617912463843822, 0.01420089416205883, 0.04639661684632301, 0.022786036133766174, 0.21939244866371155, 0.477140873670578, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01561034843325615, 0.000964807637501508, 0.0010281838476657867, 0.007148519158363342, 0.005316654685884714, 0.0005432687466964126, 0.0007839889149181545, 0.00047083027311600745, 0.0022980389185249805, 0.005463102366775274, 0.000548307434655726, 0.0008661496685817838, 0.0009035562397912145, 0.000925196975003928, 0.008375940844416618, 0.0014478119555860758, 0.0020614906679838896, 0.0036933852825313807, 0.017008868977427483, 0.006138673983514309, 0.007041901350021362, 0.041287098079919815, 0.06922487914562225, 0.2661719024181366, 0.05024213343858719, 0.1144513264298439, 0.13764901459217072, 0.23233459889888763, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02189529314637184, 0.0013514538295567036, 0.0013727964833378792, 0.005157722160220146, 0.010932797566056252, 0.0004452221328392625, 0.0016178287332877517, 0.0005713263526558876, 0.0007700271671637893, 0.0030935355462133884, 0.00036163386539556086, 0.000932903029024601, 0.0019032390555366874, 0.000525438750628382, 0.0007036192109808326, 0.0015780625399202108, 0.0010200463002547622, 0.0009346720762550831, 0.005167576018720865, 0.0007855418953113258, 0.0028796831611543894, 0.006337143015116453, 0.049514152109622955, 0.021886909380555153, 0.030046813189983368, 0.06941599398851395, 0.02995389513671398, 0.06111619994044304, 0.6677284836769104, 0.0, 0.0, 0.0, 0.0], [0.00029466592241078615, 8.085126319201663e-05, 0.00011992641520919278, 0.0001715401012916118, 0.00038990104803815484, 8.630267984699458e-05, 5.25372197444085e-05, 6.616386963287368e-05, 0.0001137840372393839, 6.200086500030011e-05, 0.00011238036677241325, 0.0005867322906851768, 9.78500975179486e-05, 0.00021334874327294528, 0.0004044429515488446, 0.00047262446605600417, 0.0004730731307063252, 0.0005199533188715577, 0.0008571154903620481, 0.00022720213746652007, 0.0015976789873093367, 0.0014780652709305286, 0.0016501445788890123, 0.009339648298919201, 0.012792675755918026, 0.012606960721313953, 0.0216596107929945, 0.028867468237876892, 0.0778479129076004, 0.826757550239563, 0.0, 0.0, 0.0], [0.0006396547541953623, 0.0001992026373045519, 0.0003378460824023932, 0.0003228614223189652, 0.00038839818444103, 2.2511421775561757e-05, 0.00011559668928384781, 1.968370816030074e-05, 8.749762491788715e-05, 0.00016675732331350446, 2.1353202100726776e-05, 0.0001825768267735839, 0.002879622858017683, 3.2708350772736594e-05, 6.355990626616403e-05, 0.0009078503935597837, 6.314194615697488e-05, 4.954513497068547e-05, 0.005010182503610849, 0.00021555769490078092, 0.00018923310562968254, 0.00023579836124554276, 0.0021191718988120556, 0.003475247649475932, 0.0004957503406330943, 0.012673018500208855, 0.0026274595875293016, 0.001192636787891388, 0.028011472895741463, 0.14214564859867096, 0.7951083779335022, 0.0, 0.0], [0.005492149852216244, 0.0014179619029164314, 6.310044409474358e-05, 0.0009282372775487602, 0.0004675877280533314, 9.701230737846345e-05, 5.678696106770076e-05, 6.82406680425629e-05, 4.054810415254906e-05, 0.00021011468197684735, 6.534693238791078e-05, 0.00011957802053075284, 9.082323231268674e-05, 9.077353024622425e-05, 0.00013827483053319156, 0.0004122828249819577, 0.00016900571063160896, 0.00013570708688348532, 0.002428323496133089, 0.00020654767286032438, 0.0004959602956660092, 0.00016561975644435734, 0.0018254045862704515, 0.0016808181535452604, 0.0010187349980697036, 0.015071484260261059, 0.003408379852771759, 0.003384194802492857, 0.018865535035729408, 0.010037437081336975, 0.008259563706815243, 0.923088550567627, 0.0], [0.009386110119521618, 0.0017380572389811277, 0.0018091698875650764, 0.0014350239653140306, 0.0016812816029414535, 0.0019791293889284134, 0.0014143430162221193, 0.0021127830259501934, 0.0012016951804980636, 0.0010467651300132275, 0.0012532471446320415, 0.0012125695357099175, 0.0006952418480068445, 0.0016850184183567762, 0.001290497137233615, 0.0014949421165511012, 0.0030524602625519037, 0.00617641257122159, 0.003993147984147072, 0.002994519891217351, 0.008827606216073036, 0.009542392566800117, 0.010477352887392044, 0.021451443433761597, 0.062213558703660965, 0.026861032471060753, 0.03390643745660782, 0.11987607926130295, 0.05027468875050545, 0.026796849444508553, 0.03116568736732006, 0.10728628933429718, 0.4436681270599365]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10520488768815994, 0.8947951793670654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03907214477658272, 0.0020172251388430595, 0.9589105248451233, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015578627586364746, 0.000839252898003906, 0.0006979765021242201, 0.9828841090202332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008856466971337795, 9.934287845680956e-06, 1.1174843166372739e-05, 0.00030247055110521615, 0.9908198714256287, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3544497787952423, 0.0305892676115036, 0.05988960340619087, 0.022903529927134514, 0.047475915402173996, 0.48469194769859314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.044769011437892914, 0.0015664660604670644, 0.0003773849457502365, 0.00025073293363675475, 0.00040889650699682534, 0.00026065585552714765, 0.952366828918457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09058350324630737, 0.0011470741592347622, 0.0060273464769124985, 0.0005468479357659817, 0.001709422329440713, 0.0037850849330425262, 0.0026845429092645645, 0.8935161232948303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006010731682181358, 2.428904736007098e-05, 0.00031266716541722417, 1.868290019046981e-05, 0.0002979242999572307, 9.904515536618419e-06, 6.619554824283114e-06, 7.912206569926639e-07, 0.9933184385299683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0045468187890946865, 0.00020019362273160368, 0.0002992024237755686, 0.001336391898803413, 0.0003267655265517533, 8.741358215047512e-07, 1.7415721231373027e-05, 2.7834167326545867e-07, 0.00029665298643521965, 0.9929754734039307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12262556701898575, 0.023926571011543274, 0.03827652707695961, 0.01617196388542652, 0.030366230756044388, 0.2937593460083008, 0.10661351680755615, 0.0705995187163353, 0.04190010204911232, 0.01783309504389763, 0.2379276007413864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0008121061837300658, 0.00011546615860424936, 0.00013500892964657396, 5.539286939892918e-05, 0.00013174118066672236, 1.0027158623415744e-06, 1.3799076441500802e-06, 1.6001598623915925e-07, 1.8972953057527775e-06, 5.419655622063146e-07, 4.753091502607276e-07, 0.9987448453903198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0013333045644685626, 0.00010533037857385352, 0.0007669601473025978, 0.0009021877776831388, 3.570836042854353e-06, 8.120475740724942e-07, 1.403809051225835e-07, 9.56129397877703e-08, 1.6865070620042388e-06, 2.9789011023240164e-05, 4.381340659165289e-07, 1.1965798876190092e-06, 0.9968544840812683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08159801363945007, 0.02138885296881199, 0.028877170756459236, 0.012675784528255463, 0.02493157796561718, 0.22996489703655243, 0.1040123701095581, 0.06472097337245941, 0.034600939601659775, 0.015198715031147003, 0.1856415718793869, 0.020528046414256096, 0.005003849510103464, 0.170857235789299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0013488875702023506, 8.921194239519536e-05, 0.000685996375977993, 0.0006963209598325193, 2.1248602934065275e-05, 3.7633867577824276e-07, 6.226732125469425e-07, 4.307212293497287e-07, 7.091874067555182e-06, 0.0013103681849315763, 1.6113720846533397e-07, 9.548743946652394e-07, 0.00016453607531730086, 1.1531915333762299e-07, 0.9956737160682678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010867511155083776, 0.00040724765858612955, 0.00010700341954361647, 0.000678271462675184, 0.00011028484004782513, 1.3184225622353551e-07, 2.660271150034532e-07, 4.6195683012228983e-07, 8.409730980929453e-06, 0.0007784883491694927, 5.109439982220465e-08, 8.792070502749993e-07, 4.9342852435074747e-05, 3.4893165690164096e-08, 0.000114411988761276, 0.9966580867767334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05868089199066162, 0.018785733729600906, 0.024067318066954613, 0.011013144627213478, 0.02145637758076191, 0.1911056935787201, 0.09902717173099518, 0.060658663511276245, 0.03016272373497486, 0.014801906421780586, 0.15370333194732666, 0.016615163534879684, 0.0043853819370269775, 0.14085334539413452, 0.01501499954611063, 0.005390208680182695, 0.13427796959877014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07323038578033447, 0.028374578803777695, 0.021058257669210434, 0.007611887063831091, 0.010053583420813084, 0.06553954631090164, 0.1455976814031601, 0.08620846271514893, 0.01024126447737217, 0.0074257394298911095, 0.045262716710567474, 0.00662145996466279, 0.0011621782323345542, 0.03923855721950531, 0.008256876841187477, 0.003065689466893673, 0.036122649908065796, 0.4049285352230072, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.944500976009294e-05, 1.8382105508862878e-06, 3.7134324060161816e-08, 1.557527866680175e-05, 3.4723757380561437e-06, 1.3165046830465599e-09, 2.7038657535172206e-08, 1.718662012706318e-08, 9.2322629541286e-08, 1.350637921859743e-05, 4.4787801245504966e-10, 2.0416692780855783e-09, 5.542018044479846e-08, 3.063855003038185e-10, 4.2177114778496616e-07, 7.065867521305336e-06, 2.4244301011222547e-10, 1.4397331105087119e-09, 0.9998784065246582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002934500575065613, 0.0005883863777853549, 0.004250314552336931, 0.004028473515063524, 0.00011592977534746751, 4.331634045229293e-06, 6.773919267288875e-06, 7.076480687828735e-05, 0.00024952771491371095, 0.0003159341576974839, 2.082445462292526e-06, 4.409225221024826e-05, 0.0003044698678422719, 1.4702602584293345e-06, 0.00019761378644034266, 0.0013599281664937735, 1.2478686812755768e-06, 6.875201052025659e-06, 0.00019261165289208293, 0.9853246808052063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0405653677880764, 0.017898330464959145, 0.020600976422429085, 0.009821103885769844, 0.01788281463086605, 0.15654000639915466, 0.09208228439092636, 0.05628824234008789, 0.02666134014725685, 0.014471275731921196, 0.12537623941898346, 0.013986770063638687, 0.003927926532924175, 0.11453618109226227, 0.013395378366112709, 0.004846667870879173, 0.10880251228809357, 0.04953394830226898, 0.005186409689486027, 0.004420872312039137, 0.10317535698413849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024536319077014923, 0.0031243376433849335, 0.0009699301444925368, 4.6315424697240815e-05, 0.00013434777793008834, 0.0006453940295614302, 0.011668842285871506, 0.00032713435939513147, 0.0004573049955070019, 2.3976073862286285e-05, 0.00034454185515642166, 4.996423376724124e-05, 2.575737926235888e-05, 0.0002821774687618017, 6.525323442474473e-06, 4.981808615411865e-06, 0.00023554022482130677, 0.0002664511266630143, 2.5311152057838626e-05, 2.976109135488514e-05, 0.00018809246830642223, 0.9566068649291992, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0020759969484061003, 0.00014591761282645166, 5.289893306326121e-05, 4.2180658056167886e-05, 4.7387107770191506e-05, 4.1423194829803833e-07, 0.00012964275083504617, 2.4250975911854766e-05, 1.8034011191048194e-06, 1.4839239383945824e-06, 1.4489953059637628e-07, 4.199924660497345e-06, 4.106825457483865e-08, 1.0260462346423083e-07, 8.285448984679533e-07, 5.7818925824904e-07, 7.695144432773304e-08, 6.669597496511415e-08, 6.472609675256535e-05, 1.5700858284617425e-06, 5.641820521873342e-08, 4.403023922350258e-06, 0.9974013566970825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005159099819138646, 0.00011814597382908687, 3.2705549529055133e-05, 0.00021188679966144264, 4.5635159040102735e-05, 2.9248755595290277e-07, 3.0579308258893434e-06, 7.607346219629108e-08, 0.000137536451802589, 0.0005283522768877447, 1.1575992431289706e-07, 4.028569492220413e-06, 2.0792908799194265e-06, 8.805391615851477e-08, 0.00010051658318843693, 4.4316107960185036e-05, 6.963698950812613e-08, 9.373004417057018e-08, 3.337762609589845e-05, 1.5888857888057828e-05, 5.610664643995733e-08, 7.05262834799214e-08, 9.389261322212406e-06, 0.9981963038444519, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0691523477435112, 0.0140320910140872, 0.005599102005362511, 0.0012576858280226588, 0.0008468004525639117, 0.009601176716387272, 0.008965776301920414, 0.052476946264505386, 0.0002502838906366378, 0.0009063857141882181, 0.005419907625764608, 0.0007309210486710072, 0.0001918795460369438, 0.004396581556648016, 0.005964719224721193, 0.00035585390287451446, 0.0038770181126892567, 0.009727220050990582, 0.001102349371649325, 0.0003644291136879474, 0.003413958242163062, 0.003052355023100972, 0.005698255263268948, 0.0002955732343252748, 0.7923204302787781, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010461597703397274, 1.955721563717816e-05, 1.7359042203679564e-06, 3.103058406850323e-05, 2.7308056814945303e-05, 1.0180717602281675e-08, 4.815781835532107e-07, 1.7494296855602443e-07, 7.3124517996348e-08, 7.983091450114443e-07, 3.464323272694969e-09, 4.906740741716931e-06, 1.0718952836441531e-07, 2.35255281921809e-09, 2.3834166995584383e-07, 1.3731373655900825e-06, 1.8288706105096253e-09, 6.247633965728028e-09, 9.208364645019174e-06, 1.6384317405027105e-06, 1.2523946324449753e-09, 8.27128976421676e-10, 8.456793693767395e-06, 3.1186914384306874e-06, 9.241437837204103e-09, 0.9988435506820679, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010544945253059268, 0.00021373217168729752, 0.0002815716725308448, 0.00113733671605587, 0.00014783968799747527, 2.0068493995495373e-06, 4.831355909118429e-06, 3.482335159787908e-06, 5.100349881104194e-06, 0.000124204860185273, 9.301510885961761e-07, 1.058263296727091e-05, 1.1688275662891101e-05, 7.077505301822384e-07, 0.0034115940798074007, 0.00019905276712961495, 5.995612468723266e-07, 4.6430378120021487e-07, 1.9585138943511993e-05, 0.00011087791790487245, 4.7500583377768635e-07, 3.2808816285978537e-07, 4.535354491963517e-06, 5.161709486856125e-05, 3.2474736144649796e-07, 1.3071360626781825e-05, 0.9931889772415161, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02420077472925186, 0.0028201299719512463, 0.004319300409406424, 0.0009108305675908923, 0.0017753951251506805, 0.003809915855526924, 0.002953325165435672, 0.0167147908359766, 0.0013931754510849714, 0.005003185477107763, 0.002276089508086443, 0.000587641610763967, 0.0009901636512950063, 0.0018066938500851393, 0.003131241537630558, 0.00023389386478811502, 0.0016082727815955877, 0.009910304099321365, 0.002853953745216131, 0.00020495163334999233, 0.001371265621855855, 0.006919005420058966, 0.0010336586274206638, 0.00014528397878166288, 0.01748979091644287, 0.00046553160063922405, 0.00030240879277698696, 0.884769082069397, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005256084259599447, 3.528643219397054e-06, 1.703766429272946e-06, 9.408168261870742e-05, 0.6647974252700806, 1.6531473079339776e-07, 9.51110109781439e-07, 8.886889304449141e-07, 1.701670953480061e-05, 3.742182161659002e-05, 6.832264176637182e-08, 9.81090579443844e-06, 7.548720759587013e-08, 4.963250432865607e-08, 2.0393883914948674e-06, 7.686544449825305e-06, 4.0668499678986336e-08, 2.6744308101456227e-08, 3.3431806514272466e-05, 4.3410815919742163e-07, 3.007987459113792e-08, 3.2060558652347027e-08, 4.900573458144208e-06, 3.0609417080995627e-06, 1.4603192433071399e-08, 2.214551204815507e-05, 9.21116861718474e-06, 3.1642709785728584e-08, 0.33442816138267517, 0.0, 0.0, 0.0, 0.0], [0.004677004646509886, 0.0002802134840749204, 8.346102549694479e-05, 3.1570123155688634e-06, 4.065346672632586e-07, 1.3343500882001536e-07, 2.6423611416248605e-05, 1.1439977498639564e-07, 2.787237463053316e-07, 3.7496099594136467e-06, 4.652897445112103e-08, 1.721399939924595e-06, 1.8165600579322927e-07, 3.148475968828279e-08, 1.8334230844629928e-07, 5.2147463236451586e-08, 2.5215808108214333e-08, 3.078440968806717e-08, 7.142029545548212e-08, 1.6640171907056356e-08, 1.7768222448921733e-08, 8.634525272555038e-08, 2.80096719507128e-06, 8.454143767266942e-07, 3.098357126418705e-08, 2.927866091795295e-07, 5.67622805647261e-07, 5.055421414823513e-09, 2.9141034474378102e-08, 0.9949179887771606, 0.0, 0.0, 0.0], [5.636792411678471e-05, 0.0002002374967560172, 1.6319110045515117e-06, 1.5089327689565835e-06, 1.7779768313630484e-05, 5.95644145118257e-10, 6.94038226356497e-06, 5.034010541749012e-09, 2.1682893702745787e-07, 1.7164256860269234e-06, 1.9326265587871205e-10, 1.8911425314627195e-08, 9.538840117784275e-08, 1.2946883842790413e-10, 8.07715050399338e-09, 4.386615546536632e-05, 9.768665043541347e-11, 5.256080015669795e-10, 6.93216934450902e-05, 7.505880716962565e-08, 7.069290985928234e-11, 3.988046870517792e-08, 1.0610266144794878e-05, 2.2120727862784406e-06, 8.688617048058234e-10, 9.928487088473048e-06, 5.390094592883088e-09, 1.1354458345769203e-10, 3.0600433547078865e-06, 3.8945626101849484e-07, 0.9995738863945007, 0.0, 0.0], [0.0003556974115781486, 1.9489458281896077e-05, 9.160975423583295e-06, 1.3085226783005055e-05, 2.3808830519556068e-05, 2.9718961513935938e-08, 4.1605944716138765e-05, 1.7756491388354334e-07, 6.896235049680399e-07, 1.050622017828573e-06, 1.2230765733534099e-08, 4.290539891371736e-06, 3.2958240581137943e-07, 9.211071905212975e-09, 1.7466379631514428e-06, 4.682780854636803e-06, 7.44272554698e-09, 9.673800427378865e-09, 3.9665097574470565e-05, 7.324884450099489e-07, 5.5436903956262995e-09, 1.0396686178637538e-07, 1.4401590306079015e-05, 8.873331353242975e-06, 5.9894045278952035e-09, 1.5627783795935102e-05, 2.981124680445646e-06, 6.874342872720263e-09, 4.854650796914939e-06, 7.0722649070376065e-06, 6.210680112417322e-06, 0.999423623085022, 0.0], [0.05455268174409866, 0.016429055482149124, 0.01600833609700203, 0.006986877880990505, 0.024884145706892014, 0.07376931607723236, 0.07933785766363144, 0.05594551935791969, 0.02726820856332779, 0.013368774205446243, 0.055903077125549316, 0.007223024964332581, 0.005426575895398855, 0.05012328177690506, 0.008279063738882542, 0.0030609651003032923, 0.04682298004627228, 0.047518469393253326, 0.00284494343213737, 0.007037975825369358, 0.04282715171575546, 0.051381900906562805, 0.02728237584233284, 0.026375344023108482, 0.02615921013057232, 0.011997979134321213, 0.006220123264938593, 0.03648780658841133, 0.01112469844520092, 0.005218563135713339, 0.0025592001620680094, 0.002604028908535838, 0.14697043597698212]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9192657470703125, 0.08073429018259048, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4543737471103668, 0.42650437355041504, 0.11912190169095993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5267522931098938, 0.2232162356376648, 0.12420623749494553, 0.12582524120807648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39034879207611084, 0.1709941178560257, 0.06872710585594177, 0.18371818959712982, 0.1862117350101471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1974421739578247, 0.2543684244155884, 0.1448846310377121, 0.18925857543945312, 0.20821942389011383, 0.0058267852291464806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19473567605018616, 0.13241828978061676, 0.14391931891441345, 0.1512073427438736, 0.30024465918540955, 0.020584644749760628, 0.05688999220728874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.126966655254364, 0.21597377955913544, 0.1608932763338089, 0.1969882994890213, 0.1884462684392929, 0.013544926419854164, 0.07520709931850433, 0.021979715675115585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.291212260723114, 0.059542279690504074, 0.11079410463571548, 0.09717857092618942, 0.22345605492591858, 0.016262579709291458, 0.08719442039728165, 0.024762261658906937, 0.08959741145372391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22981958091259003, 0.038026776164770126, 0.160138338804245, 0.11780403554439545, 0.1618119180202484, 0.03552818298339844, 0.07561115175485611, 0.020756017416715622, 0.10670632123947144, 0.053797684609889984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1331443041563034, 0.1885865330696106, 0.10808101296424866, 0.15994970500469208, 0.17739209532737732, 0.003598014358431101, 0.02506207674741745, 0.012862928211688995, 0.07453099638223648, 0.11275240778923035, 0.004039985593408346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.167464017868042, 0.1435522735118866, 0.061185725033283234, 0.17358075082302094, 0.10113829374313354, 0.01755346730351448, 0.03239528089761734, 0.007995491847395897, 0.05453447997570038, 0.07883201539516449, 0.01725820265710354, 0.1445099264383316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2699681520462036, 0.13029073178768158, 0.06605684757232666, 0.06156139820814133, 0.08437128365039825, 0.019846616312861443, 0.016312789171934128, 0.012965921312570572, 0.03231465443968773, 0.05254793539643288, 0.019868606701493263, 0.1369563788175583, 0.09693866968154907, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09820347279310226, 0.1361863911151886, 0.08005785197019577, 0.12152862548828125, 0.1357938051223755, 0.0024323563557118177, 0.017789501696825027, 0.009086486883461475, 0.05637528374791145, 0.08521634340286255, 0.002753336215391755, 0.1520378738641739, 0.09946723282337189, 0.003071403130888939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1701289266347885, 0.08885715156793594, 0.09089689701795578, 0.08085784316062927, 0.11427336931228638, 0.01090148277580738, 0.014788416214287281, 0.0054973699152469635, 0.05151257663965225, 0.05330682918429375, 0.010595808736979961, 0.0944228246808052, 0.1309812068939209, 0.01115368027240038, 0.07182563096284866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.103658527135849, 0.03588540107011795, 0.08803563565015793, 0.060879360884428024, 0.08348328620195389, 0.03080574981868267, 0.029615940526127815, 0.010918696410953999, 0.04049994423985481, 0.04288605973124504, 0.03219295293092728, 0.1500813364982605, 0.12658780813217163, 0.034902188926935196, 0.05825437605381012, 0.0713128000497818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0704709142446518, 0.09600996226072311, 0.05621582269668579, 0.0869988352060318, 0.09934128820896149, 0.0016298776026815176, 0.01240861788392067, 0.006380435544997454, 0.041014041751623154, 0.06348711997270584, 0.0018482193117961287, 0.11387643218040466, 0.07328981161117554, 0.002071293769404292, 0.07246166467666626, 0.20012786984443665, 0.002367777982726693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.056594423949718475, 0.08906204998493195, 0.047032430768013, 0.09457871317863464, 0.08793891221284866, 0.001972164260223508, 0.017767684534192085, 0.005990440491586924, 0.06014855206012726, 0.08834963291883469, 0.002263767411932349, 0.10461527109146118, 0.06079372763633728, 0.002556623425334692, 0.07818624377250671, 0.19496025145053864, 0.002929993672296405, 0.004259060136973858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.159706249833107, 0.026096459478139877, 0.04515179246664047, 0.03497577831149101, 0.08030678331851959, 0.05469036474823952, 0.04078544303774834, 0.026513004675507545, 0.027251940220594406, 0.039198171347379684, 0.053514327853918076, 0.0484292097389698, 0.0626426711678505, 0.05558210611343384, 0.05559666082262993, 0.04792959615588188, 0.05676325038075447, 0.048923008143901825, 0.03594321012496948, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08663120865821838, 0.09557435661554337, 0.03673810139298439, 0.06946706026792526, 0.056814610958099365, 0.008190208114683628, 0.022195827215909958, 0.007642820477485657, 0.031468283385038376, 0.0755520835518837, 0.008965260349214077, 0.05263481289148331, 0.044911064207553864, 0.00993504747748375, 0.04481375962495804, 0.15198466181755066, 0.010933397337794304, 0.007993672043085098, 0.16402560472488403, 0.013528089970350266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04783450439572334, 0.06669352948665619, 0.03798922151327133, 0.06040368974208832, 0.06899043917655945, 0.0010267274919897318, 0.008172677829861641, 0.004158171825110912, 0.028268275782465935, 0.044072382152080536, 0.001158646191470325, 0.07832911610603333, 0.050829000771045685, 0.0013004970969632268, 0.04904298111796379, 0.14145003259181976, 0.0014934330247342587, 0.0025566823314875364, 0.17534081637859344, 0.12910202145576477, 0.0017870542360469699, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04114088416099548, 0.04766073450446129, 0.03586999699473381, 0.06666101515293121, 0.07969272881746292, 0.0023650778457522392, 0.020340194925665855, 0.004854496102780104, 0.06436203420162201, 0.06737150996923447, 0.0027073684614151716, 0.055960532277822495, 0.056486647576093674, 0.003076723776757717, 0.053543880581855774, 0.15165933966636658, 0.0035397191531956196, 0.004673931282013655, 0.1640271693468094, 0.05968153104186058, 0.004154942464083433, 0.010169513523578644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0662880539894104, 0.04092540591955185, 0.02732267789542675, 0.045053672045469284, 0.06575216352939606, 0.01565755158662796, 0.027881883084774017, 0.013711248524487019, 0.03174295276403427, 0.05280745029449463, 0.015447767451405525, 0.032181113958358765, 0.032901059836149216, 0.016298862174153328, 0.02663664147257805, 0.09772850573062897, 0.017114197835326195, 0.0169194545596838, 0.09847064316272736, 0.047879092395305634, 0.018412547186017036, 0.015331598930060863, 0.17753542959690094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09801428020000458, 0.026328807696700096, 0.035868145525455475, 0.05713058263063431, 0.06943872570991516, 0.01212895568460226, 0.02090909518301487, 0.008747953921556473, 0.02699965052306652, 0.03726676478981972, 0.01171633880585432, 0.08499540388584137, 0.055013373494148254, 0.012196715921163559, 0.035639114677906036, 0.08789661526679993, 0.012970106676220894, 0.01085102278739214, 0.06408385187387466, 0.059639208018779755, 0.014492185786366463, 0.006093737669289112, 0.09761442244052887, 0.05396495759487152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.027693239971995354, 0.040737707167863846, 0.03122355230152607, 0.05879037827253342, 0.05601825937628746, 0.0015714785549789667, 0.011908049695193768, 0.0033397923689335585, 0.05176554620265961, 0.052912432700395584, 0.0018259822390973568, 0.060300346463918686, 0.02835717797279358, 0.0020878107752650976, 0.050864774733781815, 0.07898838073015213, 0.002398707205429673, 0.002904823748394847, 0.11135736107826233, 0.0458601638674736, 0.002884918823838234, 0.011431250721216202, 0.1234055906534195, 0.13488471508026123, 0.006487554870545864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1539076715707779, 0.023786786943674088, 0.05320247262716293, 0.039638858288526535, 0.05711062625050545, 0.015628939494490623, 0.020206080749630928, 0.009252365678548813, 0.021311869844794273, 0.029029950499534607, 0.014741908758878708, 0.06123840808868408, 0.10112593322992325, 0.01515782717615366, 0.04335403069853783, 0.040907204151153564, 0.015732651576399803, 0.02007342129945755, 0.053749311715364456, 0.03468617424368858, 0.016989391297101974, 0.006368501577526331, 0.040420182049274445, 0.031060412526130676, 0.01393716037273407, 0.06738190352916718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08555091917514801, 0.03505741432309151, 0.05885257199406624, 0.03497910127043724, 0.05178741738200188, 0.002511990023776889, 0.0041512236930429935, 0.0020859187934547663, 0.014081122353672981, 0.024491356685757637, 0.00237600551918149, 0.09535115957260132, 0.07766137272119522, 0.0024908825289458036, 0.04572679474949837, 0.05774116516113281, 0.0026603781152516603, 0.003347759833559394, 0.04799826443195343, 0.026788828894495964, 0.002958715660497546, 0.0046557895839214325, 0.036070987582206726, 0.021599190309643745, 0.004788636229932308, 0.2205219864845276, 0.03371305391192436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02070671133697033, 0.03719405084848404, 0.019723715260624886, 0.03894224017858505, 0.03182699903845787, 0.0012253670720383525, 0.008815755136311054, 0.00240529328584671, 0.03457954525947571, 0.047298040241003036, 0.0013953752350062132, 0.05148204788565636, 0.020486745983362198, 0.0015608381945639849, 0.03826119378209114, 0.04863754287362099, 0.0017825315007939935, 0.0025446058716624975, 0.06541351228952408, 0.0418856218457222, 0.002096060197800398, 0.00940138939768076, 0.08460032194852829, 0.09019994735717773, 0.005403279792517424, 0.22932566702365875, 0.05692273750901222, 0.0058829220943152905, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08582809567451477, 0.03967175632715225, 0.014841830357909203, 0.056536201387643814, 0.05960613861680031, 0.0069875153712928295, 0.010110095143318176, 0.002887723734602332, 0.015322854742407799, 0.025928769260644913, 0.0068304408341646194, 0.03354894369840622, 0.021093543618917465, 0.007213155273348093, 0.019323399290442467, 0.05298228561878204, 0.007658611051738262, 0.00515784602612257, 0.0652317926287651, 0.018170015886425972, 0.00853470154106617, 0.004368166904896498, 0.026912439614534378, 0.04962793365120888, 0.004404325969517231, 0.1938866674900055, 0.03933224827051163, 0.005363550502806902, 0.11263899505138397, 0.0, 0.0, 0.0, 0.0], [0.07040347903966904, 0.059261616319417953, 0.015334845520555973, 0.024139033630490303, 0.01572885550558567, 0.01949208974838257, 0.017311519011855125, 0.017303064465522766, 0.020563246682286263, 0.0451558493077755, 0.021815843880176544, 0.07079728692770004, 0.030063945800065994, 0.02354060672223568, 0.0206844974309206, 0.02116367034614086, 0.02644512988626957, 0.023540055379271507, 0.0566372349858284, 0.033694811165332794, 0.03070726804435253, 0.015993354842066765, 0.015474077314138412, 0.0308036208152771, 0.03180556744337082, 0.07969610393047333, 0.034374870359897614, 0.03453714773058891, 0.030624380335211754, 0.06290692090988159, 0.0, 0.0, 0.0], [0.05338500440120697, 0.029621530324220657, 0.021030081436038017, 0.02369570918381214, 0.03343641385436058, 0.018393803387880325, 0.024060698226094246, 0.022810012102127075, 0.013972371816635132, 0.028813567012548447, 0.01905973069369793, 0.015371969901025295, 0.02533531002700329, 0.019971946254372597, 0.014075735583901405, 0.038844525814056396, 0.02134619653224945, 0.01932143047451973, 0.05632656440138817, 0.021360019221901894, 0.023394571617245674, 0.023136626929044724, 0.06416381895542145, 0.06724690645933151, 0.0346950925886631, 0.0434902124106884, 0.030327260494232178, 0.03285713121294975, 0.053275082260370255, 0.0659981369972229, 0.0411824993789196, 0.0, 0.0], [0.1817709058523178, 0.01953316666185856, 0.028002936393022537, 0.029110195115208626, 0.04134833812713623, 0.018019482493400574, 0.01047173049300909, 0.008382907137274742, 0.015335801988840103, 0.02183944173157215, 0.016893355175852776, 0.03806138038635254, 0.03643865883350372, 0.017464272677898407, 0.026129066944122314, 0.040115050971508026, 0.0183172095566988, 0.012488226406276226, 0.05136965215206146, 0.019443852826952934, 0.019889751449227333, 0.0035764507483690977, 0.026232965290546417, 0.018429184332489967, 0.011723744682967663, 0.0327298529446125, 0.034808218479156494, 0.012035044841468334, 0.060302965342998505, 0.007873311638832092, 0.04227292165160179, 0.07958997040987015, 0.0], [0.01500339712947607, 0.020334864035248756, 0.00781344249844551, 0.016553569585084915, 0.016466114670038223, 0.0002380963123869151, 0.001959895482286811, 0.0006898263236507773, 0.006483224220573902, 0.01073406357318163, 0.0002443528501316905, 0.014634675346314907, 0.009247622452676296, 0.0002605919726192951, 0.009339914657175541, 0.04272659495472908, 0.00028863942134194076, 0.00038116759969852865, 0.05474936217069626, 0.09452767670154572, 0.0003421130240894854, 0.0017270189709961414, 0.04745934158563614, 0.026613805443048477, 0.0010238662362098694, 0.1653798222541809, 0.014187117107212543, 0.0013092365115880966, 0.04770656302571297, 0.011198500171303749, 0.22050751745700836, 0.1394260972738266, 0.00044186264858581126]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9333657622337341, 0.06663419306278229, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.32452353835105896, 0.5923717617988586, 0.083104707300663, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14159759879112244, 0.514380931854248, 0.28144127130508423, 0.0625801831483841, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2526226341724396, 0.058340635150671005, 0.1045888215303421, 0.4411159157752991, 0.14333190023899078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1805155873298645, 0.09828896820545197, 0.1087396889925003, 0.12262703478336334, 0.0999554991722107, 0.3898732364177704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17192280292510986, 0.023320937529206276, 0.12332724034786224, 0.060765013098716736, 0.05971726030111313, 0.34759166836738586, 0.21335498988628387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0962703675031662, 0.04683612659573555, 0.028257345780730247, 0.03239244595170021, 0.05865050107240677, 0.1582932472229004, 0.30996495485305786, 0.26933497190475464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09948237985372543, 0.06464175879955292, 0.02867184951901436, 0.07305674999952316, 0.029787175357341766, 0.1396002322435379, 0.20754709839820862, 0.26580220460891724, 0.09141051769256592, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0563204400241375, 0.029885875061154366, 0.013419931754469872, 0.002407551510259509, 0.013245484791696072, 0.04564542695879936, 0.05522558465600014, 0.1002708226442337, 0.65799880027771, 0.025580082088708878, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04266996681690216, 0.010426468215882778, 0.010652237571775913, 0.01344663929194212, 0.009353145025670528, 0.04015975818037987, 0.0710517019033432, 0.1373765766620636, 0.10423267632722855, 0.2173662781715393, 0.34326452016830444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.029683886095881462, 0.0025616372004151344, 0.0044074878096580505, 0.034248724579811096, 0.014238736592233181, 0.02800186164677143, 0.022288046777248383, 0.0710596814751625, 0.04026233032345772, 0.5543041825294495, 0.17333056032657623, 0.025612974539399147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04039591923356056, 0.008631567470729351, 0.005494223907589912, 0.003864137688651681, 0.023363124579191208, 0.02720697410404682, 0.02567731775343418, 0.05048515647649765, 0.0510561540722847, 0.050417810678482056, 0.14164334535598755, 0.5115286111831665, 0.060235679149627686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.028706416487693787, 0.004808458499610424, 0.004723657388240099, 0.005382596980780363, 0.0034560468047857285, 0.01447016280144453, 0.02403738722205162, 0.04162624478340149, 0.03567296266555786, 0.07060734182596207, 0.10830997675657272, 0.058116115629673004, 0.20621225237846375, 0.39387041330337524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05342649295926094, 0.011923289857804775, 0.015572250820696354, 0.002112323185428977, 0.0058510382659733295, 0.022170910611748695, 0.038184668868780136, 0.02741154097020626, 0.05464289337396622, 0.04910832643508911, 0.123283751308918, 0.05287175625562668, 0.07545655965805054, 0.3701530396938324, 0.09783122688531876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008346715942025185, 0.00027852662606164813, 0.0011786009417846799, 0.0021395485382527113, 0.002476171124726534, 0.002918292535468936, 0.004576900042593479, 0.003965593408793211, 0.0049730269238352776, 0.011347766034305096, 0.013014056719839573, 0.005545963998883963, 0.0208955816924572, 0.03838542103767395, 0.8750316500663757, 0.004926194902509451, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021700305864214897, 0.002678663469851017, 0.002383927581831813, 0.002815626095980406, 0.0015562345506623387, 0.006139403209090233, 0.00903981551527977, 0.013740858063101768, 0.012412196956574917, 0.024686496704816818, 0.0340690053999424, 0.017561456188559532, 0.060829490423202515, 0.12004058808088303, 0.11516808718442917, 0.1266368329524994, 0.42854100465774536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019681409001350403, 0.0028661920223385096, 0.0027528645005077124, 0.0023642026353627443, 0.0022205752320587635, 0.00477696442976594, 0.005015392787754536, 0.007020771503448486, 0.0066029978916049, 0.01582488790154457, 0.021779092028737068, 0.02237590402364731, 0.03905550763010979, 0.07342642545700073, 0.07227571308612823, 0.08103621006011963, 0.25563231110572815, 0.36529263854026794, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.034438684582710266, 0.0024295076727867126, 0.0027038753032684326, 0.0010108916321769357, 0.0028212442994117737, 0.009310654364526272, 0.007474057842046022, 0.010526394471526146, 0.019342610612511635, 0.006583379115909338, 0.03052523173391819, 0.008166540414094925, 0.023945633322000504, 0.08047981560230255, 0.04428933188319206, 0.04886505752801895, 0.23266322910785675, 0.38709738850593567, 0.04732643440365791, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0036976796109229326, 0.0064509655348956585, 0.0004921727231703699, 0.00030695926398038864, 0.00012400785635691136, 0.0010727376211434603, 0.0008858796209096909, 0.0013806353090330958, 0.0008200184092856944, 0.00027311863959766924, 0.002783061470836401, 0.03529426082968712, 0.003561372635886073, 0.007148307748138905, 0.001647408353164792, 0.016731644049286842, 0.019172830507159233, 0.022339239716529846, 0.8733668327331543, 0.0024509585928171873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013628782704472542, 0.0014384430833160877, 0.0012188631808385253, 0.001291585387662053, 0.00061180250486359, 0.00214003655128181, 0.002746960148215294, 0.0033360449597239494, 0.0030918733682483435, 0.0059889135882258415, 0.00723721319809556, 0.003547741798684001, 0.012891959398984909, 0.022229162976145744, 0.02082422375679016, 0.026295319199562073, 0.07648168504238129, 0.1626145839691162, 0.1263865828514099, 0.10034429281949997, 0.4056539535522461, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02143297716975212, 0.0007291641086339951, 0.0010889690602198243, 0.0008559610578231514, 0.0010556622873991728, 0.002354246564209461, 0.001863330602645874, 0.002486985642462969, 0.004011374898254871, 0.0036456298548728228, 0.00663661677390337, 0.0024591649416834116, 0.008106634020805359, 0.019501395523548126, 0.01394551433622837, 0.016831588000059128, 0.06727852672338486, 0.10203754156827927, 0.07506174594163895, 0.03785502165555954, 0.34741589426994324, 0.2633460462093353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018374430015683174, 0.0016340144211426377, 0.0002648663939908147, 0.0006277090287767351, 0.0007212907075881958, 0.0022947133984416723, 0.0014375776518136263, 0.0024335694033652544, 0.001022504991851747, 0.002173098735511303, 0.005665965843945742, 0.0005857065552845597, 0.004730310756713152, 0.015789609402418137, 0.009121064096689224, 0.006447882391512394, 0.04965192824602127, 0.07221108675003052, 0.04530428349971771, 0.022536247968673706, 0.23380516469478607, 0.2810094356536865, 0.2221575230360031, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016010282561182976, 0.00041907670674845576, 0.0016793166287243366, 0.0020331651903688908, 0.001112604746595025, 0.002304120920598507, 0.0016414872370660305, 0.002045227447524667, 0.0008826442644931376, 0.003531813155859709, 0.004660748410969973, 0.0011461268877610564, 0.0040252795442938805, 0.011729458346962929, 0.006906011141836643, 0.005978971719741821, 0.03413613513112068, 0.05391993746161461, 0.07536923885345459, 0.015544150955975056, 0.15307289361953735, 0.21672506630420685, 0.23267336189746857, 0.15245288610458374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016415491700172424, 0.0010880987392738461, 0.0013027036329731345, 0.001233563176356256, 0.0010325232287868857, 0.0013605270069092512, 0.0011352720903232694, 0.0009713192121125758, 0.001758021884597838, 0.0023549937177449465, 0.0022677970118820667, 0.0026170003693550825, 0.0032849623821675777, 0.005564447958022356, 0.007287738379091024, 0.006582648493349552, 0.01691109873354435, 0.023348167538642883, 0.033363789319992065, 0.0120608601719141, 0.08410528302192688, 0.10776980221271515, 0.12741322815418243, 0.2500956058502197, 0.2886750400066376, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.031117744743824005, 0.0015063051832839847, 0.001083932351320982, 0.002421521581709385, 0.0013826879439875484, 0.0037937189918011427, 0.0016339285066351295, 0.003119518281891942, 0.0012812626082450151, 0.0020685228519141674, 0.004760123323649168, 0.0008757315226830542, 0.008592117577791214, 0.009353641420602798, 0.011993247084319592, 0.005962998140603304, 0.02202821709215641, 0.03411329910159111, 0.009586771950125694, 0.013681817799806595, 0.08417052775621414, 0.08917819708585739, 0.10806845873594284, 0.1556077003479004, 0.37236857414245605, 0.02024947851896286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.014838477596640587, 0.000575731392018497, 0.0047436547465622425, 0.00045677294838242233, 0.0007412272389046848, 0.0014999984996393323, 0.0008866075659170747, 0.0008452081237919629, 0.00010359247244196013, 0.0009065139456652105, 0.0018096774583682418, 0.060291070491075516, 0.0015377565287053585, 0.0033079434651881456, 0.0013713666703552008, 0.0020826756954193115, 0.00864399690181017, 0.00908886268734932, 0.007760948967188597, 0.005808332469314337, 0.03386512026190758, 0.03987189754843712, 0.053745534271001816, 0.03694772720336914, 0.12259428948163986, 0.5718705654144287, 0.013804461807012558, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018570004031062126, 0.001214314834214747, 0.0012880462454631925, 0.0010612563928589225, 0.0007490042480640113, 0.0010485613020136952, 0.0008687864174135029, 0.0005973855149932206, 0.0012938276631757617, 0.0014042491093277931, 0.0011055080685764551, 0.0005003443802706897, 0.0020262575708329678, 0.0021463108714669943, 0.002873790916055441, 0.002641367493197322, 0.005802980158478022, 0.00819135271012783, 0.00833907164633274, 0.005543302278965712, 0.02655869536101818, 0.03308916091918945, 0.03250738978385925, 0.09199853241443634, 0.10410477966070175, 0.16861769556999207, 0.20895430445671082, 0.26690366864204407, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01665443368256092, 0.00072486512362957, 0.0008980674901977181, 0.003161684377118945, 0.0005522819701582193, 0.0016607240540906787, 0.0007486115791834891, 0.0009652787121012807, 0.0003842800797428936, 0.002257774816825986, 0.0015545623609796166, 0.0007036992465145886, 0.0014688160736113787, 0.0027998806908726692, 0.0030139745213091373, 0.005369033198803663, 0.006552340462803841, 0.0087015675380826, 0.007138855289667845, 0.006516315974295139, 0.026185564696788788, 0.03929200395941734, 0.031550053507089615, 0.024343017488718033, 0.10670771449804306, 0.15159796178340912, 0.13674210011959076, 0.32013967633247375, 0.09161487221717834, 0.0, 0.0, 0.0, 0.0], [0.03722681477665901, 0.000744272954761982, 0.001918031251989305, 0.001429059891961515, 0.00255973101593554, 0.0032928287982940674, 0.0009007241460494697, 0.0015445075696334243, 0.00035572113119997084, 0.0004492724547162652, 0.00266881356947124, 0.001404664828442037, 0.0017281001200899482, 0.0045427302829921246, 0.0012941044988110662, 0.004677655175328255, 0.009138202294707298, 0.008992942050099373, 0.005343649536371231, 0.0020318408496677876, 0.030930889770388603, 0.021215278655290604, 0.036399755626916885, 0.056794602423906326, 0.11195952445268631, 0.011458119377493858, 0.03353290632367134, 0.2658853828907013, 0.24695426225662231, 0.09262567013502121, 0.0, 0.0, 0.0], [0.04408876225352287, 0.001108294352889061, 0.0033875873778015375, 0.0048531824722886086, 0.0028643254190683365, 0.004500851966440678, 0.0014518089592456818, 0.002192496554926038, 0.0007902360521256924, 0.0006717371288686991, 0.0035771559923887253, 0.0005131770740263164, 0.012861708179116249, 0.005116846412420273, 0.0030142529867589474, 0.005887457635253668, 0.010453438386321068, 0.013818331062793732, 0.008691059425473213, 0.011229281313717365, 0.0314008928835392, 0.023181650787591934, 0.03044440597295761, 0.035206787288188934, 0.09999871999025345, 0.006090168841183186, 0.14714208245277405, 0.16393038630485535, 0.12749525904655457, 0.19357767701148987, 0.0004599914245773107, 0.0, 0.0], [0.0371740460395813, 0.005006891209632158, 0.001611231011338532, 0.0028301456477493048, 0.0005118506960570812, 0.0027071244549006224, 0.0020970292389392853, 0.00123287970200181, 0.0006310886819846928, 0.0017632452072575688, 0.0017868784489110112, 0.0002528328914195299, 0.0010720744030550122, 0.0026448301505297422, 0.001566156861372292, 0.0038084066472947598, 0.005276741925626993, 0.00693025765940547, 0.013310822658240795, 0.0035816472955048084, 0.01830451190471649, 0.026684748008847237, 0.01997152902185917, 0.032155733555555344, 0.07432045787572861, 0.02392224408686161, 0.08761470019817352, 0.1800754964351654, 0.027492599561810493, 0.059722479432821274, 0.19122706353664398, 0.16271227598190308, 0.0], [0.008116928860545158, 0.0008723047212697566, 0.0003707280848175287, 0.000473485590191558, 0.00017832992307376117, 0.0003994707658421248, 0.00029511755565181375, 0.00018311967141926289, 0.00016714565572328866, 0.00023702485486865044, 0.00025333566009067, 0.00012855020759161562, 0.00020213171956129372, 0.00039944867603480816, 0.00016511800640728325, 0.00046228672727011144, 0.0008780235075391829, 0.0011140466667711735, 0.0020708779338747263, 0.001963674323633313, 0.0035278580617159605, 0.004475219640880823, 0.004463491961359978, 0.007312541361898184, 0.014446226879954338, 0.03503049165010452, 0.020014144480228424, 0.043885815888643265, 0.0194367878139019, 0.11325745284557343, 0.07277626544237137, 0.16196811199188232, 0.4804743826389313]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9473748207092285, 0.05262519419193268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8785884380340576, 0.055394649505615234, 0.06601689755916595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7270771265029907, 0.1370987445116043, 0.04866088926792145, 0.08716321736574173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4651746451854706, 0.1342930644750595, 0.1535816788673401, 0.1747254878282547, 0.0722251608967781, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17035967111587524, 0.01184193603694439, 0.023650838062167168, 0.021745804697275162, 0.025856323540210724, 0.7465453743934631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14214570820331573, 0.04383270442485809, 0.05021180957555771, 0.045165035873651505, 0.05872130021452904, 0.511153519153595, 0.14876997470855713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08473348617553711, 0.020369818434119225, 0.037461623549461365, 0.03195910155773163, 0.03419601544737816, 0.4350069463253021, 0.1189405769109726, 0.23733240365982056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3423079550266266, 0.03593634441494942, 0.07259216159582138, 0.10352766513824463, 0.08196531236171722, 0.07694562524557114, 0.14196321368217468, 0.09896712005138397, 0.045794617384672165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.37114864587783813, 0.06278744339942932, 0.05806949734687805, 0.055662766098976135, 0.13124842941761017, 0.07535628229379654, 0.10726623982191086, 0.07924024015665054, 0.030107339844107628, 0.029113223776221275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06430105119943619, 0.005169104319065809, 0.01101298164576292, 0.009054876863956451, 0.011748064309358597, 0.31885024905204773, 0.03684945032000542, 0.08319542557001114, 0.012068144045770168, 0.01467620488256216, 0.4330744445323944, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23777922987937927, 0.03812997788190842, 0.019743354991078377, 0.0750802680850029, 0.14420796930789948, 0.062449246644973755, 0.07018381357192993, 0.06523611396551132, 0.04883222281932831, 0.034600336104631424, 0.06439773738384247, 0.13935981690883636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2901448607444763, 0.04085763916373253, 0.06965623050928116, 0.06467736512422562, 0.11515604704618454, 0.07279440015554428, 0.05406035855412483, 0.04095995053648949, 0.03646121919155121, 0.03709696605801582, 0.08112155646085739, 0.06249445304274559, 0.034518949687480927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04191604629158974, 0.00338806607760489, 0.00708235427737236, 0.005899201612919569, 0.007586190477013588, 0.20389807224273682, 0.023296764120459557, 0.05173070728778839, 0.00781681202352047, 0.009731385856866837, 0.27760201692581177, 0.008386759087443352, 0.016172701492905617, 0.33549293875694275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1512935310602188, 0.04240790382027626, 0.04383379966020584, 0.09706762433052063, 0.14943550527095795, 0.04439878091216087, 0.06174500659108162, 0.041995152831077576, 0.018608782440423965, 0.031412459909915924, 0.05092645809054375, 0.06660285592079163, 0.094162218272686, 0.05761292949318886, 0.04849696904420853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29958033561706543, 0.07432074099779129, 0.030061950907111168, 0.016736464574933052, 0.03856483846902847, 0.051068708300590515, 0.09408655017614365, 0.05606793239712715, 0.05458230897784233, 0.04522043839097023, 0.05638071149587631, 0.015378035604953766, 0.04082852602005005, 0.06084693595767021, 0.03081105835735798, 0.035464461892843246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.030439969152212143, 0.0024933929089456797, 0.005298203323036432, 0.004223390016704798, 0.005517448764294386, 0.14508461952209473, 0.016034148633480072, 0.03598649054765701, 0.0057580494321882725, 0.007398172281682491, 0.1961347907781601, 0.0060908859595656395, 0.011465121060609818, 0.23737995326519012, 0.008031773380935192, 0.005861478857696056, 0.2768021523952484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015668924897909164, 0.0019133499590680003, 0.0067479307763278484, 0.005610877647995949, 0.006710363551974297, 0.10858529061079025, 0.013436978682875633, 0.030674783512949944, 0.008698036894202232, 0.005958769004791975, 0.15696421265602112, 0.006401257123798132, 0.014357196167111397, 0.19220459461212158, 0.009938814677298069, 0.008154558017849922, 0.22861388325691223, 0.17936018109321594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2751207649707794, 0.046356093138456345, 0.025782734155654907, 0.02037108689546585, 0.045191291719675064, 0.04741504415869713, 0.05800829827785492, 0.05449458584189415, 0.021855849772691727, 0.0286741741001606, 0.05054798722267151, 0.035789452493190765, 0.01434398628771305, 0.05505193769931793, 0.019970901310443878, 0.025070643052458763, 0.0598367415368557, 0.10591267794370651, 0.01020571868866682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12210459262132645, 0.02900637313723564, 0.027926085516810417, 0.030763661488890648, 0.06431961804628372, 0.05075862631201744, 0.05746714025735855, 0.03854452073574066, 0.02881442941725254, 0.03641034662723541, 0.055306993424892426, 0.02755570225417614, 0.05062384530901909, 0.06039684638381004, 0.03790903463959694, 0.03416256979107857, 0.06550320982933044, 0.08224613219499588, 0.08903142064809799, 0.011148831807076931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019922718405723572, 0.0015991267282515764, 0.0035362686030566692, 0.002760607050731778, 0.003674750216305256, 0.091985784471035, 0.009868190623819828, 0.021762728691101074, 0.0036746240220963955, 0.004800301045179367, 0.1232718899846077, 0.003948225639760494, 0.0077277058735489845, 0.14901939034461975, 0.0050945039838552475, 0.0038495443295687437, 0.17433799803256989, 0.14503765106201172, 0.0031391752418130636, 0.0039015652146190405, 0.21708731353282928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.025169124826788902, 0.0025891440454870462, 0.0079044783487916, 0.002818176057189703, 0.008317497558891773, 0.06284768134355545, 0.016097379848361015, 0.02483357861638069, 0.007658040151000023, 0.011317078024148941, 0.08451008051633835, 0.012135403230786324, 0.022048382088541985, 0.10017251968383789, 0.015103279612958431, 0.0201522596180439, 0.11906807124614716, 0.14148969948291779, 0.006576648913323879, 0.0070740580558776855, 0.14850659668445587, 0.15361084043979645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08679645508527756, 0.015818683430552483, 0.009913158603012562, 0.005941123701632023, 0.011749119497835636, 0.04402250796556473, 0.049411579966545105, 0.047211624681949615, 0.02244851179420948, 0.028144177049398422, 0.05249372124671936, 0.013664904050529003, 0.038044534623622894, 0.05856489762663841, 0.016008734703063965, 0.028531746938824654, 0.06752396374940872, 0.10004056990146637, 0.026074495166540146, 0.01816527172923088, 0.08061446994543076, 0.14588378369808197, 0.03293200582265854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1220332682132721, 0.026796920225024223, 0.034712765365839005, 0.01660085655748844, 0.05098601058125496, 0.03362342715263367, 0.03376288339495659, 0.03289439156651497, 0.022763608023524284, 0.034695446491241455, 0.03710823133587837, 0.027503039687871933, 0.03050803393125534, 0.040704939514398575, 0.019409824162721634, 0.03338808938860893, 0.046037912368774414, 0.0814194306731224, 0.025792930275201797, 0.017713351175189018, 0.05326376482844353, 0.06955212354660034, 0.07340098917484283, 0.03532777354121208, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012632702477276325, 0.0031967288814485073, 0.008999628014862537, 0.0037871047388762236, 0.005590218584984541, 0.06018747389316559, 0.01017302367836237, 0.026063406839966774, 0.008280324749648571, 0.0059984405525028706, 0.08480246365070343, 0.007755734492093325, 0.014807665720582008, 0.10079343616962433, 0.011636026203632355, 0.007885102182626724, 0.12061367183923721, 0.1281987428665161, 0.006487110164016485, 0.0032305715139955282, 0.15047506988048553, 0.10557684302330017, 0.01548060867935419, 0.01902632601559162, 0.07832161337137222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11176051944494247, 0.01863556168973446, 0.056223705410957336, 0.04677280783653259, 0.03736496344208717, 0.022993413731455803, 0.03136527165770531, 0.026408882811665535, 0.043359220027923584, 0.05663556605577469, 0.021786415949463844, 0.02382213994860649, 0.03064166195690632, 0.023289259523153305, 0.054304927587509155, 0.068811796605587, 0.024489402770996094, 0.047770895063877106, 0.036271773278713226, 0.022222528234124184, 0.026998937129974365, 0.021766120567917824, 0.03442491590976715, 0.028240270912647247, 0.05891920626163483, 0.024719825014472008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10639798641204834, 0.03710790351033211, 0.08273960649967194, 0.01785685494542122, 0.020950015634298325, 0.018305247649550438, 0.02262009307742119, 0.018192268908023834, 0.02185117080807686, 0.012518538162112236, 0.019214095547795296, 0.030340095981955528, 0.07187619060277939, 0.02078801579773426, 0.03963521122932434, 0.06151585280895233, 0.023179292678833008, 0.04398040100932121, 0.0461922287940979, 0.020667990669608116, 0.027080878615379333, 0.043865546584129333, 0.03276738151907921, 0.04369065538048744, 0.05080845206975937, 0.04029493033885956, 0.025563016533851624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015084543265402317, 0.0038223823066800833, 0.005877262447029352, 0.0049718511290848255, 0.005370152648538351, 0.05223647877573967, 0.016127679497003555, 0.03182991221547127, 0.008211130276322365, 0.01147382240742445, 0.0670468807220459, 0.010528383776545525, 0.010598228313028812, 0.07938900589942932, 0.007211721036583185, 0.006271459627896547, 0.09142372012138367, 0.10866517573595047, 0.003973816521465778, 0.005621667951345444, 0.10983319580554962, 0.09237749129533768, 0.022960500791668892, 0.019314918667078018, 0.08864136040210724, 0.018464699387550354, 0.01102225948125124, 0.09165028482675552, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09854122251272202, 0.03967056795954704, 0.05052143335342407, 0.047943927347660065, 0.019531873986124992, 0.015683405101299286, 0.02507474087178707, 0.01499791070818901, 0.02772342413663864, 0.016418181359767914, 0.016389025375247, 0.026316560804843903, 0.034359268844127655, 0.01775798387825489, 0.02336267940700054, 0.03763512149453163, 0.019405601546168327, 0.034421682357788086, 0.04902299866080284, 0.030190542340278625, 0.022159069776535034, 0.03754066675901413, 0.038793161511421204, 0.04032415151596069, 0.042312659323215485, 0.06829201430082321, 0.02531413920223713, 0.04330072179436684, 0.03699522837996483, 0.0, 0.0, 0.0, 0.0], [0.10688817501068115, 0.036595746874809265, 0.005083095747977495, 0.010160424746572971, 0.013297361321747303, 0.041752055287361145, 0.026246795430779457, 0.030128560960292816, 0.013482403010129929, 0.01822318695485592, 0.0458262637257576, 0.025558775290846825, 0.01561881322413683, 0.05039897561073303, 0.011657019145786762, 0.01165912114083767, 0.05515517294406891, 0.05091661214828491, 0.019206790253520012, 0.013998426496982574, 0.06383472681045532, 0.029088884592056274, 0.016710449010133743, 0.026095259934663773, 0.05484984815120697, 0.03806673362851143, 0.03896070644259453, 0.05375230684876442, 0.02367916889488697, 0.05310814082622528, 0.0, 0.0, 0.0], [0.10871608555316925, 0.06286413967609406, 0.023045092821121216, 0.012493222020566463, 0.009688261896371841, 0.0237207543104887, 0.025617308914661407, 0.02828286960721016, 0.01952311582863331, 0.015187139622867107, 0.02461576834321022, 0.01885579340159893, 0.013071908615529537, 0.025697486475110054, 0.010639778338372707, 0.007336428388953209, 0.028488246724009514, 0.04087510332465172, 0.023693950846791267, 0.028460804373025894, 0.03178119286894798, 0.03399212285876274, 0.01690451055765152, 0.04699757322669029, 0.054809171706438065, 0.060481660068035126, 0.02113782800734043, 0.05147767812013626, 0.01530434750020504, 0.07868863642215729, 0.037551965564489365, 0.0, 0.0], [0.16510625183582306, 0.013307341374456882, 0.02282034605741501, 0.03222496435046196, 0.028327805921435356, 0.011912108398973942, 0.021759113296866417, 0.012591330334544182, 0.025371313095092773, 0.015923485159873962, 0.01174505427479744, 0.021340148523449898, 0.02265850454568863, 0.012097017839550972, 0.05877393111586571, 0.04114292189478874, 0.012866122648119926, 0.021896688267588615, 0.027385754510760307, 0.01541272085160017, 0.014822260476648808, 0.013198774307966232, 0.029060134664177895, 0.04031304642558098, 0.02303694374859333, 0.05035790055990219, 0.04650072380900383, 0.03221072629094124, 0.045741382986307144, 0.011448167264461517, 0.051484815776348114, 0.047162190079689026, 0.0], [0.019862733781337738, 0.0006941378815099597, 0.0017670636298134923, 0.0019038196187466383, 0.002311579417437315, 0.05924392119050026, 0.0051649510860443115, 0.008714542724192142, 0.002490669023245573, 0.003057960420846939, 0.07585161924362183, 0.0023905509151518345, 0.003177350852638483, 0.08945119380950928, 0.003065295284613967, 0.00162091467063874, 0.10312026739120483, 0.06259164214134216, 0.0020582969300448895, 0.00223221885971725, 0.12742048501968384, 0.024703852832317352, 0.0035101929679512978, 0.0049941763281822205, 0.028317108750343323, 0.005874201655387878, 0.006215331610292196, 0.03686559572815895, 0.005438114050775766, 0.004061863292008638, 0.004735518712550402, 0.004534383304417133, 0.292558491230011]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9726406335830688, 0.02735934779047966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8850566744804382, 0.08160645514726639, 0.03333684802055359, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.784497857093811, 0.09046003222465515, 0.1072097048163414, 0.017832357436418533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6679065227508545, 0.10135099291801453, 0.10997921228408813, 0.06990877538919449, 0.05085451155900955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.586279034614563, 0.06960930675268173, 0.06798024475574493, 0.06058965623378754, 0.08339769393205643, 0.13214407861232758, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5015710592269897, 0.06227878853678703, 0.07209987938404083, 0.0559091791510582, 0.0814688503742218, 0.12033160775899887, 0.10634062439203262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4001609981060028, 0.05525399371981621, 0.06347677856683731, 0.05413787066936493, 0.07119624316692352, 0.11230526119470596, 0.12489721924066544, 0.11857160180807114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4018532335758209, 0.08579415082931519, 0.05644883215427399, 0.07181122153997421, 0.08318918943405151, 0.07845646888017654, 0.09191887080669403, 0.0776887759566307, 0.05283930152654648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3827159106731415, 0.07976950705051422, 0.06207751855254173, 0.06360233575105667, 0.08211030066013336, 0.07804949581623077, 0.08597435802221298, 0.07506491243839264, 0.06327842175960541, 0.027357222512364388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.34041672945022583, 0.045351944863796234, 0.04658911004662514, 0.0403917171061039, 0.0548904649913311, 0.08179008215665817, 0.08906515687704086, 0.09645894169807434, 0.055649708956480026, 0.06398672610521317, 0.08540944010019302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31186193227767944, 0.09540000557899475, 0.07292015105485916, 0.0697687417268753, 0.07777833193540573, 0.0673503577709198, 0.061614058911800385, 0.05481072515249252, 0.052520133554935455, 0.05022517964243889, 0.07299350202083588, 0.012756953947246075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3665284216403961, 0.06308671832084656, 0.03947843238711357, 0.04609527066349983, 0.05740760639309883, 0.063483327627182, 0.0523846372961998, 0.055016204714775085, 0.04584016650915146, 0.06228690966963768, 0.06589912623167038, 0.05806362256407738, 0.024429524317383766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2856442928314209, 0.03804025799036026, 0.03942389041185379, 0.03423863276839256, 0.046394024044275284, 0.06771665066480637, 0.07328073680400848, 0.07855431735515594, 0.04789663851261139, 0.0559365451335907, 0.07124951481819153, 0.03568926453590393, 0.049560461193323135, 0.07637481391429901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2977541983127594, 0.05259548872709274, 0.04347937926650047, 0.058458633720874786, 0.04568732529878616, 0.052594032138586044, 0.0445619635283947, 0.0459747239947319, 0.06316150724887848, 0.07768755406141281, 0.05499148741364479, 0.034664712846279144, 0.05020102858543396, 0.05886140838265419, 0.01932654157280922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28853151202201843, 0.046169109642505646, 0.02823304384946823, 0.03824242576956749, 0.04330622777342796, 0.05174916237592697, 0.04318273440003395, 0.04393119364976883, 0.056163422763347626, 0.0677381381392479, 0.05490180850028992, 0.08139312267303467, 0.04325693100690842, 0.059048131108284, 0.03989902883768082, 0.014254054985940456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23721367120742798, 0.03161582350730896, 0.03324564918875694, 0.02923194319009781, 0.038618169724941254, 0.05549165979027748, 0.05966496095061302, 0.06321780383586884, 0.04073698818683624, 0.04752673953771591, 0.058378253132104874, 0.030399682000279427, 0.042871586978435516, 0.06284616887569427, 0.05321290343999863, 0.047368962317705154, 0.06835903227329254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2098696082830429, 0.02729126065969467, 0.03115660697221756, 0.026614999398589134, 0.03165116906166077, 0.05273225158452988, 0.0527450330555439, 0.05635902285575867, 0.04076547920703888, 0.04278235137462616, 0.056191280484199524, 0.030678270384669304, 0.0439896285533905, 0.060914747416973114, 0.050137005746364594, 0.041573163121938705, 0.06652862578630447, 0.07801952958106995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2385382503271103, 0.044145818799734116, 0.046435050666332245, 0.0345127172768116, 0.03572181984782219, 0.04369327798485756, 0.043049730360507965, 0.034988246858119965, 0.04371805489063263, 0.0395219624042511, 0.04457855224609375, 0.02459944598376751, 0.0625118762254715, 0.04753483459353447, 0.04375608637928963, 0.04995928332209587, 0.050908081233501434, 0.05266242474317551, 0.019164476543664932, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17729146778583527, 0.042214617133140564, 0.030818702653050423, 0.030886109918355942, 0.033868517726659775, 0.045211855322122574, 0.042901020497083664, 0.03221559524536133, 0.04018864035606384, 0.04926897957921028, 0.048016250133514404, 0.03814244642853737, 0.0512651763856411, 0.05206843465566635, 0.04744115099310875, 0.03924531862139702, 0.05630476027727127, 0.05462939664721489, 0.05991863086819649, 0.02810296230018139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19048276543617249, 0.025203490629792213, 0.02678745612502098, 0.023672688752412796, 0.0311040710657835, 0.04345342889428139, 0.04649331048130989, 0.04820645600557327, 0.03323280066251755, 0.038927506655454636, 0.04549151286482811, 0.024442730471491814, 0.03570159897208214, 0.049077682197093964, 0.043035659939050674, 0.03905563801527023, 0.0537174753844738, 0.06658954918384552, 0.04320827126502991, 0.03176472336053848, 0.06035127118229866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1497536599636078, 0.02347457781434059, 0.02550838701426983, 0.02894243411719799, 0.03517160564661026, 0.0388018935918808, 0.04594280570745468, 0.03962727263569832, 0.03708778694272041, 0.03872300684452057, 0.041907213628292084, 0.021688053384423256, 0.04328259453177452, 0.04592539742588997, 0.03893951699137688, 0.040076084434986115, 0.050600238144397736, 0.0608304925262928, 0.04372159764170647, 0.03023523837327957, 0.05728614702820778, 0.062474045902490616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1751340627670288, 0.027519280090928078, 0.029514005407691002, 0.020715326070785522, 0.026873530820012093, 0.03454612195491791, 0.038530781865119934, 0.033037807792425156, 0.041815564036369324, 0.040100302547216415, 0.03696897253394127, 0.030468925833702087, 0.03995397686958313, 0.04023701697587967, 0.0448262058198452, 0.03708262741565704, 0.04420146346092224, 0.04931037500500679, 0.04125743359327316, 0.02861069329082966, 0.04997343569993973, 0.05269286409020424, 0.036629170179367065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13285988569259644, 0.04070804640650749, 0.041116777807474136, 0.03484427556395531, 0.04087607562541962, 0.027567220851778984, 0.028293684124946594, 0.022520430386066437, 0.03875420615077019, 0.04037803038954735, 0.0290894266217947, 0.02960921637713909, 0.056701187044382095, 0.031181856989860535, 0.03766117990016937, 0.05688636004924774, 0.03396708518266678, 0.03781304135918617, 0.049514103680849075, 0.03194558247923851, 0.03759903833270073, 0.043266378343105316, 0.04305671527981758, 0.03379024937748909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14709363877773285, 0.018218711018562317, 0.022143611684441566, 0.021621398627758026, 0.027072913944721222, 0.03385418280959129, 0.03787612169981003, 0.038019631057977676, 0.02793252095580101, 0.03090183436870575, 0.03606925904750824, 0.01902313157916069, 0.034658029675483704, 0.039169859141111374, 0.0337555892765522, 0.026136614382267, 0.042978327721357346, 0.05313740670681, 0.03463507443666458, 0.02014029584825039, 0.04878360405564308, 0.04990803450345993, 0.04624393582344055, 0.047156691551208496, 0.06346960365772247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17602786421775818, 0.014882151037454605, 0.026751166209578514, 0.024088067933917046, 0.035667534917593, 0.027094289660453796, 0.024984240531921387, 0.021471867337822914, 0.02635936439037323, 0.02384510263800621, 0.027567004784941673, 0.01686953753232956, 0.07777431607246399, 0.029109209775924683, 0.047996968030929565, 0.02900249883532524, 0.031323354691267014, 0.036155980080366135, 0.039595600217580795, 0.017008021473884583, 0.03483906760811806, 0.03443719819188118, 0.041492193937301636, 0.09124377369880676, 0.04052295908331871, 0.0038906047120690346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18501748144626617, 0.027786999940872192, 0.02509763464331627, 0.027019010856747627, 0.02919921837747097, 0.0303370151668787, 0.03222178295254707, 0.023015083745121956, 0.026792865246534348, 0.022793833166360855, 0.030674872919917107, 0.02122085727751255, 0.05388808622956276, 0.032593000680208206, 0.03073764219880104, 0.025725232437253, 0.034866053611040115, 0.03793580085039139, 0.028672028332948685, 0.026148967444896698, 0.03875335305929184, 0.04179505631327629, 0.038631584495306015, 0.05337152257561684, 0.03982068598270416, 0.02571161277592182, 0.010172730311751366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1244632825255394, 0.01676890254020691, 0.02010509744286537, 0.01926703006029129, 0.024457845836877823, 0.03020336665213108, 0.03127393126487732, 0.032546062022447586, 0.023186009377241135, 0.02350839413702488, 0.03173321858048439, 0.01708051562309265, 0.029082056134939194, 0.03428216278553009, 0.035791296511888504, 0.02582055889070034, 0.03753117844462395, 0.04618246853351593, 0.029500015079975128, 0.017913812771439552, 0.04274730384349823, 0.0424346998333931, 0.039002399891614914, 0.04141839221119881, 0.059494998306035995, 0.035957347601652145, 0.030984869226813316, 0.05726282671093941, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14491020143032074, 0.025843987241387367, 0.03117695264518261, 0.019462747499346733, 0.012575741857290268, 0.025274593383073807, 0.02202068828046322, 0.02126728929579258, 0.03165539354085922, 0.02766416035592556, 0.026251591742038727, 0.022091040387749672, 0.03851797431707382, 0.02826686017215252, 0.028877614066004753, 0.03686533495783806, 0.030699966475367546, 0.03204502910375595, 0.034116294234991074, 0.020355412736535072, 0.03446315973997116, 0.03542865812778473, 0.03072841465473175, 0.04441896826028824, 0.03793594241142273, 0.057348690927028656, 0.03889699652791023, 0.04111206904053688, 0.01972820796072483, 0.0, 0.0, 0.0, 0.0], [0.1316843181848526, 0.02546011097729206, 0.027962401509284973, 0.024109849706292152, 0.016868827864527702, 0.03140677139163017, 0.02324734814465046, 0.02207169681787491, 0.027362488210201263, 0.026370452716946602, 0.03204537183046341, 0.02877582609653473, 0.04614204913377762, 0.03455977886915207, 0.031321071088314056, 0.029437724500894547, 0.037490688264369965, 0.035974208265542984, 0.03067101538181305, 0.026778321713209152, 0.041662365198135376, 0.03274399787187576, 0.030348774045705795, 0.032651983201503754, 0.038056500256061554, 0.034575626254081726, 0.022936126217246056, 0.036903269588947296, 0.025966186076402664, 0.014414903707802296, 0.0, 0.0, 0.0], [0.16563695669174194, 0.022809254005551338, 0.029107755050063133, 0.024944668635725975, 0.024352887645363808, 0.025031816214323044, 0.01848665066063404, 0.018573684617877007, 0.028443647548556328, 0.029199903830885887, 0.025318238884210587, 0.0322050005197525, 0.025753289461135864, 0.026890495792031288, 0.03127396106719971, 0.0330515019595623, 0.028835482895374298, 0.029910417273640633, 0.027558812871575356, 0.02462468110024929, 0.0320536270737648, 0.02649376541376114, 0.021709619089961052, 0.03164015710353851, 0.037074748426675797, 0.047994695603847504, 0.027932148426771164, 0.034756120294332504, 0.03804945573210716, 0.021535690873861313, 0.00875084102153778, 0.0, 0.0], [0.1679421365261078, 0.02598348818719387, 0.03222334757447243, 0.019469384104013443, 0.023735303431749344, 0.023115726187825203, 0.019973624497652054, 0.016550229862332344, 0.029796777293086052, 0.028494669124484062, 0.02310885861515999, 0.022087080404162407, 0.042165569961071014, 0.024390170350670815, 0.020749147981405258, 0.038735855370759964, 0.026269836351275444, 0.027289096266031265, 0.01961737684905529, 0.02024286612868309, 0.02920321188867092, 0.030413372442126274, 0.02576262690126896, 0.040849801152944565, 0.033326636999845505, 0.021795310080051422, 0.02631053514778614, 0.031013479456305504, 0.036892615258693695, 0.01937718316912651, 0.043556053191423416, 0.009558654390275478, 0.0], [0.11396825313568115, 0.0177528727799654, 0.016061948612332344, 0.015585058368742466, 0.01839613914489746, 0.0243670791387558, 0.026053884997963905, 0.023999108001589775, 0.021919477730989456, 0.02625109814107418, 0.024730542674660683, 0.01532302051782608, 0.02561456710100174, 0.026337873190641403, 0.024982869625091553, 0.024642597883939743, 0.028590325266122818, 0.03295150026679039, 0.027568642050027847, 0.01848755031824112, 0.03220851719379425, 0.031914710998535156, 0.03630727529525757, 0.034154027700424194, 0.03678560256958008, 0.03297771140933037, 0.02627890184521675, 0.03809887915849686, 0.029801957309246063, 0.018183251842856407, 0.03632066771388054, 0.03568094223737717, 0.057703107595443726]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8058415055274963, 0.19415844976902008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6373866200447083, 0.09672049432992935, 0.265892893075943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5870267152786255, 0.09922724962234497, 0.07913826406002045, 0.23460783064365387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4194740355014801, 0.06312595307826996, 0.08123063296079636, 0.08381497859954834, 0.352354496717453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.530853271484375, 0.0959073081612587, 0.07779335975646973, 0.06661548465490341, 0.07293293625116348, 0.15589763224124908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3850307762622833, 0.0747809186577797, 0.06978143751621246, 0.047606535255908966, 0.05144914612174034, 0.08776704221963882, 0.2835841178894043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2962956726551056, 0.05328270420432091, 0.06944748014211655, 0.040975481271743774, 0.06660832464694977, 0.1021856963634491, 0.10869501531124115, 0.26250967383384705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30475011467933655, 0.06337985396385193, 0.05753422528505325, 0.04057719558477402, 0.07300138473510742, 0.07375828176736832, 0.07239887863397598, 0.056936051696538925, 0.2576640844345093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29880765080451965, 0.055528245866298676, 0.05443596467375755, 0.052853018045425415, 0.06568748503923416, 0.07554223388433456, 0.06968104094266891, 0.05411387234926224, 0.09120786190032959, 0.18214257061481476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2693301737308502, 0.06352430582046509, 0.059521205723285675, 0.05242469906806946, 0.06052158400416374, 0.12185832113027573, 0.07608653604984283, 0.09753072261810303, 0.042326074093580246, 0.050583261996507645, 0.10629310458898544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22074298560619354, 0.06960075348615646, 0.04872344434261322, 0.06675713509321213, 0.06954210251569748, 0.06483785808086395, 0.04652373120188713, 0.039300836622714996, 0.018016086891293526, 0.035806313157081604, 0.053022850304841995, 0.2671259045600891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15080073475837708, 0.04732475057244301, 0.12551113963127136, 0.062400832772254944, 0.053546320647001266, 0.0557839535176754, 0.04542611539363861, 0.03888600692152977, 0.0301998108625412, 0.03337055444717407, 0.04645954445004463, 0.023437924683094025, 0.2868523597717285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2044883370399475, 0.049720507115125656, 0.04838545247912407, 0.04385359212756157, 0.05115719884634018, 0.1007489413022995, 0.06420682370662689, 0.08302561938762665, 0.03880453109741211, 0.047957733273506165, 0.09582382440567017, 0.03239700570702553, 0.044411029666662216, 0.09501936286687851, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16236740350723267, 0.028519179672002792, 0.047843087464571, 0.041354816406965256, 0.040284883230924606, 0.052005354315042496, 0.04226505383849144, 0.03821168839931488, 0.05986882373690605, 0.06849396973848343, 0.04734281450510025, 0.019715163856744766, 0.06202229857444763, 0.04572192206978798, 0.24398353695869446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1312893033027649, 0.03962808847427368, 0.059519387781620026, 0.039663221687078476, 0.04406356438994408, 0.04348495230078697, 0.03726546838879585, 0.03240035101771355, 0.037205733358860016, 0.06481602042913437, 0.0404745377600193, 0.025914236903190613, 0.06507600098848343, 0.03922510892152786, 0.0774419754743576, 0.22253204882144928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1581333875656128, 0.03911251947283745, 0.03856494650244713, 0.03587969392538071, 0.04187794402241707, 0.08161000907421112, 0.05245805159211159, 0.0681268572807312, 0.03444807231426239, 0.04342750832438469, 0.08275996893644333, 0.029333394020795822, 0.04157378897070885, 0.08478686213493347, 0.048816002905368805, 0.032352838665246964, 0.08673812448978424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13890595734119415, 0.03169632703065872, 0.03251554071903229, 0.03538898378610611, 0.038000334054231644, 0.06974425911903381, 0.05942453071475029, 0.06768239289522171, 0.027843806892633438, 0.039054665714502335, 0.07273104041814804, 0.030109873041510582, 0.04163093492388725, 0.07565010339021683, 0.04018832743167877, 0.027483616024255753, 0.0779590755701065, 0.09399020671844482, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09691290557384491, 0.03068731166422367, 0.030817952007055283, 0.044734325259923935, 0.04171941801905632, 0.036036767065525055, 0.04101702570915222, 0.03210476040840149, 0.04344063997268677, 0.04885551705956459, 0.03457902371883392, 0.016025099903345108, 0.04994165524840355, 0.0346352718770504, 0.06065686047077179, 0.034977883100509644, 0.03454343602061272, 0.03782794997096062, 0.25048619508743286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1205921471118927, 0.04121064394712448, 0.05098516866564751, 0.05289150029420853, 0.02886130101978779, 0.047061987221241, 0.029212836176156998, 0.038170017302036285, 0.021046487614512444, 0.02978781796991825, 0.04406721517443657, 0.02650335431098938, 0.04127003252506256, 0.044307366013526917, 0.03080156072974205, 0.04064901918172836, 0.044745106250047684, 0.042122457176446915, 0.028442280367016792, 0.1972716897726059, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11388306319713593, 0.02825540117919445, 0.028351284563541412, 0.02695867046713829, 0.03131086379289627, 0.05977547913789749, 0.0391821451485157, 0.05072040110826492, 0.02768402174115181, 0.035564225167036057, 0.06452133506536484, 0.024267084896564484, 0.03616494685411453, 0.06838169693946838, 0.041393011808395386, 0.0290946364402771, 0.0723005011677742, 0.07349381595849991, 0.03700020909309387, 0.0352863147854805, 0.07641096413135529, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08453851193189621, 0.017416611313819885, 0.018949132412672043, 0.016560642048716545, 0.022296126931905746, 0.041740596294403076, 0.05894863232970238, 0.038933612406253815, 0.030214648693799973, 0.03464233875274658, 0.048319004476070404, 0.01635843701660633, 0.02567455731332302, 0.053096748888492584, 0.020546521991491318, 0.02046983130276203, 0.05704640597105026, 0.06604909896850586, 0.03774646297097206, 0.02141387201845646, 0.06129930168390274, 0.20773889124393463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11248443275690079, 0.024394843727350235, 0.024523135274648666, 0.02748955972492695, 0.026104673743247986, 0.037315063178539276, 0.06748529523611069, 0.03890375792980194, 0.01798143796622753, 0.028454391285777092, 0.037565309554338455, 0.018326064571738243, 0.020088661462068558, 0.038651712238788605, 0.023285649716854095, 0.02422661893069744, 0.03960611671209335, 0.04833188280463219, 0.04500092566013336, 0.017362141981720924, 0.04009140282869339, 0.05208283290266991, 0.19024406373500824, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08183359354734421, 0.019828449934720993, 0.0268733948469162, 0.029252558946609497, 0.02518443949520588, 0.031927723437547684, 0.029049787670373917, 0.024972515180706978, 0.03350626304745674, 0.040074292570352554, 0.033517323434352875, 0.01603599824011326, 0.03204454109072685, 0.03448064252734184, 0.02851710096001625, 0.03532731905579567, 0.03583228588104248, 0.040583960711956024, 0.029941115528345108, 0.02109791710972786, 0.03671329468488693, 0.03921257704496384, 0.03543240949511528, 0.23876051604747772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1014569103717804, 0.014237052761018276, 0.01698417402803898, 0.018636560067534447, 0.028536250814795494, 0.036538016051054, 0.029570508748292923, 0.04198319464921951, 0.014166050590574741, 0.030081404373049736, 0.04016640782356262, 0.020075039938092232, 0.03037012554705143, 0.04353441670536995, 0.03039301559329033, 0.02071734517812729, 0.04677112400531769, 0.054951030761003494, 0.028809187933802605, 0.020043691620230675, 0.05092542991042137, 0.040844667702913284, 0.04185802862048149, 0.03848978877067566, 0.15986062586307526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07937928289175034, 0.02067432925105095, 0.020799750462174416, 0.027988238260149956, 0.0456547737121582, 0.02656259760260582, 0.02539670467376709, 0.021243248134851456, 0.01776380091905594, 0.025200635194778442, 0.02757645957171917, 0.03060709498822689, 0.0343799963593483, 0.028568318113684654, 0.022726938128471375, 0.016051946207880974, 0.02971273846924305, 0.03276180475950241, 0.025702396407723427, 0.012878886424005032, 0.03062613122165203, 0.020369645208120346, 0.037413887679576874, 0.02785036899149418, 0.035718511790037155, 0.27639150619506836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09605437517166138, 0.023092901334166527, 0.024199649691581726, 0.02497413381934166, 0.036829665303230286, 0.030014390125870705, 0.02106921561062336, 0.018117520958185196, 0.022569265216588974, 0.02834322489798069, 0.03050513006746769, 0.021707683801651, 0.02821178361773491, 0.031639423221349716, 0.03916611522436142, 0.03627365455031395, 0.03311571106314659, 0.03514396771788597, 0.025745240971446037, 0.01588900201022625, 0.034675467759370804, 0.026770086959004402, 0.02714345045387745, 0.040450796484947205, 0.037603843957185745, 0.03232336416840553, 0.17837102711200714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07476936280727386, 0.011021515354514122, 0.010706553235650063, 0.015325449407100677, 0.01990356482565403, 0.03285866603255272, 0.02193606272339821, 0.029454153031110764, 0.01642150804400444, 0.022476568818092346, 0.037223439663648605, 0.017580240964889526, 0.021954137831926346, 0.040462128818035126, 0.0314154177904129, 0.010417778976261616, 0.044297389686107635, 0.05118127539753914, 0.02956555038690567, 0.015394327230751514, 0.0490642711520195, 0.032021936029195786, 0.030905112624168396, 0.04132053256034851, 0.06578275561332703, 0.039784036576747894, 0.020499693229794502, 0.1662566363811493, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05124204233288765, 0.011390029452741146, 0.020265797153115273, 0.02452964335680008, 0.1273244321346283, 0.02008390985429287, 0.01769273355603218, 0.020381979644298553, 0.01854861155152321, 0.023206062614917755, 0.02102605439722538, 0.020521238446235657, 0.025210730731487274, 0.021994249895215034, 0.017190469428896904, 0.020805906504392624, 0.023035310208797455, 0.026458051055669785, 0.031086131930351257, 0.011454473249614239, 0.024357983842492104, 0.022524939849972725, 0.02460077404975891, 0.024588003754615784, 0.028380829840898514, 0.046606115996837616, 0.0436270646750927, 0.020300474017858505, 0.2115660160779953, 0.0, 0.0, 0.0, 0.0], [0.07929296046495438, 0.023537393659353256, 0.022847279906272888, 0.01993604004383087, 0.015462889336049557, 0.025110291317105293, 0.021429041400551796, 0.015073486603796482, 0.009924097917973995, 0.015724750235676765, 0.027188710868358612, 0.020747274160385132, 0.034976352006196976, 0.029102327302098274, 0.021219026297330856, 0.01814761385321617, 0.031058205291628838, 0.033809494227170944, 0.020137561485171318, 0.01232312060892582, 0.0336926206946373, 0.024336127564311028, 0.031084518879652023, 0.03377700224518776, 0.04355441778898239, 0.032963529229164124, 0.03314928337931633, 0.02536490373313427, 0.02216367982327938, 0.22286593914031982, 0.0, 0.0, 0.0], [0.10059653967618942, 0.03096376173198223, 0.025578506290912628, 0.02022406831383705, 0.02713298238813877, 0.029490763321518898, 0.04074482247233391, 0.021403620019555092, 0.01639261096715927, 0.022520696744322777, 0.027555173262953758, 0.013599208556115627, 0.027306705713272095, 0.02780657820403576, 0.011214186437427998, 0.023586537688970566, 0.028399186208844185, 0.03066891059279442, 0.021664202213287354, 0.0170323196798563, 0.02905159257352352, 0.02654992789030075, 0.03297554329037666, 0.026790326461195946, 0.032060641795396805, 0.027298329398036003, 0.017307188361883163, 0.01876882277429104, 0.028226526454091072, 0.017085116356611252, 0.18000461161136627, 0.0, 0.0], [0.08361605554819107, 0.01658189296722412, 0.015823297202587128, 0.022005168721079826, 0.024062560871243477, 0.021028300747275352, 0.022811293601989746, 0.01441238820552826, 0.01557209063321352, 0.015104832127690315, 0.020917730405926704, 0.02179816924035549, 0.02598598599433899, 0.022013207897543907, 0.022025061771273613, 0.018091216683387756, 0.02311510220170021, 0.025451797991991043, 0.02594352513551712, 0.011241882108151913, 0.024466171860694885, 0.022869886830449104, 0.031613435596227646, 0.029542667791247368, 0.02381790429353714, 0.029349012300372124, 0.025922641158103943, 0.017268184572458267, 0.031844593584537506, 0.012037739157676697, 0.02752492018043995, 0.25614133477211, 0.0], [0.05258439853787422, 0.012508384883403778, 0.012737673707306385, 0.012144193984568119, 0.014467821456491947, 0.024812445044517517, 0.017109140753746033, 0.02516257017850876, 0.016298970207571983, 0.015160082839429379, 0.029820039868354797, 0.014290271326899529, 0.02409479022026062, 0.03374277800321579, 0.02163226343691349, 0.018924102187156677, 0.03819216787815094, 0.04115181788802147, 0.024165775626897812, 0.02063564397394657, 0.0441853329539299, 0.037937089800834656, 0.02963634952902794, 0.03152840584516525, 0.04542307183146477, 0.03596360608935356, 0.030482541769742966, 0.04609917104244232, 0.03206765279173851, 0.01766294613480568, 0.03169601783156395, 0.044629115611314774, 0.10305344313383102]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7707713842391968, 0.22922860085964203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7813623547554016, 0.10978527367115021, 0.1088523343205452, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5350388884544373, 0.11194944381713867, 0.15013688802719116, 0.2028747797012329, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4180358350276947, 0.16036385297775269, 0.10740306973457336, 0.10625777393579483, 0.2079394906759262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4349866509437561, 0.0957985520362854, 0.08251801878213882, 0.10028502345085144, 0.15332910418510437, 0.13308261334896088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.44621357321739197, 0.056242119520902634, 0.05040299892425537, 0.0708429366350174, 0.09360905736684799, 0.11472617089748383, 0.16796310245990753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3609194755554199, 0.07294464856386185, 0.05191003903746605, 0.07159049808979034, 0.09321669489145279, 0.09543664008378983, 0.14539925754070282, 0.1085827425122261, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31714069843292236, 0.07683128118515015, 0.0555228516459465, 0.06445363909006119, 0.08586593717336655, 0.10643254965543747, 0.1452113538980484, 0.09439334273338318, 0.054148342460393906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19288600981235504, 0.11343874782323837, 0.045305073261260986, 0.08361206203699112, 0.05763271823525429, 0.11914195120334625, 0.11441227048635483, 0.12364509701728821, 0.07640955597162247, 0.07351643592119217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.25174087285995483, 0.060194142162799835, 0.049302127212285995, 0.0592232346534729, 0.08453334867954254, 0.07307681441307068, 0.12308555096387863, 0.08293969184160233, 0.06380269676446915, 0.07185833901166916, 0.08024313300848007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24793602526187897, 0.04855771362781525, 0.0617169588804245, 0.06616784632205963, 0.0878860205411911, 0.059203825891017914, 0.09128591418266296, 0.06866812705993652, 0.06062868982553482, 0.08399355411529541, 0.0656941831111908, 0.05826115608215332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15039603412151337, 0.07072301208972931, 0.0361880287528038, 0.038128845393657684, 0.0549657829105854, 0.09552796185016632, 0.1278020441532135, 0.09101752191781998, 0.04133947566151619, 0.06619425117969513, 0.11493083089590073, 0.0352681428194046, 0.07751806080341339, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21730749309062958, 0.052248768508434296, 0.04279685020446777, 0.05130990967154503, 0.07021073251962662, 0.060848649591207504, 0.1009417176246643, 0.06729136407375336, 0.053472720086574554, 0.05803244560956955, 0.0638660341501236, 0.041436828672885895, 0.054298125207424164, 0.06593839824199677, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14158986508846283, 0.08735616505146027, 0.041096288710832596, 0.07771318405866623, 0.0664159283041954, 0.06084612011909485, 0.07890867441892624, 0.0646718218922615, 0.04156755656003952, 0.05314024165272713, 0.06033195182681084, 0.04990345239639282, 0.061476901173591614, 0.06152055785059929, 0.05346130579710007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11277396976947784, 0.051402702927589417, 0.03480074182152748, 0.04410993680357933, 0.04927105829119682, 0.08066020160913467, 0.09371132403612137, 0.07634276896715164, 0.03460071608424187, 0.05556502193212509, 0.09000375121831894, 0.027950908988714218, 0.05808689445257187, 0.09759874641895294, 0.0585305280983448, 0.03459075838327408, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19136783480644226, 0.0458880178630352, 0.03718419373035431, 0.044788483530282974, 0.05845540761947632, 0.05162312090396881, 0.08451797813177109, 0.05661727488040924, 0.04477924108505249, 0.046815864741802216, 0.051775235682725906, 0.03474309295415878, 0.04365592449903488, 0.05257754027843475, 0.04571913182735443, 0.05523937568068504, 0.0542522594332695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1780986338853836, 0.036513157188892365, 0.035378023982048035, 0.046600595116615295, 0.05606749653816223, 0.055425308644771576, 0.06580903381109238, 0.05869591236114502, 0.044602103531360626, 0.03845332935452461, 0.05522070452570915, 0.028129279613494873, 0.03887631371617317, 0.05635207146406174, 0.04307203367352486, 0.04859212040901184, 0.05801304802298546, 0.05610081925988197, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11277122050523758, 0.04416342079639435, 0.016790850088000298, 0.03922899439930916, 0.030570238828659058, 0.08429381996393204, 0.05829834192991257, 0.07985574752092361, 0.0277402326464653, 0.024607928469777107, 0.08568025380373001, 0.012135534547269344, 0.02122361958026886, 0.08979950100183487, 0.024395618587732315, 0.018000077456235886, 0.09797869622707367, 0.08564860373735428, 0.046817269176244736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15648676455020905, 0.04359336569905281, 0.029469123110175133, 0.023382794111967087, 0.039893943816423416, 0.06601442396640778, 0.07239897549152374, 0.049598757177591324, 0.025720084086060524, 0.02872989885509014, 0.072687529027462, 0.02010437287390232, 0.03894995152950287, 0.07793485373258591, 0.0318501777946949, 0.029572593048214912, 0.08162933588027954, 0.04983031377196312, 0.04757082462310791, 0.014582015573978424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16675150394439697, 0.04021673649549484, 0.03194626793265343, 0.039155542850494385, 0.04867978021502495, 0.043519336730241776, 0.07027733325958252, 0.04676979035139084, 0.037370480597019196, 0.03785953298211098, 0.041853513568639755, 0.029438771307468414, 0.03496701642870903, 0.04187152534723282, 0.0366595983505249, 0.04418947920203209, 0.042447008192539215, 0.04308998957276344, 0.05540823936462402, 0.024029964581131935, 0.04349851235747337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2131170630455017, 0.03452149033546448, 0.026512041687965393, 0.03728464990854263, 0.04200230538845062, 0.053780727088451385, 0.06410718709230423, 0.040195904672145844, 0.029513956978917122, 0.030562086030840874, 0.04814052954316139, 0.019645746797323227, 0.023855995386838913, 0.04712359234690666, 0.027805248275399208, 0.02563280612230301, 0.04690323770046234, 0.042115021497011185, 0.04245338216423988, 0.016209963709115982, 0.047201577574014664, 0.04131557047367096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16099104285240173, 0.031492140144109726, 0.02550600655376911, 0.03203628957271576, 0.038119375705718994, 0.05386460945010185, 0.05289202556014061, 0.06297369301319122, 0.03872942551970482, 0.030703024938702583, 0.0486149825155735, 0.016964131966233253, 0.020984867587685585, 0.04743489250540733, 0.026178570464253426, 0.032817017287015915, 0.04874100908637047, 0.037023045122623444, 0.050284452736377716, 0.014425929635763168, 0.04926920682191849, 0.027485135942697525, 0.052469104528427124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13924194872379303, 0.04732195660471916, 0.022920064628124237, 0.03782675042748451, 0.03733158856630325, 0.056281961500644684, 0.06773106753826141, 0.06383748352527618, 0.028824562206864357, 0.028368622064590454, 0.05008406192064285, 0.014775182120501995, 0.021058904007077217, 0.04819711297750473, 0.017685120925307274, 0.015456218272447586, 0.04842803254723549, 0.03709951788187027, 0.04247325658798218, 0.018426815047860146, 0.04861331358551979, 0.022673944011330605, 0.05998959392309189, 0.025352949276566505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1956234872341156, 0.03233328461647034, 0.02287408895790577, 0.038390759378671646, 0.03449878841638565, 0.046169035136699677, 0.05553751066327095, 0.03960668295621872, 0.023098403587937355, 0.02424929477274418, 0.04043306037783623, 0.016078542917966843, 0.02162495255470276, 0.039030540734529495, 0.026520878076553345, 0.02811342291533947, 0.0382363460958004, 0.03542612865567207, 0.041745755821466446, 0.02109713852405548, 0.03767954558134079, 0.0372869148850441, 0.04423920810222626, 0.02292150817811489, 0.0371846966445446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0581965297460556, 0.038897402584552765, 0.026005247607827187, 0.023567883297801018, 0.022979989647865295, 0.053841497749090195, 0.058061063289642334, 0.06858772039413452, 0.03745982423424721, 0.029159117490053177, 0.05474672466516495, 0.013592935167253017, 0.027647055685520172, 0.05575402453541756, 0.030779872089624405, 0.016137350350618362, 0.05745430663228035, 0.039687298238277435, 0.03406552970409393, 0.013110971078276634, 0.059776563197374344, 0.016043761745095253, 0.0296992938965559, 0.020566528663039207, 0.08347287029027939, 0.03070860542356968, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15561480820178986, 0.030323179438710213, 0.021067576482892036, 0.03860040754079819, 0.025089262053370476, 0.0471951961517334, 0.042556509375572205, 0.05166256055235863, 0.030368110164999962, 0.02013363502919674, 0.04255697503685951, 0.018511774018406868, 0.01867171935737133, 0.0414302758872509, 0.022022126242518425, 0.02106103114783764, 0.041666194796562195, 0.027249205857515335, 0.0404815711081028, 0.01553641352802515, 0.04219621419906616, 0.01700734533369541, 0.06220947578549385, 0.015703151002526283, 0.05443185567855835, 0.040924087166786194, 0.015729248523712158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1521887183189392, 0.032320473343133926, 0.02627762407064438, 0.03215135633945465, 0.037080563604831696, 0.03843332827091217, 0.0421852208673954, 0.034409213811159134, 0.02929617278277874, 0.02475227415561676, 0.03461233526468277, 0.021795077249407768, 0.023419689387083054, 0.033866435289382935, 0.028580613434314728, 0.034403249621391296, 0.03315696865320206, 0.02671039290726185, 0.04213566705584526, 0.019021358340978622, 0.0327858068048954, 0.026839980855584145, 0.033044565469026566, 0.023302629590034485, 0.03390035033226013, 0.039449259638786316, 0.02133425697684288, 0.042546432465314865, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10210391134023666, 0.04830533638596535, 0.027957912534475327, 0.02813485451042652, 0.04368894547224045, 0.037659596651792526, 0.04012181982398033, 0.03589580953121185, 0.024491775780916214, 0.019768046215176582, 0.03467409685254097, 0.01543145626783371, 0.032616570591926575, 0.03414337709546089, 0.02746138721704483, 0.020323215052485466, 0.034458424896001816, 0.015827570110559464, 0.030705854296684265, 0.020360929891467094, 0.035580456256866455, 0.0347902737557888, 0.03518150374293327, 0.028572576120495796, 0.04333386942744255, 0.03896387293934822, 0.017587702721357346, 0.045533761382102966, 0.04632510989904404, 0.0, 0.0, 0.0, 0.0], [0.1184174120426178, 0.026689790189266205, 0.02854764647781849, 0.03516456112265587, 0.03519095852971077, 0.030704857781529427, 0.04254690557718277, 0.023103507235646248, 0.025463111698627472, 0.029678557068109512, 0.028395213186740875, 0.019178256392478943, 0.02383357845246792, 0.027640020474791527, 0.033817537128925323, 0.03964013233780861, 0.027574429288506508, 0.021856164559721947, 0.03966764733195305, 0.03941831737756729, 0.027115626260638237, 0.030498048290610313, 0.03493284806609154, 0.0323205292224884, 0.027840537950396538, 0.03877580538392067, 0.021124791353940964, 0.038611434400081635, 0.032771822065114975, 0.019479986280202866, 0.0, 0.0, 0.0], [0.05433790758252144, 0.019247835502028465, 0.011686470359563828, 0.014118614606559277, 0.013909783214330673, 0.05736802518367767, 0.034546393901109695, 0.046650584787130356, 0.013026444241404533, 0.013271301984786987, 0.05952775850892067, 0.00906313955783844, 0.017364203929901123, 0.06135562062263489, 0.012634649872779846, 0.015145530924201012, 0.06425535678863525, 0.04627061262726784, 0.019556371495127678, 0.012543444521725178, 0.06913556903600693, 0.03482367470860481, 0.030005982145667076, 0.012261815369129181, 0.07985589653253555, 0.01899644173681736, 0.010722932405769825, 0.08654540032148361, 0.017174091190099716, 0.02214416302740574, 0.02245398424565792, 0.0, 0.0], [0.05849645659327507, 0.03437737002968788, 0.013603090308606625, 0.02417042851448059, 0.019005870446562767, 0.06546404957771301, 0.03062298148870468, 0.035732071846723557, 0.01885945536196232, 0.012241479009389877, 0.0628218948841095, 0.01183574739843607, 0.009552357718348503, 0.06431795656681061, 0.02158959023654461, 0.01091296412050724, 0.06665915250778198, 0.023997453972697258, 0.026596734300255775, 0.00615355372428894, 0.06984328478574753, 0.037238676100969315, 0.03004671446979046, 0.021686799824237823, 0.043640609830617905, 0.02120961807668209, 0.013490457087755203, 0.04632722958922386, 0.020434502512216568, 0.01336226798593998, 0.018568990752100945, 0.04714022949337959, 0.0], [0.1352868378162384, 0.02973336912691593, 0.02611132711172104, 0.03753575310111046, 0.0388815701007843, 0.033166784793138504, 0.048243921250104904, 0.030468309298157692, 0.02603822574019432, 0.02412371151149273, 0.02789275161921978, 0.022709941491484642, 0.0241852980107069, 0.026114553213119507, 0.023209670558571815, 0.02517528086900711, 0.02461479790508747, 0.02112315408885479, 0.02968505583703518, 0.018167467787861824, 0.02306438237428665, 0.02059805579483509, 0.034411415457725525, 0.021083395928144455, 0.02253883332014084, 0.032281555235385895, 0.013987252488732338, 0.024144919589161873, 0.027002308517694473, 0.012929446063935757, 0.03616539388895035, 0.026840241625905037, 0.03248501941561699]]]}\n",
              "    )\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "print(\"Layer 0 Head Attention Patterns:\")\n",
        "cv.attention.attention_patterns(tokens=gpt2_str_tokens, attention=attention_pattern)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMLRNhoHXMAh"
      },
      "source": [
        "In this case, we only wanted the layer 0 attention patterns, but we are storing the internal activations from all locations in the model. It's convenient to have access to all activations, but this can be prohibitively expensive for memory use with larger models, batch sizes, or sequence lengths. In addition, we don't need to do the full forward pass through the model to collect layer 0 attention patterns. The following cell will collect only the layer 0 attention patterns and stop the forward pass at layer 1, requiring far less memory and compute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6cucELM-XMAh"
      },
      "outputs": [],
      "source": [
        "attn_hook_name = \"blocks.0.attn.hook_pattern\"\n",
        "attn_layer = 0\n",
        "_, gpt2_attn_cache = model.run_with_cache(gpt2_tokens, remove_batch_dim=True, stop_at_layer=attn_layer + 1, names_filter=[attn_hook_name])\n",
        "gpt2_attn = gpt2_attn_cache[attn_hook_name]\n",
        "assert torch.equal(gpt2_attn, attention_pattern)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWLreIYGXMAi"
      },
      "source": [
        "## Hooks: Intervening on Activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSrNwEbgXMAi"
      },
      "source": [
        "One of the great things about interpreting neural networks is that we have *full control* over our system. From a computational perspective, we know exactly what operations are going on inside (even if we don't know what they mean!). And we can make precise, surgical edits and see how the model's behaviour and other internals change. This is an extremely powerful tool, because it can let us eg set up careful counterfactuals and causal intervention to easily understand model behaviour.\n",
        "\n",
        "Accordingly, being able to do this is a pretty core operation, and this is one of the main things TransformerLens supports! The key feature here is **hook points**. Every activation inside the transformer is surrounded by a hook point, which allows us to edit or intervene on it.\n",
        "\n",
        "We do this by adding a **hook function** to that activation. The hook function maps `current_activation_value, hook_point` to `new_activation_value`. As the model is run, it computes that activation as normal, and then the hook function is applied to compute a replacement, and that is substituted in for the activation. The hook function can be an arbitrary Python function, so long as it returns a tensor of the correct shape.\n",
        "\n",
        "<details><summary>Relationship to PyTorch hooks</summary>\n",
        "\n",
        "[PyTorch hooks](https://blog.paperspace.com/pytorch-hooks-gradient-clipping-debugging/) are a great and underrated, yet incredibly janky, feature. They can act on a layer, and edit the input or output of that layer, or the gradient when applying autodiff. The key difference is that **Hook points** act on *activations* not layers. This means that you can intervene within a layer on each activation, and don't need to care about the precise layer structure of the transformer. And it's immediately clear exactly how the hook's effect is applied. This adjustment was shamelessly inspired by [Garcon's use of ProbePoints](https://transformer-circuits.pub/2021/garcon/index.html).\n",
        "\n",
        "They also come with a range of other quality of life improvements, like the model having a `model.reset_hooks()` method to remove all hooks, or helper methods to temporarily add hooks for a single forward pass - it is *incredibly* easy to shoot yourself in the foot with standard PyTorch hooks!\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA18qwBrXMAj"
      },
      "source": [
        "As a basic example, let's [ablate](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=fh-HJyz1CgUVrXuoiban6bYx) head 7 in layer 0 on the text above.\n",
        "\n",
        "We define a `head_ablation_hook` function. This takes the value tensor for attention layer 0, and sets the component with `head_index==7` to zero and returns it (Note - we return by convention, but since we're editing the activation in-place, we don't strictly *need* to).\n",
        "\n",
        "We then use the `run_with_hooks` helper function to run the model and *temporarily* add in the hook for just this run. We enter in the hook as a tuple of the activation name (also the hook point name - found with `utils.get_act_name`) and the hook function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgZeIVwFXMAn",
        "outputId": "1a9782f5-4806-42f7-8235-cadb797f756a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the value tensor: torch.Size([1, 33, 12, 64])\n",
            "Original Loss: 3.999\n",
            "Ablated Loss: 5.453\n"
          ]
        }
      ],
      "source": [
        "layer_to_ablate = 0\n",
        "head_index_to_ablate = 8\n",
        "\n",
        "# We define a head ablation hook\n",
        "# The type annotations are NOT necessary, they're just a useful guide to the reader\n",
        "#\n",
        "def head_ablation_hook(\n",
        "    value: Float[torch.Tensor, \"batch pos head_index d_head\"],\n",
        "    hook: HookPoint\n",
        ") -> Float[torch.Tensor, \"batch pos head_index d_head\"]:\n",
        "    print(f\"Shape of the value tensor: {value.shape}\")\n",
        "    value[:, :, head_index_to_ablate, :] = 0.\n",
        "    return value\n",
        "\n",
        "original_loss = model(gpt2_tokens, return_type=\"loss\")\n",
        "ablated_loss = model.run_with_hooks(\n",
        "    gpt2_tokens,\n",
        "    return_type=\"loss\",\n",
        "    fwd_hooks=[(\n",
        "        utils.get_act_name(\"v\", layer_to_ablate),\n",
        "        head_ablation_hook\n",
        "        )]\n",
        "    )\n",
        "print(f\"Original Loss: {original_loss.item():.3f}\")\n",
        "print(f\"Ablated Loss: {ablated_loss.item():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq-tssvqXMAo"
      },
      "source": [
        "**Gotcha:** Hooks are global state - they're added in as part of the model, and stay there until removed. `run_with_hooks` tries to create an abstraction where these are local state, by removing all hooks at the end of the function. But you can easily shoot yourself in the foot if there's, eg, an error in one of your hooks so the function never finishes. If you start getting bugs, try `model.reset_hooks()` to clean things up. Further, if you *do* add hooks of your own that you want to keep, which you can do with `add_perma_hook` on the relevant HookPoint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TPg2ev2Y2JZ7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywH_B38-XMAo"
      },
      "source": [
        "### Activation Patching on the Indirect Object Identification Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sBrsqucXMAp"
      },
      "source": [
        "For a somewhat more involved example, let's use hooks to apply **[activation patching](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=qeWBvs-R-taFfcCq-S_hgMqx)** on the **[Indirect Object Identification](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=iWsV3s5Kdd2ca3zNgXr5UPHa)** (IOI) task.\n",
        "\n",
        "The IOI task is the task of identifying that a sentence like \"After John and Mary went to the store, Mary gave a bottle of milk to\" continues with \" John\" rather than \" Mary\" (ie, finding the indirect object), and Redwood Research have [an excellent paper studying the underlying circuit in GPT-2 Small](https://arxiv.org/abs/2211.00593).\n",
        "\n",
        "**[Activation patching](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=qeWBvs-R-taFfcCq-S_hgMqx)** is a technique from [Kevin Meng and David Bau's excellent ROME paper](https://rome.baulab.info/). The goal is to identify which model activations are important for completing a task. We do this by setting up a **clean prompt** and a **corrupted prompt** and a **metric** for performance on the task. We then pick a specific model activation, run the model on the corrupted prompt, but then *intervene* on that activation and patch in its value when run on the clean prompt. We then apply the metric, and see how much this patch has recovered the clean performance.\n",
        "(See [a more detailed demonstration of activation patching here](https://colab.research.google.com/github/TransformerLensOrg/TransformerLens/blob/main/demos/Exploratory_Analysis_Demo.ipynb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiNEFmEOXMAp"
      },
      "source": [
        "Here, our clean prompt is \"After John and Mary went to the store, **Mary** gave a bottle of milk to\", our corrupted prompt is \"After John and Mary went to the store, **John** gave a bottle of milk to\", and our metric is the difference between the correct logit ( John) and the incorrect logit ( Mary) on the final token.\n",
        "\n",
        "We see that the logit difference is significantly positive on the clean prompt, and significantly negative on the corrupted prompt, showing that the model is capable of doing the task!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4oshcwRXMAv",
        "outputId": "2281c0cd-4972-4e17-fe3f-f2fc3752d5b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean logit difference: 4.276\n",
            "Corrupted logit difference: -2.738\n"
          ]
        }
      ],
      "source": [
        "clean_prompt = \"After John and Mary went to the store, Mary gave a bottle of milk to\"\n",
        "corrupted_prompt = \"After John and Mary went to the store, John gave a bottle of milk to\"\n",
        "\n",
        "clean_tokens = model.to_tokens(clean_prompt)\n",
        "corrupted_tokens = model.to_tokens(corrupted_prompt)\n",
        "\n",
        "def logits_to_logit_diff(logits, correct_answer=\" John\", incorrect_answer=\" Mary\"):\n",
        "    # model.to_single_token maps a string value of a single token to the token index for that token\n",
        "    # If the string is not a single token, it raises an error.\n",
        "    correct_index = model.to_single_token(correct_answer)\n",
        "    incorrect_index = model.to_single_token(incorrect_answer)\n",
        "    return logits[0, -1, correct_index] - logits[0, -1, incorrect_index]\n",
        "\n",
        "# We run on the clean prompt with the cache so we store activations to patch in later.\n",
        "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
        "clean_logit_diff = logits_to_logit_diff(clean_logits)\n",
        "print(f\"Clean logit difference: {clean_logit_diff.item():.3f}\")\n",
        "\n",
        "# We don't need to cache on the corrupted prompt.\n",
        "corrupted_logits = model(corrupted_tokens)\n",
        "corrupted_logit_diff = logits_to_logit_diff(corrupted_logits)\n",
        "print(f\"Corrupted logit difference: {corrupted_logit_diff.item():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmr2O6tEXMAw"
      },
      "source": [
        "We now setup the hook function to do activation patching. Here, we'll patch in the [residual stream](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=DHp9vZ0h9lA9OCrzG2Y3rrzH) at the start of a specific layer and at a specific position. This will let us see how much the model is using the residual stream at that layer and position to represent the key information for the task.\n",
        "\n",
        "We want to iterate over all layers and positions, so we write the hook to take in an position parameter. Hook functions must have the input signature (activation, hook), but we can use `functools.partial` to set the position parameter before passing it to `run_with_hooks`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e4da3304b76944c7b77a5a0283c26b58",
            "bf6836f1e74c486bb54d1953fb2de847",
            "7f11c7ec377c407f82d32f43852fcd41",
            "c0eeb1e756f84219983f1d90727628ad",
            "5ff330f7c5a943f2a9bf4b752a6e4f4f",
            "75e0a891703449d5a42b22631739add3",
            "f11869041c2a4a48ac3fa97e98a623b3",
            "169adb50059e460bbc3d254669cc6294",
            "692bc0f171c147e9a17158b5195979c5",
            "5eaa6013e1e245a19bc07159037a09bb",
            "12bcf7a24ea94eb6810c6e2205e9d176"
          ]
        },
        "id": "qkYyPhhQXMAw",
        "outputId": "8272797f-89e8-4cd1-e22d-652ac7537842"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4da3304b76944c7b77a5a0283c26b58"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# We define a residual stream patching hook\n",
        "# We choose to act on the residual stream at the start of the layer, so we call it resid_pre\n",
        "# The type annotations are a guide to the reader and are not necessary\n",
        "def residual_stream_patching_hook(\n",
        "    resid_pre: Float[torch.Tensor, \"batch pos d_model\"],\n",
        "    hook: HookPoint,\n",
        "    position: int\n",
        ") -> Float[torch.Tensor, \"batch pos d_model\"]:\n",
        "    # Each HookPoint has a name attribute giving the name of the hook.\n",
        "    clean_resid_pre = clean_cache[hook.name]\n",
        "    resid_pre[:, position, :] = clean_resid_pre[:, position, :]\n",
        "    return resid_pre\n",
        "\n",
        "# We make a tensor to store the results for each patching run. We put it on the model's device to avoid needing to move things between the GPU and CPU, which can be slow.\n",
        "num_positions = len(clean_tokens[0])\n",
        "ioi_patching_result = torch.zeros((model.cfg.n_layers, num_positions), device=model.cfg.device) ##patching for each (layer, position).\n",
        "\n",
        "for layer in tqdm.tqdm(range(model.cfg.n_layers)):\n",
        "    for position in range(num_positions):\n",
        "        # Use functools.partial to create a temporary hook function with the position fixed\n",
        "        temp_hook_fn = partial(residual_stream_patching_hook, position=position)\n",
        "        # Run the model with the patching hook\n",
        "        patched_logits = model.run_with_hooks(corrupted_tokens, fwd_hooks=[\n",
        "            (utils.get_act_name(\"resid_pre\", layer), temp_hook_fn)\n",
        "        ])\n",
        "        # Calculate the logit difference\n",
        "        patched_logit_diff = logits_to_logit_diff(patched_logits).detach()\n",
        "        # Store the result, normalizing by the clean and corrupted logit difference so it's between 0 and 1 (ish)\n",
        "        ioi_patching_result[layer, position] = (patched_logit_diff - corrupted_logit_diff)/(clean_logit_diff - corrupted_logit_diff)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBEg0fWwXMAx"
      },
      "source": [
        "We can now visualize the results, and see that this computation is extremely localised within the model. Initially, the second subject (Mary) token is all that matters (naturally, as it's the only different token), and all relevant information remains here until heads in layer 7 and 8 move this to the final token where it's used to predict the indirect object.\n",
        "(Note - the heads are in layer 7 and 8, not 8 and 9, because we patched in the residual stream at the *start* of each layer)\n",
        "\n",
        "mine: clean prompt v.s. corrupt prompt -- only one token is different."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nXOQnWLXMA7",
        "outputId": "e26496af-a3c9-4e39-857c-7e1bcaeb37d6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"1d04e6ee-31ed-4e10-b7a1-08f454ff13b2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1d04e6ee-31ed-4e10-b7a1-08f454ff13b2\")) {                    Plotly.newPlot(                        \"1d04e6ee-31ed-4e10-b7a1-08f454ff13b2\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"\\u003c|endoftext|\\u003e_0\",\"After_1\",\" John_2\",\" and_3\",\" Mary_4\",\" went_5\",\" to_6\",\" the_7\",\" store_8\",\",_9\",\" Mary_10\",\" gave_11\",\" a_12\",\" bottle_13\",\" of_14\",\" milk_15\",\" to_16\"],\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9981480240821838,0.0016014170832931995,0.00014983542496338487,-0.00037064551725052297,-2.1482755983015522e-05,-0.000627894711215049,-0.0005147703341208398],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9980558156967163,0.0022839705925434828,0.0001830113324103877,-0.000504164956510067,-0.0002675826835911721,-5.1395454647718e-05,-0.0012810792541131377],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9967373609542847,0.004082539584487677,0.000974066206254065,4.3509378883754835e-05,-0.0001593531051184982,-0.0003361099516041577,-0.0019437815062701702],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9905893206596375,0.019987665116786957,0.001896193134598434,0.0010143123799934983,-6.716760253766552e-05,0.0009109776583500206,-0.0019008159870281816],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9616512656211853,0.08534800261259079,0.005204265471547842,0.0030527268536388874,0.00019687994790729135,0.001105954055674374,-0.002283698646351695],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9630993008613586,0.08437121659517288,0.004121969919651747,0.0007184486021287739,0.000102790909295436,0.0010028912220150232,-0.004215243272483349],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9359176158905029,0.11111806333065033,0.007705239113420248,0.000375812262063846,0.00036575071862898767,0.001326492172665894,0.018744928762316704],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7701548933982849,0.03741942718625069,0.0020680550951510668,-8.239589078584686e-05,0.00013460713671520352,0.001724603003822267,0.44990602135658264],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09650597721338272,0.025926152244210243,0.001972062513232231,0.0003298554802313447,0.00042503225267864764,0.0018855876987800002,0.8994725346565247],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.023322386667132378,0.018538258969783783,0.0015875485260039568,0.0005272792768664658,0.0002534421219024807,0.0008737227180972695,0.9612759947776794],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.008558566682040691,0.006340676452964544,0.0005816660122945905,-0.0003418205596972257,0.00011094891669927165,0.0006477459101006389,0.9495818614959717]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Position: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Position\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Normalized Logit Difference After Patching Residual Stream on the IOI Task\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1d04e6ee-31ed-4e10-b7a1-08f454ff13b2');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Add the index to the end of the label, because plotly doesn't like duplicate labels\n",
        "token_labels = [f\"{token}_{index}\" for index, token in enumerate(model.to_str_tokens(clean_tokens))]\n",
        "imshow(ioi_patching_result, x=token_labels, xaxis=\"Position\", yaxis=\"Layer\", title=\"Normalized Logit Difference After Patching Residual Stream on the IOI Task\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnt-KEHEXMA8"
      },
      "source": [
        "## Hooks: Accessing Activations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HPS-Xpb3-yFo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyXyrD8YXMA-"
      },
      "source": [
        "Hooks can also be used to just **access** an activation - to run some function using that activation value, *without* changing the activation value. This can be achieved by just having the hook return nothing, and not editing the activation in place.\n",
        "\n",
        "This is useful for eg extracting activations for a specific task, or for doing some long-running calculation across many inputs, eg finding the text that most activates a specific neuron. (Note - everything this can do *could* be done with `run_with_cache` and post-processing, but this workflow can be more intuitive and memory efficient.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBhUf0zSXMA-"
      },
      "source": [
        "To demonstrate this, let's look for **[induction heads](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html)** in GPT-2 Small.\n",
        "\n",
        "Induction circuits are a very important circuit in generative language models, which are used to detect and continue repeated subsequences. They consist of two heads in separate layers that compose together, a **previous token head** which always attends to the previous token, and an **induction head** which attends to the token *after* an earlier copy of the current token.\n",
        "\n",
        "To see why this is important, let's say that the model is trying to predict the next token in a news article about Michael Jordan. The token \" Michael\", in general, could be followed by many surnames. But an induction head will look from that occurrence of \" Michael\" to the token after previous occurrences of \" Michael\", ie \" Jordan\" and can confidently predict that that will come next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DgEFj2NXMA_"
      },
      "source": [
        "An interesting fact about induction heads is that they generalise to arbitrary sequences of repeated tokens. We can see this by generating sequences of 50 random tokens, repeated twice, and plotting the average loss at predicting the next token, by position. We see that the model goes from terrible to very good at the halfway point.\n",
        "\n",
        "也就是说: 我有一个100长度的prompt(后50个重复前50个),分别基于前i个预测第i+1个,发现预测后50的效果明显好."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "xyjRrdLQXMA_",
        "outputId": "0f7dac76-3c70-4f14-a931-708ab3b67744"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"c13132b1-e20e-49f5-9c76-82f8e3a2c299\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c13132b1-e20e-49f5-9c76-82f8e3a2c299\")) {                    Plotly.newPlot(                        \"c13132b1-e20e-49f5-9c76-82f8e3a2c299\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98],\"xaxis\":\"x\",\"y\":[11.366578,14.05094,14.694366,11.934131,12.401121,13.82222,12.7496605,13.210833,12.437172,12.560435,12.64299,12.002296,12.49555,11.551773,12.135539,11.814117,12.597275,12.574695,11.769257,11.825121,10.794054,12.125197,12.208514,12.242575,12.366364,11.650583,10.799309,12.344912,12.097815,10.9438305,10.952,11.818374,11.555084,11.550753,10.988928,12.209543,10.452301,11.872388,11.714977,11.0585785,12.0808,11.350151,11.534587,11.2888155,11.227522,11.9999485,10.312478,11.824241,12.255859,10.548581,4.282768,1.4201959,0.4117692,0.29200074,0.55988854,0.3546719,0.14932585,0.16205497,0.3304574,0.29929674,0.28759062,0.29002446,0.16966388,0.20988676,0.13190138,0.2123321,0.023467593,0.13664374,0.0213405,0.49062806,0.23257864,0.20292611,0.077092305,0.07654021,0.026995521,0.13485248,0.09563343,0.1546291,0.055419277,0.10524086,0.037905,0.060635764,0.032411024,0.021876793,0.038605183,0.11815455,0.08687655,0.088888064,0.03997034,0.050619327,0.027084991,0.063848786,0.1728355,0.30831653,0.038246945,0.019236509,0.05024488,0.12119057,0.022895977],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Loss by position on random repeated tokens\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c13132b1-e20e-49f5-9c76-82f8e3a2c299');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "batch_size = 10\n",
        "seq_len = 50\n",
        "size = (batch_size, seq_len)\n",
        "input_tensor = torch.randint(1000, 10000, size)\n",
        "\n",
        "random_tokens = input_tensor.to(model.cfg.device)\n",
        "repeated_tokens = einops.repeat(random_tokens, \"batch seq_len -> batch (2 seq_len)\")\n",
        "repeated_logits = model(repeated_tokens)\n",
        "correct_log_probs = model.loss_fn(repeated_logits, repeated_tokens, per_token=True)\n",
        "loss_by_position = einops.reduce(correct_log_probs, \"batch position -> position\", \"mean\")\n",
        "line(loss_by_position, xaxis=\"Position\", yaxis=\"Loss\", title=\"Loss by position on random repeated tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxkKNOpnXMBA"
      },
      "source": [
        "The induction heads will be attending from the second occurrence of each token to the token *after* its first occurrence, ie the token `50-1==49` places back. So by looking at the average attention paid 49 tokens back, we can identify induction heads! Let's define a hook to do this!\n",
        "\n",
        "<details><summary>Technical details</summary>\n",
        "\n",
        "* We attach the hook to the attention pattern activation. There's one big pattern activation per layer, stacked across all heads, so we need to do some tensor manipulation to get a per-head score.\n",
        "* Hook functions can access global state, so we make a big tensor to store the induction head score for each head, and then we just add the score for each head to the appropriate position in the tensor.\n",
        "* To get a single hook function that works for each layer, we use the `hook.layer()` method to get the layer index (internally this is just inferred from the hook names).\n",
        "* As we want to add this to *every* activation pattern hook point, rather than giving the string for an activation name, this time we give a **name filter**. This is a Boolean function on hook point names, and it adds the hook function to every hook point where the function evaluates as true.\n",
        "    * `run_with_hooks` allows us to enter a list of (act_name, hook_function) pairs to all be added at once, so we could also have done this by inputting a list with a hook for each layer.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wn5nkbLHXMBA",
        "outputId": "c0ae14ee-78ad-458f-e16b-5c3729d7451f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"190ab42e-4456-4833-a298-6f585a1583e4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"190ab42e-4456-4833-a298-6f585a1583e4\")) {                    Plotly.newPlot(                        \"190ab42e-4456-4833-a298-6f585a1583e4\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.009955878369510174,9.966958168661222e-05,0.010546973906457424,4.0583410054750857e-07,0.00022813043324276805,0.00019768899073824286,0.00977946724742651,0.0006674872129224241,0.00908320676535368,0.00915559846907854,0.006828702986240387,0.015242615714669228],[0.0011627675266936421,0.00045248764217831194,0.0021361575927585363,0.01417490839958191,0.004926139954477549,0.010640118271112442,0.015927109867334366,0.013070465996861458,0.012896527536213398,0.016126573085784912,0.006526595447212458,0.000517632404807955],[0.0044746194034814835,0.01877586357295513,0.003041735850274563,0.0019074507290497422,0.012237360700964928,0.002584304893389344,0.0039876471273601055,0.008248553611338139,0.004771647043526173,0.0017633740790188313,0.0006906316848471761,0.010382029227912426],[0.015542104840278625,0.007110548205673695,0.002217961009591818,0.012544052675366402,0.021509619429707527,0.011987114325165749,0.00174334819894284,0.0009274697513319552,0.005935505498200655,0.01233423687517643,0.009232483804225922,0.006464063189923763],[0.01664578728377819,0.014668889343738556,0.013992691412568092,0.008478098548948765,0.01899615488946438,0.012697082944214344,0.008333329111337662,0.0017152393702417612,0.01665916107594967,0.014090241864323616,0.018890956416726112,8.906972381872436e-11],[0.451614111661911,0.9170698523521423,0.01424565352499485,0.0065706996247172356,0.011130396276712418,0.9321417212486267,0.008963020518422127,0.018100803717970848,0.02871188521385193,0.029120853170752525,0.02137076109647751,0.01733485981822014],[0.008789685554802418,0.017398007214069366,0.01834423653781414,0.015153961256146431,0.02248268947005272,0.011032403446733952,0.03012258931994438,0.01068038959056139,0.009857730939984322,0.9169892072677612,0.036462243646383286,0.01406988874077797],[0.01107383705675602,0.17768746614456177,0.8614926934242249,0.019131189212203026,0.018100876361131668,0.016298996284604073,0.04784739762544632,0.08873092383146286,0.01723749376833439,0.019047973677515984,0.9243332743644714,0.06009266525506973],[0.015750497579574585,0.40704065561294556,0.014495478942990303,0.050178349018096924,0.017805716022849083,0.012079598382115364,0.15166832506656647,0.013180013746023178,0.032852329313755035,0.03178909420967102,0.06760691851377487,0.022921957075595856],[0.25689446926116943,0.19054049253463745,0.10555234551429749,0.012684683315455914,0.0927107185125351,0.026271803304553032,0.4618716239929199,0.029983991757035255,0.05182349309325218,0.4789004623889923,0.016641730442643166,0.03995012864470482],[0.339070200920105,0.5105082392692566,0.038450296968221664,0.14799615740776062,0.05797654390335083,0.01543364953249693,0.3008923828601837,0.47816023230552673,0.05431150645017624,0.015494456514716148,0.16141793131828308,0.2569926977157593],[0.017057929188013077,0.053864460438489914,0.03378748893737793,0.009234139695763588,0.03453892469406128,0.1011928990483284,0.04960957169532776,0.07048070430755615,0.009171898476779461,0.30352190136909485,0.40838193893432617,0.022866230458021164]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Induction Score by Head\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('190ab42e-4456-4833-a298-6f585a1583e4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# We make a tensor to store the induction score for each head. We put it on the model's device to avoid needing to move things between the GPU and CPU, which can be slow.\n",
        "induction_score_store = torch.zeros((model.cfg.n_layers, model.cfg.n_heads), device=model.cfg.device)\n",
        "def induction_score_hook(\n",
        "    pattern: Float[torch.Tensor, \"batch head_index dest_pos source_pos\"],\n",
        "    hook: HookPoint,\n",
        "):\n",
        "    # We take the diagonal of attention paid from each destination position to source positions seq_len-1 tokens back\n",
        "    # (This only has entries for tokens with index>=seq_len)\n",
        "    induction_stripe = pattern.diagonal(dim1=-2, dim2=-1, offset=1-seq_len)\n",
        "    # Get an average score per head\n",
        "    induction_score = einops.reduce(induction_stripe, \"batch head_index position -> head_index\", \"mean\")\n",
        "    # Store the result.\n",
        "    induction_score_store[hook.layer(), :] = induction_score\n",
        "\n",
        "# We make a boolean filter on activation names, that's true only on attention pattern names.\n",
        "pattern_hook_names_filter = lambda name: name.endswith(\"pattern\")\n",
        "\n",
        "model.run_with_hooks(\n",
        "    repeated_tokens,\n",
        "    return_type=None, # For efficiency, we don't need to calculate the logits\n",
        "    fwd_hooks=[(\n",
        "        pattern_hook_names_filter,\n",
        "        induction_score_hook\n",
        "    )]\n",
        ")\n",
        "\n",
        "imshow(induction_score_store, xaxis=\"Head\", yaxis=\"Layer\", title=\"Induction Score by Head\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPgw-ks4XMBB"
      },
      "source": [
        "Head 5 in Layer 5 scores extremely highly on this score, and we can feed in a shorter repeated random sequence, visualize the attention pattern for it and see this directly - including the \"induction stripe\" at `seq_len-1` tokens back.\n",
        "\n",
        "This time we put in a hook on the attention pattern activation to visualize the pattern of the relevant head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cy8p54VjXMBC",
        "outputId": "3f25db6f-10cd-483c-cf94-5e3201b3e9c9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"circuits-vis-fcf89ad6-45d6\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.0/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-fcf89ad6-45d6\",\n",
              "      AttentionPatterns,\n",
              "      {\"tokens\": [\"use\", \" advice\", \" Social\", \"\\u00f6\", \"\\u00b7\", \" fought\", \" Le\", \" allegedly\", \" NO\", \"alth\", \"car\", \" prepared\", \"new\", \"rant\", \"roll\", \" hours\", \" published\", \"66\", \"ension\", \" 44\", \"use\", \" advice\", \" Social\", \"\\u00f6\", \"\\u00b7\", \" fought\", \" Le\", \" allegedly\", \" NO\", \"alth\", \"car\", \" prepared\", \"new\", \"rant\", \"roll\", \" hours\", \" published\", \"66\", \"ension\", \" 44\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9737270474433899, 0.0262729711830616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9820428490638733, 0.017020266503095627, 0.0009368456667289138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9895542860031128, 0.00866580568253994, 0.0004119748482480645, 0.0013679902767762542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8543053865432739, 0.0780181884765625, 0.0008415378979407251, 0.00013599172234535217, 0.06669897586107254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9374335408210754, 0.033002182841300964, 0.0015577428275719285, 2.5352785542054335e-06, 0.0010925536043941975, 0.026911530643701553, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.976921021938324, 0.0038436956238001585, 2.234029489045497e-05, 3.521895996527746e-05, 0.005183499306440353, 0.01217629387974739, 0.0018179028993472457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9473506212234497, 0.013174930587410927, 0.0013492131838575006, 1.180242543341592e-05, 0.0009449435747228563, 0.011318957433104515, 0.018021011725068092, 0.007828536443412304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9847127199172974, 0.0010781448800116777, 0.002173440996557474, 5.48224352314719e-06, 0.0004914223100058734, 0.0013570792507380247, 0.0001018581388052553, 0.00028538500191643834, 0.009794448502361774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9915198683738708, 0.0044833519496023655, 0.00012727153080049902, 0.0001670209167059511, 0.0016301727155223489, 0.0011521612759679556, 0.0003231288574170321, 0.00012646260438486934, 0.00039313812158070505, 7.735053804935887e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8908807635307312, 0.024311939254403114, 1.7341229977319017e-05, 4.1577197407605127e-05, 0.0008967601461336017, 0.07334909588098526, 0.0009482800960540771, 0.004280842375010252, 0.005168660078197718, 7.830293725419324e-06, 9.693214815342799e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.817081093788147, 0.13517087697982788, 0.011989914812147617, 1.1421690032875631e-05, 0.0003511958639137447, 0.00945067685097456, 0.01946328766644001, 0.0006557486485689878, 0.0005761014763265848, 2.9927012292318977e-05, 1.658979817875661e-05, 0.005203105043619871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9082697033882141, 0.006068143527954817, 0.013871830888092518, 0.0008237074362114072, 0.011908311396837234, 0.01554207131266594, 0.008354817517101765, 0.0020781648345291615, 0.0013173273764550686, 0.0021398114040493965, 0.003944162279367447, 0.0012376609956845641, 0.02444424293935299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9479592442512512, 0.0021026760805398226, 0.01193847507238388, 0.00012338522356003523, 3.537495786076761e-06, 0.00014498857490252703, 0.0005875465576536953, 2.5534713131492026e-05, 0.0013609088491648436, 0.0003395720850676298, 0.01007620245218277, 0.0157905463129282, 0.006346344482153654, 0.003201034851372242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9393549561500549, 0.006392289884388447, 0.0018427352188155055, 6.116198164818343e-06, 0.0003358719404786825, 0.0020515176001936197, 0.003801520448178053, 0.0012357976520434022, 0.0002194812404923141, 0.0003869338543154299, 5.012214751332067e-05, 0.008153197355568409, 0.026924636214971542, 0.002938011661171913, 0.0063067772425711155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9339620471000671, 0.0017828113632276654, 0.005864645820111036, 0.000199502072064206, 7.227147580124438e-05, 0.001453535514883697, 0.0025924306828528643, 0.0004859396431129426, 0.002229833509773016, 0.00015120525495149195, 0.012292936444282532, 0.005057854112237692, 0.012368598021566868, 0.003944497089833021, 0.0062751127406954765, 0.011266660876572132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8931334614753723, 0.0015468199271708727, 0.013001665472984314, 7.96635686128866e-06, 5.864337435923517e-05, 0.0008863371913321316, 0.0032020823564380407, 3.214758908143267e-05, 0.00018022512085735798, 1.1455734238552395e-05, 7.600105163874105e-05, 0.0004202726122457534, 0.001612616004422307, 0.028539085760712624, 0.010535502806305885, 0.025432026013731956, 0.021323613822460175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9847024083137512, 0.00045824647531844676, 0.0001722048327792436, 6.160975090097054e-07, 4.7827966227487195e-06, 0.0005806126864627004, 0.00044618724496103823, 0.00041201553540304303, 0.0013038743054494262, 0.00031760730780661106, 6.99415395502001e-05, 0.0013941085198894143, 5.5830587371019647e-05, 0.0009110421524383128, 0.0001955802144948393, 0.000396028597606346, 0.0011691706022247672, 0.007409737445414066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8922598958015442, 0.010283716022968292, 0.007569305133074522, 0.015225780196487904, 0.000603529391810298, 0.0014377714833244681, 0.018397411331534386, 0.000181866911589168, 0.0021135706920176744, 3.8036650948924944e-05, 0.009962501004338264, 0.003998196218162775, 0.0012666822876781225, 0.002186268102377653, 0.003267065854743123, 0.0015871906653046608, 0.019133716821670532, 0.008779392577707767, 0.0017080693505704403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5637850761413574, 2.2041742340661585e-05, 0.00038083098479546607, 1.3938017673353897e-07, 4.306914647145277e-08, 0.0001288325438508764, 5.202714601182379e-05, 4.098215413250728e-06, 0.00043821678264066577, 1.0102498890773859e-05, 2.0490140741458163e-05, 0.00021747533173765987, 2.5249997634091415e-05, 2.1293963072821498e-05, 0.002207203535363078, 5.8927667851094157e-05, 0.002418374177068472, 0.0032775455620139837, 0.4260479211807251, 0.0008841017843224108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14634987711906433, 0.4510916769504547, 0.027205228805541992, 0.003008269937708974, 0.0007913715671747923, 0.08009303361177444, 0.005927639082074165, 0.0006846353644505143, 0.0021268511191010475, 0.0027747598942369223, 0.00023907265858724713, 0.002550537697970867, 0.005493414122611284, 0.015832215547561646, 0.0003449993673712015, 0.0005726668750867248, 0.0021751606836915016, 0.03904319554567337, 0.1698266863822937, 0.041207652539014816, 0.0026610144414007664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1588301807641983, 0.09413877129554749, 0.6926900744438171, 4.7764006012585014e-05, 8.085336048679892e-06, 0.009355566464364529, 0.0008445510757155716, 2.443790663164691e-06, 0.0001377410371787846, 1.1189789574928e-06, 4.677354354498675e-06, 0.0003472109674476087, 0.0026314801070839167, 0.0004504164680838585, 0.006463209632784128, 0.0005723321228288114, 0.001266839331947267, 0.006402328610420227, 0.0018093092367053032, 0.006555440369993448, 0.0003791518392972648, 0.01706133596599102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0507238395512104, 0.004356134217232466, 0.00013167195720598102, 0.93964684009552, 0.0005500880652107298, 0.002771187573671341, 1.4556246242136694e-05, 5.017395324102836e-06, 1.5498708307859488e-05, 7.02077898040443e-08, 8.694883035786916e-06, 3.654152897070162e-05, 3.6079711662750924e-06, 2.594179386505857e-05, 7.59087424739846e-06, 7.100912853275076e-07, 4.6297875087475404e-05, 7.143527909647673e-05, 0.00012089155643479899, 0.000561000662855804, 1.3380984455579892e-05, 0.0007342093158513308, 0.00015471279039047658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04466324299573898, 0.0028326697647571564, 7.648682367289439e-05, 0.00015513764810748398, 0.7502217888832092, 0.1919575184583664, 9.640491043683141e-05, 0.00016210104513447732, 0.00012769455497618765, 1.1226586138946004e-05, 8.733231879887171e-06, 0.0002813311293721199, 5.207761569181457e-05, 0.008386502042412758, 4.340233772381907e-06, 6.482672324636951e-05, 3.802950232056901e-05, 7.603670383105054e-05, 0.00012636416067834944, 9.22799008549191e-05, 4.0301836179423844e-07, 0.00011281618208158761, 2.522413069527829e-06, 0.00044938692008145154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0136062391102314, 0.006971819791942835, 3.188595292158425e-05, 1.8455398276273627e-06, 0.0023010680451989174, 0.9711790680885315, 0.0003632439475040883, 8.45976173877716e-05, 0.00010611514881020412, 4.505663468989951e-07, 2.987568166190613e-07, 0.0008592635276727378, 8.84485270944424e-05, 0.0003481197636574507, 9.285117812396493e-07, 3.160546111757867e-05, 1.2802072888007388e-05, 5.803379099234007e-05, 0.00010517534974496812, 6.438309355871752e-05, 1.8867468725147774e-06, 0.0009238768252544105, 4.681064638134558e-06, 8.993229130282998e-06, 0.002845223993062973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019611306488513947, 0.004386154469102621, 6.198722985573113e-05, 4.885768589701911e-08, 4.2524367017904297e-05, 0.0036122521851211786, 0.9598399996757507, 0.005622244905680418, 0.002344567561522126, 5.173993713469827e-07, 1.962153874046635e-06, 0.0016548263374716043, 0.0005915339570492506, 0.001169586437754333, 5.784231689176522e-06, 8.118995174299926e-05, 4.500300929066725e-05, 0.0001849783438956365, 5.086977398605086e-05, 0.000111328401544597, 6.848466000519693e-06, 3.85396160709206e-05, 4.853071914112661e-06, 1.2763491952227923e-07, 3.953082341467962e-06, 0.0005269552930258214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008729123510420322, 0.00017810783174354583, 2.8806312002416234e-07, 4.138274221077154e-07, 6.864992610644549e-05, 0.0009331199107691646, 0.0001488830748712644, 0.9844523668289185, 0.004786375444382429, 0.0001132896650233306, 7.25545532986871e-07, 7.424702926073223e-05, 1.4996358004282229e-05, 0.00019790712394751608, 2.995068371092202e-07, 4.872013960266486e-06, 5.296111794450553e-06, 4.536831511359196e-06, 0.00011268968228250742, 3.4171025617979467e-06, 8.272540071629919e-06, 1.237986271007685e-05, 3.665547154696469e-08, 9.025117719829723e-07, 1.6053079889388755e-05, 0.00011404424003558233, 1.8653661754797213e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04082169756293297, 0.003618433838710189, 4.8210502427536994e-05, 1.9615818303009291e-07, 5.380281072575599e-05, 0.0021802405826747417, 0.003327243495732546, 0.0018782124388962984, 0.9307870268821716, 0.004815405700355768, 1.4430276678467635e-05, 0.0028288080357015133, 0.0001046408069669269, 0.0029309175442904234, 0.0009514765115454793, 6.522196053992957e-05, 0.0002954130177386105, 0.00012317558866925538, 0.001551239751279354, 0.0005327718099579215, 0.00022083611111156642, 0.0004432721179910004, 1.939156027219724e-05, 5.825709763485065e-07, 1.663282819208689e-05, 0.0004773263353854418, 0.0011258200975134969, 0.000767689838539809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13800935447216034, 0.0003385838062968105, 0.00015972652181517333, 3.422568184419106e-08, 1.2696329577011056e-05, 0.00024196661252062768, 3.8219157431740314e-05, 3.751519398065284e-05, 0.004743278957903385, 0.8406777381896973, 0.0001887540565803647, 0.00015232608711812645, 1.2507432074926328e-05, 0.0002236285072285682, 0.00013282443978823721, 6.470834341598675e-05, 0.00013950421998742968, 9.763532580109313e-05, 0.0004387960070744157, 4.4860902562504634e-05, 6.358889368129894e-05, 0.00034255790524184704, 5.2226645493647084e-05, 5.293432536745968e-07, 4.435891696630279e-06, 6.54347168165259e-05, 2.914482593041612e-06, 3.872663910442498e-06, 0.013709748163819313, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007798762992024422, 0.00022834629635326564, 4.6384946017496986e-07, 6.367677087837365e-07, 1.5816745872143656e-05, 4.7439083573408425e-05, 5.239070105744759e-06, 7.306558018171927e-06, 1.2522126780822873e-05, 3.3302333690699015e-07, 0.9909055233001709, 0.00045220478205010295, 5.365327069739578e-06, 7.535887561971322e-05, 8.799969691608567e-06, 7.89504611020675e-06, 0.00023918120132293552, 2.256896095786942e-06, 7.641861884621903e-05, 5.5141779739642516e-05, 4.378313406050438e-06, 2.181060699513182e-05, 4.4351477157533736e-08, 1.258427687389485e-06, 2.069825995931751e-06, 1.2951696589880157e-05, 3.9528120510112785e-07, 1.1202276937183342e-06, 7.9817673395155e-06, 2.9978505153849255e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.042284343391656876, 0.011305336840450764, 7.640699664079875e-07, 2.2586050363315735e-06, 9.786370355868712e-05, 0.038269199430942535, 0.00023640785366296768, 0.0014555181842297316, 0.0029497782234102488, 1.2863498568549403e-06, 2.827169737429358e-05, 0.8946184515953064, 0.000523496069945395, 0.001179973711259663, 0.0009106355137191713, 0.00036046106833964586, 0.00020461619715206325, 2.910214607254602e-05, 0.0013425356009975076, 0.0003398243279661983, 0.00033255034941248596, 8.43034649733454e-05, 7.937682511283128e-08, 5.809831236547325e-06, 4.910861207463313e-06, 0.0023872887250036, 2.6967012672685087e-05, 0.00020931517065037042, 0.0007688838522881269, 5.801371116831433e-06, 3.4147673432016745e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006102928426116705, 0.016550440341234207, 4.6485070924973115e-05, 8.233602954987873e-08, 7.398419256787747e-06, 0.0005482262931764126, 0.000593138684052974, 1.573847112013027e-05, 3.5032899177167565e-05, 3.3504232987979776e-07, 1.8657554790024733e-07, 0.000460667914012447, 0.8416212201118469, 0.12311417609453201, 0.00635922746732831, 0.002699504140764475, 0.00016676213999744505, 0.0012130774557590485, 0.00013198891247157007, 8.468204759992659e-05, 4.615942543750862e-06, 6.99491283739917e-05, 4.916110356134595e-06, 3.4761166034513735e-07, 3.71195625348264e-07, 6.107363878982142e-05, 6.7285327531863e-05, 2.275831548104179e-06, 2.060149927274324e-05, 7.198155458354449e-07, 2.7881066344548344e-08, 1.652937862672843e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0404171422123909, 0.0013464416842907667, 0.0002881725085899234, 4.343583896115888e-06, 0.0006837462424300611, 0.0021492778323590755, 0.0012713986216112971, 0.00021145936625543982, 0.00014913539052940905, 2.368190689594485e-05, 9.255170880351216e-05, 7.46091318433173e-05, 0.0030381649266928434, 0.9153454899787903, 0.0020634918473660946, 0.002670771675184369, 0.0006971447728574276, 0.022915314882993698, 0.0016386568313464522, 0.00029437849298119545, 8.30199132906273e-06, 0.00011940939293708652, 3.610887142713182e-05, 1.2593977771757636e-05, 0.000383078760933131, 0.0011952179484069347, 0.00018445361638441682, 7.125888805603608e-05, 0.00012850709026679397, 6.062284592189826e-05, 4.517687557381578e-05, 6.895808724038943e-07, 0.0023790940176695585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03775651007890701, 0.0016132266027852893, 0.0003177846665494144, 8.171087984010228e-07, 4.6314994506246876e-07, 7.222019485197961e-05, 0.00012490902736317366, 4.997585165256169e-06, 0.0003066718054469675, 5.749355295847636e-06, 0.0002466128207743168, 0.003777747042477131, 0.0013358069118112326, 0.002113186754286289, 0.8997160792350769, 0.04417850449681282, 0.00033094992977567017, 0.001384939532727003, 0.0003935607383027673, 0.002321055391803384, 0.0004642207932192832, 0.00019271507335361093, 0.0005703868810087442, 5.92765218243585e-06, 2.4687210498086642e-08, 3.108325699940906e-06, 7.16592330718413e-06, 2.9240155186016636e-07, 7.98414257587865e-05, 1.2546398465929087e-05, 0.0001265132159460336, 0.00023837975459173322, 0.0008907333249226213, 0.0014062307309359312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08771783858537674, 0.007821416482329369, 5.662468174705282e-05, 1.4731131869893943e-08, 1.0490747627045494e-05, 0.0011058712843805552, 0.0004291172663215548, 5.523042636923492e-05, 3.919887603842653e-05, 2.7502044304128503e-06, 2.546168616390787e-06, 0.002755208173766732, 0.005722646601498127, 0.0011191918747499585, 0.0015876393299549818, 0.8757357597351074, 0.0010800447780638933, 0.003532156115397811, 0.0015019910642877221, 0.0006949505768716335, 4.3340980482753366e-05, 0.00023435073671862483, 6.934305019967724e-06, 2.7577918615406816e-08, 9.912458835970028e-07, 0.00019156669441144913, 2.9515418646042235e-05, 5.4682345762557816e-06, 2.4805774501146516e-06, 1.4659882481282693e-06, 7.256012395373546e-07, 8.567833720007911e-05, 0.004263886250555515, 0.0007048699189908803, 0.0034579611383378506, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018741462379693985, 0.00013177553773857653, 0.0001151907054008916, 8.336372729900177e-07, 3.8734546592422703e-07, 4.034390804008581e-05, 8.927338058128953e-05, 6.5760018514993135e-06, 6.646589463343844e-05, 2.0145337487065262e-07, 0.00012498503201641142, 0.00022737719700671732, 0.0003596782626118511, 4.087373235961422e-05, 8.65406691445969e-05, 0.00017062197730410844, 0.9720672369003296, 0.004511029925197363, 0.0017741514602676034, 0.00033421185798943043, 0.0006673701573163271, 8.272354534710757e-06, 8.590857760282233e-05, 4.4451999769989925e-07, 1.5395192676237457e-08, 3.916235073120333e-06, 1.856171184044797e-05, 1.744039764162153e-06, 2.306476017110981e-05, 6.561277245964448e-07, 5.5365380831062794e-05, 1.002774115477223e-05, 0.0001100561858038418, 2.098819095408544e-05, 6.0086229495937005e-05, 4.435600567376241e-05, 0.0, 0.0, 0.0, 0.0], [0.021614333614706993, 6.699936784571037e-05, 0.00023382958897855133, 1.946084609016907e-07, 1.0567928256932646e-06, 2.5699444449855946e-05, 0.0002104660088662058, 1.7352494978695177e-06, 6.270136509556323e-06, 8.374804139066327e-08, 2.3547661385237006e-06, 1.8064512914861552e-05, 0.00023376515309792012, 0.001895317924208939, 0.00020409416174516082, 0.0004746883932966739, 0.0029953729826956987, 0.9625540971755981, 0.00691427756100893, 0.00019762477313634008, 0.00011761223140638322, 1.78101454366697e-05, 8.19376073195599e-05, 8.319892685904051e-08, 6.341040403867737e-08, 1.503461476204393e-06, 1.595173125679139e-05, 1.2851933206547983e-07, 7.935282724247372e-07, 1.268652596309039e-07, 5.140130951986066e-07, 3.882859900272706e-08, 5.8853103837464005e-05, 0.0011026777792721987, 9.716644126456231e-05, 8.231291576521471e-05, 0.0007721150759607553, 0.0, 0.0, 0.0], [0.036683231592178345, 5.292119567457121e-06, 1.6796273030195152e-06, 3.2259253601729654e-10, 1.7678923214248243e-08, 9.71175995800877e-06, 6.970066351641435e-06, 3.922034920833539e-06, 1.5272406017174944e-05, 6.423094873753143e-07, 3.0026106401237485e-07, 2.1527788703679107e-05, 8.620285143479123e-07, 2.371107621002011e-05, 1.1333961538184667e-06, 4.370046099211322e-06, 2.1794727217638865e-05, 0.0007244806620292366, 0.9565503597259521, 7.606112922076136e-05, 0.005361164920032024, 3.4096636227332056e-05, 1.4788588487135712e-06, 1.9675812090724776e-09, 6.515209260982147e-09, 7.016106451374071e-07, 1.9081969071521598e-07, 3.605064478051645e-07, 3.97335998059134e-06, 1.5304269709304208e-06, 1.0370927583380762e-07, 7.635036922692962e-07, 1.8985110727953725e-07, 6.1644395827897824e-06, 2.6138322937185876e-06, 1.3529084981200867e-06, 1.0274129635945428e-05, 0.00042383253457956016, 0.0, 0.0], [0.039370130747556686, 0.0003585830272641033, 7.41930998628959e-05, 4.9509686505189165e-05, 4.653078576666303e-06, 4.69761471322272e-05, 0.0002299233601661399, 1.250448349310318e-06, 3.7233094190014526e-05, 8.911907656283802e-08, 7.931947038741782e-05, 0.00013509126438293606, 1.8374801584286615e-05, 0.0001029744089464657, 8.208496728911996e-05, 2.753642911557108e-05, 0.0005808327696286142, 0.001175031648017466, 0.00090598821407184, 0.9545682072639465, 7.417640154017136e-05, 0.0005086685996502638, 0.0001944841060321778, 8.633135439595208e-05, 8.952758889790857e-07, 1.429008443665225e-05, 3.4452030376996845e-05, 2.1258705373838893e-07, 1.695069659035653e-05, 4.816184286937641e-07, 3.1853684049565345e-05, 1.3589491572929546e-05, 2.5087774702114984e-05, 5.98193691985216e-05, 0.00011690238170558587, 1.1342107427481096e-05, 0.0002713192661758512, 0.0002638357982505113, 0.00042731984285637736, 0.0], [0.02540118619799614, 7.441657317031058e-07, 1.083011466107564e-05, 2.249714858848506e-09, 9.22188214680375e-10, 8.20854529592907e-06, 2.5448052838328294e-06, 1.0004332295920904e-07, 3.16087098326534e-05, 2.427833578622085e-07, 5.28918860709382e-07, 1.4262905096984468e-05, 1.5345697192969965e-06, 1.87780551641481e-06, 0.0002028696471825242, 2.141229060725891e-06, 0.00010114459291798994, 0.0009309824672527611, 0.10166086256504059, 5.5514923587907106e-05, 0.8627561926841736, 2.250216311949771e-06, 3.0665501981275156e-05, 5.196882923996782e-09, 3.199170095502524e-11, 8.736409284892943e-08, 1.2241630997777975e-07, 1.2374229418909977e-09, 1.2507468454714399e-05, 4.6357610017366824e-07, 1.629777557354828e-07, 2.719423264352372e-07, 1.1941983757424168e-07, 1.4462457897934655e-07, 5.527898247237317e-05, 3.5639260431707953e-07, 4.93334409839008e-05, 0.00016947872063610703, 0.008456651121377945, 3.8713624235242605e-05]]]}\n",
              "    )\n",
              "    </script>"
            ],
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0xffff425c9fd0>"
            ]
          },
          "metadata": {
            "text/html": {
              "Content-Type": "text/html"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "if IN_GITHUB:\n",
        "    torch.manual_seed(50)\n",
        "\n",
        "induction_head_layer = 5\n",
        "induction_head_index = 5\n",
        "size = (1, 20)\n",
        "input_tensor = torch.randint(1000, 10000, size)\n",
        "\n",
        "single_random_sequence = input_tensor.to(model.cfg.device)\n",
        "repeated_random_sequence = einops.repeat(single_random_sequence, \"batch seq_len -> batch (2 seq_len)\")\n",
        "def visualize_pattern_hook(\n",
        "    pattern: Float[torch.Tensor, \"batch head_index dest_pos source_pos\"],\n",
        "    hook: HookPoint,\n",
        "):\n",
        "    display(\n",
        "        cv.attention.attention_patterns(\n",
        "            tokens=model.to_str_tokens(repeated_random_sequence),\n",
        "            attention=pattern[0, induction_head_index, :, :][None, :, :] # Add a dummy axis, as CircuitsVis expects 3D patterns.\n",
        "        )\n",
        "    )\n",
        "\n",
        "model.run_with_hooks(\n",
        "    repeated_random_sequence,\n",
        "    return_type=None,\n",
        "    fwd_hooks=[(\n",
        "        utils.get_act_name(\"pattern\", induction_head_layer),\n",
        "        visualize_pattern_hook\n",
        "    )]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PxQhsKWXMBD"
      },
      "source": [
        "## Available Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_6zZrYzXMBD"
      },
      "source": [
        "TransformerLens comes with over 40 open source models available, all of which can be loaded into a consistent(-ish) architecture by just changing the name in `from_pretrained`. The open source models available are [documented here](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=jHj79Pj58cgJKdq4t-ygK-4h), and a set of interpretability friendly models I've trained are [documented here](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=NCJ6zH_Okw_mUYAwGnMKsj2m), including a set of toy language models (tiny one to four layer models) and a set of [SoLU models](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=FZ5W6GGcy6OitPEaO733JLqf) up to GPT-2 Medium size (300M parameters). You can see [a table of the official alias and hyper-parameters of available models here](https://github.com/TransformerLensOrg/TransformerLens/blob/main/transformer_lens/model_properties_table.md).\n",
        "\n",
        "**Note:** TransformerLens does not currently support multi-GPU models (which you want for models above eg 7B parameters), but this feature is coming soon!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eKrc7o4XMBE"
      },
      "source": [
        "\n",
        "Notably, this means that analysis can be near immediately re-run on a different model by just changing the name - to see this, let's load in DistilGPT-2 (a distilled version of GPT-2, with half as many layers) and copy the code from above to see the induction heads in that model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoRzjuUJXMBE",
        "outputId": "c90052b5-83e6-4bf8-bc14-cb14cf41cfb3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using pad_token, but it is not set yet.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained model distilgpt2 into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "# NBVAL_IGNORE_OUTPUT\n",
        "distilgpt2 = HookedTransformer.from_pretrained(\"distilgpt2\", device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe5XYV7eXMBG",
        "outputId": "25f928d9-7175-4514-c1c3-bf0dd3202ce9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"378fa384-2cc7-4a1c-b871-c643c0e527e8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"378fa384-2cc7-4a1c-b871-c643c0e527e8\")) {                    Plotly.newPlot(                        \"378fa384-2cc7-4a1c-b871-c643c0e527e8\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.009922467172145844,0.00014764934894628823,0.011443736031651497,3.4372510526736733e-06,0.0006867930642329156,5.491139290825231e-06,0.008899171836674213,0.0014873683685436845,0.008349093608558178,0.00954477023333311,0.009120927192270756,0.01596890762448311],[0.003026863094419241,0.018020611256361008,0.003568781539797783,0.0006068727816455066,0.013361244462430477,0.002166191814467311,0.005081023555248976,0.01559095922857523,0.0044562919065356255,8.614760008640587e-05,0.003938235342502594,0.014764327555894852],[0.010219043120741844,0.00780068663880229,0.011151125654578209,0.0025892923586070538,0.019908905029296875,0.005215638317167759,0.00943383015692234,0.0015526963397860527,0.017547965049743652,0.011387993581593037,0.021231677383184433,1.451456820402222e-13],[0.007366393692791462,0.22952795028686523,0.8673726916313171,0.016448020935058594,0.01666181907057762,0.011658817529678345,0.01942884363234043,0.20720870792865753,0.014285862445831299,0.016440654173493385,0.9371501803398132,0.49821725487709045],[0.27513042092323303,0.23388457298278809,0.08511187136173248,0.010210886597633362,0.08357562869787216,0.02389742061495781,0.6404961943626404,0.025386787950992584,0.06823859363794327,0.651100218296051,0.015778401866555214,0.06186722218990326],[0.021418118849396706,0.07837661355733871,0.05457017943263054,0.01195995882153511,0.03577948361635208,0.17681372165679932,0.07745278626680374,0.10316655784845352,0.0073539442382752895,0.4502670466899872,0.19098441302776337,0.029486285522580147]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Induction Score by Head in Distil GPT-2\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('378fa384-2cc7-4a1c-b871-c643c0e527e8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# We make a tensor to store the induction score for each head. We put it on the model's device to avoid needing to move things between the GPU and CPU, which can be slow.\n",
        "distilgpt2_induction_score_store = torch.zeros((distilgpt2.cfg.n_layers, distilgpt2.cfg.n_heads), device=distilgpt2.cfg.device)\n",
        "def induction_score_hook(\n",
        "    pattern: Float[torch.Tensor, \"batch head_index dest_pos source_pos\"],\n",
        "    hook: HookPoint,\n",
        "):\n",
        "    # We take the diagonal of attention paid from each destination position to source positions seq_len-1 tokens back\n",
        "    # (This only has entries for tokens with index>=seq_len)\n",
        "    induction_stripe = pattern.diagonal(dim1=-2, dim2=-1, offset=1-seq_len)\n",
        "    # Get an average score per head\n",
        "    induction_score = einops.reduce(induction_stripe, \"batch head_index position -> head_index\", \"mean\")\n",
        "    # Store the result.\n",
        "    distilgpt2_induction_score_store[hook.layer(), :] = induction_score\n",
        "\n",
        "# We make a boolean filter on activation names, that's true only on attention pattern names.\n",
        "pattern_hook_names_filter = lambda name: name.endswith(\"pattern\")\n",
        "\n",
        "distilgpt2.run_with_hooks(\n",
        "    repeated_tokens,\n",
        "    return_type=None, # For efficiency, we don't need to calculate the logits\n",
        "    fwd_hooks=[(\n",
        "        pattern_hook_names_filter,\n",
        "        induction_score_hook\n",
        "    )]\n",
        ")\n",
        "\n",
        "imshow(distilgpt2_induction_score_store, xaxis=\"Head\", yaxis=\"Layer\", title=\"Induction Score by Head in Distil GPT-2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro0k1Y1dXMBJ"
      },
      "source": [
        "\n",
        "### An overview of the important open source models in the library\n",
        "\n",
        "* **GPT-2** - the classic generative pre-trained models from OpenAI\n",
        "    * Sizes Small (85M), Medium (300M), Large (700M) and XL (1.5B).\n",
        "    * Trained on ~22B tokens of internet text. ([Open source replication](https://huggingface.co/datasets/openwebtext))\n",
        "* **GPT-Neo** - Eleuther's replication of GPT-2\n",
        "    * Sizes 125M, 1.3B, 2.7B\n",
        "    * Trained on 300B(ish?) tokens of [the Pile](https://pile.eleuther.ai/) a large and diverse dataset including a bunch of code (and weird stuff)\n",
        "* **[OPT](https://ai.facebook.com/blog/democratizing-access-to-large-scale-language-models-with-opt-175b/)** - Meta AI's series of open source models\n",
        "    * Trained on 180B tokens of diverse text.\n",
        "    * 125M, 1.3B, 2.7B, 6.7B, 13B, 30B, 66B\n",
        "* **GPT-J** - Eleuther's 6B parameter model, trained on the Pile\n",
        "* **GPT-NeoX** - Eleuther's 20B parameter model, trained on the Pile\n",
        "* **StableLM** - Stability AI's 3B and 7B models, with and without chat and instruction fine-tuning\n",
        "* **Stanford CRFM models** - a replication of GPT-2 Small and GPT-2 Medium, trained on 5 different random seeds.\n",
        "    * Notably, 600 checkpoints were taken during training per model, and these are available in the library with eg `HookedTransformer.from_pretrained(\"stanford-gpt2-small-a\", checkpoint_index=265)`.\n",
        "- **BERT** - Google's bidirectional encoder-only transformer.\n",
        "    - Size Base (108M), trained on English Wikipedia and BooksCorpus.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZA2RigVXMBJ"
      },
      "source": [
        "\n",
        "### An overview of some interpretability-friendly models I've trained and included\n",
        "\n",
        "(Feel free to [reach out](mailto:neelnanda27@gmail.com) if you want more details on any of these models)\n",
        "\n",
        "Each of these models has about ~200 checkpoints taken during training that can also be loaded from TransformerLens, with the `checkpoint_index` argument to `from_pretrained`.\n",
        "\n",
        "Note that all models are trained with a Beginning of Sequence token, and will likely break if given inputs without that!\n",
        "\n",
        "* **Toy Models**: Inspired by [A Mathematical Framework](https://transformer-circuits.pub/2021/framework/index.html), I've trained 12 tiny language models, of 1-4L and each of width 512. I think that interpreting these is likely to be far more tractable than larger models, and both serve as good practice and will likely contain motifs and circuits that generalise to far larger models (like induction heads):\n",
        "    * Attention-Only models (ie without MLPs): attn-only-1l, attn-only-2l, attn-only-3l, attn-only-4l\n",
        "    * GELU models (ie with MLP, and the standard GELU activations): gelu-1l, gelu-2l, gelu-3l, gelu-4l\n",
        "    * SoLU models (ie with MLP, and [Anthropic's SoLU activation](https://transformer-circuits.pub/2022/solu/index.html), designed to make MLP neurons more interpretable): solu-1l, solu-2l, solu-3l, solu-4l\n",
        "    * All models are trained on 22B tokens of data, 80% from C4 (web text) and 20% from Python Code\n",
        "    * Models of the same layer size were trained with the same weight initialization and data shuffle, to more directly compare the effect of different activation functions.\n",
        "* **SoLU** models: A larger scan of models trained with [Anthropic's SoLU activation](https://transformer-circuits.pub/2022/solu/index.html), in the hopes that it makes the MLP neuron interpretability easier.\n",
        "    * A scan up to GPT-2 Medium size, trained on 30B tokens of the same data as toy models, 80% from C4 and 20% from Python code.\n",
        "        * solu-6l (40M), solu-8l (100M), solu-10l (200M), solu-12l (340M)\n",
        "    * An older scan up to GPT-2 Medium size, trained on 15B tokens of [the Pile](https://pile.eleuther.ai/)\n",
        "        * solu-1l-pile (13M), solu-2l-pile (13M), solu-4l-pile (13M), solu-6l-pile (40M), solu-8l-pile (100M), solu-10l-pile (200M), solu-12l-pile (340M)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU0N-t5pXMBK"
      },
      "source": [
        "## Other Resources:\n",
        "\n",
        "* [Concrete Steps to Get Started in Mechanistic Interpretability](https://neelnanda.io/getting-started): A guide I wrote for how to get involved in mechanistic interpretability, and how to learn the basic skills\n",
        "* [A Comprehensive Mechanistic Interpretability Explainer](https://neelnanda.io/glossary): An overview of concepts in the field and surrounding ideas in ML and transformers, with long digressions to give context and build intuitions.\n",
        "* [Concrete Open Problems in Mechanistic Interpretability](https://neelnanda.io/concrete-open-problems), a doc I wrote giving a long list of open problems in mechanistic interpretability, and thoughts on how to get started on trying to work on them.\n",
        "    * There's a lot of low-hanging fruit in the field, and I expect that many people reading this could use TransformerLens to usefully make progress on some of these!\n",
        "* Other demos:\n",
        "    * **[Exploratory Analysis Demo](https://neelnanda.io/exploratory-analysis-demo)**, a demonstration of my standard toolkit for how to use TransformerLens to explore a mysterious behaviour in a language model.\n",
        "    * [Interpretability in the Wild](https://github.com/redwoodresearch/Easy-Transformer) a codebase from Arthur Conmy and Alex Variengien at Redwood research using this library to do a detailed and rigorous reverse engineering of the Indirect Object Identification circuit, to accompany their paper\n",
        "        * Note - this was based on an earlier version of this library, called EasyTransformer. It's pretty similar, but several breaking changes have been made since.\n",
        "    * A [recorded walkthrough](https://www.youtube.com/watch?v=yo4QvDn-vsU) of me doing research with TransformerLens on whether a tiny model can re-derive positional information, with [an accompanying Colab](https://colab.research.google.com/github/TransformerLensOrg/TransformerLens/blob/main/No_Position_Experiment.ipynb)\n",
        "* [Neuroscope](https://neuroscope.io), a website showing the text in the dataset that most activates each neuron in some selected models. Good to explore to get a sense for what kind of features the model tends to represent, and as a \"wiki\" to get some info\n",
        "    * A tutorial on how to make an [Interactive Neuroscope](https://github.com/TransformerLensOrg/TransformerLens/blob/main/Hacky-Interactive-Lexoscope.ipynb), where you type in text and see the neuron activations over the text update live."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h09b4yiKXMBL"
      },
      "source": [
        "## Transformer architecture\n",
        "\n",
        "HookedTransformer is a somewhat adapted GPT-2 architecture, but is computationally identical. The most significant changes are to the internal structure of the attention heads:\n",
        "* The weights (W_K, W_Q, W_V) mapping the residual stream to queries, keys and values are 3 separate matrices, rather than big concatenated one.\n",
        "* The weight matrices (W_K, W_Q, W_V, W_O) and activations (keys, queries, values, z (values mixed by attention pattern)) have separate head_index and d_head axes, rather than flattening them into one big axis.\n",
        "    * The activations all have shape `[batch, position, head_index, d_head]`\n",
        "    * W_K, W_Q, W_V have shape `[head_index, d_model, d_head]` and W_O has shape `[head_index, d_head, d_model]`\n",
        "\n",
        "The actual code is a bit of a mess, as there's a variety of Boolean flags to make it consistent with the various different model families in TransformerLens - to understand it and the internal structure, I instead recommend reading the code in [CleanTransformerDemo](https://colab.research.google.com/github/TransformerLensOrg/TransformerLens/blob/clean-transformer-demo/Clean_Transformer_Demo.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6GdDOuTXMBM"
      },
      "source": [
        "### Parameter Names\n",
        "\n",
        "Here is a list of the parameters and shapes in the model. By convention, all weight matrices multiply on the right (ie `new_activation = old_activation @ weights + bias`).\n",
        "\n",
        "Reminder of the key hyper-params:\n",
        "* `n_layers`: 12. The number of transformer blocks in the model (a block contains an attention layer and an MLP layer)\n",
        "* `n_heads`: 12. The number of attention heads per attention layer\n",
        "* `d_model`: 768. The residual stream width.\n",
        "* `d_head`: 64. The internal dimension of an attention head activation.\n",
        "* `d_mlp`: 3072. The internal dimension of the MLP layers (ie the number of neurons).\n",
        "* `d_vocab`: 50267. The number of tokens in the vocabulary.\n",
        "* `n_ctx`: 1024. The maximum number of tokens in an input prompt.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZrCZZ_NXMBN"
      },
      "source": [
        "**Transformer Block parameters:**\n",
        "Replace 0 with the relevant layer index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwm8vX9lXMBO",
        "outputId": "944901a6-4e78-4f25-f80d-b7383164b1a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "blocks.0.attn.W_Q torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_O torch.Size([12, 64, 768])\n",
            "blocks.0.attn.b_Q torch.Size([12, 64])\n",
            "blocks.0.attn.b_O torch.Size([768])\n",
            "blocks.0.attn.W_K torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_V torch.Size([12, 768, 64])\n",
            "blocks.0.attn.b_K torch.Size([12, 64])\n",
            "blocks.0.attn.b_V torch.Size([12, 64])\n",
            "blocks.0.mlp.W_in torch.Size([768, 3072])\n",
            "blocks.0.mlp.b_in torch.Size([3072])\n",
            "blocks.0.mlp.W_out torch.Size([3072, 768])\n",
            "blocks.0.mlp.b_out torch.Size([768])\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if name.startswith(\"blocks.0.\"):\n",
        "        print(name, param.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kdr9VqaXMBP"
      },
      "source": [
        "**Embedding & Unembedding parameters:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJkZChZwXMBQ",
        "outputId": "3f6fd93e-a96a-4ad6-fdc5-7047bd299b87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embed.W_E torch.Size([50257, 768])\n",
            "pos_embed.W_pos torch.Size([1024, 768])\n",
            "unembed.W_U torch.Size([768, 50257])\n",
            "unembed.b_U torch.Size([50257])\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if not name.startswith(\"blocks\"):\n",
        "        print(name, param.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXP-BzVQXMBW"
      },
      "source": [
        "### Activation + Hook Names\n",
        "\n",
        "Lets get out a list of the activation/hook names in the model and their shapes. In practice, I recommend using the `utils.get_act_name` function to get the names, but this is a useful fallback, and necessary to eg write a name filter function.\n",
        "\n",
        "Let's do this by entering in a short, 10 token prompt, and add a hook function to each activations to print its name and shape. To avoid spam, let's just add this to activations in the first block or not in a block.\n",
        "\n",
        "Note 1: Each LayerNorm has a hook for the scale factor (ie the standard deviation of the input activations for each token position & batch element) and for the normalized output (ie the input activation with mean 0 and standard deviation 1, but *before* applying scaling or translating with learned weights). LayerNorm is applied every time a layer reads from the residual stream: `ln1` is the LayerNorm before the attention layer in a block, `ln2` the one before the MLP layer, and `ln_final` is the LayerNorm before the unembed.\n",
        "\n",
        "Note 2: *Every* activation apart from the attention pattern and attention scores has shape beginning with `[batch, position]`. The attention pattern and scores have shape `[batch, head_index, dest_position, source_position]` (the numbers are the same, unless we're using caching)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9P9YPr2sXMBm",
        "outputId": "a69a0ef8-3841-467c-e93b-7df0dace7a60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num tokens: 10\n",
            "hook_embed torch.Size([1, 10, 768])\n",
            "hook_pos_embed torch.Size([1, 10, 768])\n",
            "blocks.0.hook_resid_pre torch.Size([1, 10, 768])\n",
            "blocks.0.ln1.hook_scale torch.Size([1, 10, 1])\n",
            "blocks.0.ln1.hook_normalized torch.Size([1, 10, 768])\n",
            "blocks.0.ln1.hook_scale torch.Size([1, 10, 1])\n",
            "blocks.0.ln1.hook_normalized torch.Size([1, 10, 768])\n",
            "blocks.0.ln1.hook_scale torch.Size([1, 10, 1])\n",
            "blocks.0.ln1.hook_normalized torch.Size([1, 10, 768])\n",
            "blocks.0.attn.hook_q torch.Size([1, 10, 12, 64])\n",
            "blocks.0.attn.hook_k torch.Size([1, 10, 12, 64])\n",
            "blocks.0.attn.hook_v torch.Size([1, 10, 12, 64])\n",
            "blocks.0.attn.hook_attn_scores torch.Size([1, 12, 10, 10])\n",
            "blocks.0.attn.hook_pattern torch.Size([1, 12, 10, 10])\n",
            "blocks.0.attn.hook_z torch.Size([1, 10, 12, 64])\n",
            "blocks.0.hook_attn_out torch.Size([1, 10, 768])\n",
            "blocks.0.hook_resid_mid torch.Size([1, 10, 768])\n",
            "blocks.0.ln2.hook_scale torch.Size([1, 10, 1])\n",
            "blocks.0.ln2.hook_normalized torch.Size([1, 10, 768])\n",
            "blocks.0.mlp.hook_pre torch.Size([1, 10, 3072])\n",
            "blocks.0.mlp.hook_post torch.Size([1, 10, 3072])\n",
            "blocks.0.hook_mlp_out torch.Size([1, 10, 768])\n",
            "blocks.0.hook_resid_post torch.Size([1, 10, 768])\n",
            "ln_final.hook_scale torch.Size([1, 10, 1])\n",
            "ln_final.hook_normalized torch.Size([1, 10, 768])\n"
          ]
        }
      ],
      "source": [
        "test_prompt = \"The quick brown fox jumped over the lazy dog\"\n",
        "print(\"Num tokens:\", len(model.to_tokens(test_prompt)[0]))\n",
        "\n",
        "def print_name_shape_hook_function(activation, hook):\n",
        "    print(hook.name, activation.shape)\n",
        "\n",
        "not_in_late_block_filter = lambda name: name.startswith(\"blocks.0.\") or not name.startswith(\"blocks\")\n",
        "\n",
        "model.run_with_hooks(\n",
        "    test_prompt,\n",
        "    return_type=None,\n",
        "    fwd_hooks=[(not_in_late_block_filter, print_name_shape_hook_function)],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzCE46VsXMBm"
      },
      "source": [
        "### Folding LayerNorm (For the Curious)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOkQnAZXXMBn"
      },
      "source": [
        "(For the curious - this is an important technical detail that's worth understanding, especially if you have preconceptions about how transformers work, but not necessary to use TransformerLens)\n",
        "\n",
        "LayerNorm is a normalization technique used by transformers, analogous to BatchNorm but more friendly to massive parallelisation. No one *really* knows why it works, but it seems to improve model numerical stability. Unlike BatchNorm, LayerNorm actually changes the functional form of the model, which makes it a massive pain for interpretability!\n",
        "\n",
        "Folding LayerNorm is a technique to make it lower overhead to deal with, and the flags `center_writing_weights` and `fold_ln` in `HookedTransformer.from_pretrained` apply this automatically (they default to True). These simplify the internal structure without changing the weights.\n",
        "\n",
        "Intuitively, LayerNorm acts on each residual stream vector (ie for each batch element and token position) independently, sets their mean to 0 (centering) and standard deviation to 1 (normalizing) (*across* the residual stream dimension - very weird!), and then applies a learned elementwise scaling and translation to each vector.\n",
        "\n",
        "Mathematically, centering is a linear map, normalizing is *not* a linear map, and scaling and translation are linear maps.\n",
        "* **Centering:** LayerNorm is applied every time a layer reads from the residual stream, so the mean of any residual stream vector can never matter - `center_writing_weights` set every weight matrix writing to the residual to have zero mean.\n",
        "* **Normalizing:** Normalizing is not a linear map, and cannot be factored out. The `hook_scale` hook point lets you access and control for this.\n",
        "* **Scaling and Translation:** Scaling and translation are linear maps, and are always followed by another linear map. The composition of two linear maps is another linear map, so we can *fold* the scaling and translation weights into the weights of the subsequent layer, and simplify things without changing the underlying computation.\n",
        "\n",
        "[See the docs for more details](https://github.com/TransformerLensOrg/TransformerLens/blob/main/further_comments.md#what-is-layernorm-folding-fold_ln)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGAD7YjgXMBn"
      },
      "source": [
        "A fun consequence of LayerNorm folding is that it creates a bias across the unembed, a `d_vocab` length vector that is added to the output logits - GPT-2 is not trained with this, but it *is* trained with a final LayerNorm that contains a bias.\n",
        "\n",
        "Turns out, this LayerNorm bias learns structure of the data that we can only see after folding! In particular, it essentially learns **unigram statistics** - rare tokens get suppressed, common tokens get boosted, by pretty dramatic degrees! Let's list the top and bottom 20 - at the top we see common punctuation and words like \" the\" and \" and\", at the bottom we see weird-ass tokens like \" RandomRedditor\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0vSMxF-XMBn"
      },
      "outputs": [],
      "source": [
        "unembed_bias = model.unembed.b_U\n",
        "bias_values, bias_indices = unembed_bias.sort(descending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpF6DtlDXMBo",
        "outputId": "415a85fd-2ba5-4705-bf5e-c0ec4086e4b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 20 values\n",
            "7.03 ','\n",
            "6.98 ' the'\n",
            "6.68 ' and'\n",
            "6.49 '.'\n",
            "6.48 '\\n'\n",
            "6.47 ' a'\n",
            "6.41 ' in'\n",
            "6.25 ' to'\n",
            "6.16 ' of'\n",
            "6.04 '-'\n",
            "6.03 ' ('\n",
            "5.88 ' \"'\n",
            "5.80 ' for'\n",
            "5.72 ' that'\n",
            "5.64 ' on'\n",
            "5.59 ' is'\n",
            "5.52 ' as'\n",
            "5.49 ' at'\n",
            "5.45 ' with'\n",
            "5.44 ' or'\n",
            "...\n",
            "Bottom 20 values\n",
            "-3.82 ' サーティ'\n",
            "-3.83 '\\x18'\n",
            "-3.83 '\\x14'\n",
            "-3.83 ' RandomRedditor'\n",
            "-3.83 '龍�'\n",
            "-3.83 '�'\n",
            "-3.83 '\\x1b'\n",
            "-3.83 '�'\n",
            "-3.83 '\\x05'\n",
            "-3.83 '\\x00'\n",
            "-3.83 '\\x06'\n",
            "-3.83 '\\x07'\n",
            "-3.83 '\\x0c'\n",
            "-3.83 '\\x02'\n",
            "-3.83 'oreAndOnline'\n",
            "-3.84 '\\x11'\n",
            "-3.84 '�'\n",
            "-3.84 '\\x10'\n",
            "-3.84 '�'\n",
            "-3.84 '�'\n"
          ]
        }
      ],
      "source": [
        "top_k = 20\n",
        "print(f\"Top {top_k} values\")\n",
        "for i in range(top_k):\n",
        "    print(f\"{bias_values[i].item():.2f} {repr(model.to_string(bias_indices[i]))}\")\n",
        "\n",
        "print(\"...\")\n",
        "print(f\"Bottom {top_k} values\")\n",
        "for i in range(top_k, 0, -1):\n",
        "    print(f\"{bias_values[-i].item():.2f} {repr(model.to_string(bias_indices[-i]))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz3Wwk0OXMBp"
      },
      "source": [
        "This can have real consequences for interpretability - for example, this bias favours \" John\" over \" Mary\" by about 1.2, about 1/3 of the effect size of the Indirect Object Identification Circuit! All other things being the same, this makes the John token 3.6x times more likely than the Mary token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gc8cYqJwXMBq",
        "outputId": "9835c456-44c5-4fe5-c2ad-ad9747b413d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "John bias: 2.8995\n",
            "Mary bias: 1.6034\n",
            "Prob ratio bias: 3.6550x\n"
          ]
        }
      ],
      "source": [
        "john_bias = model.unembed.b_U[model.to_single_token(' John')]\n",
        "mary_bias = model.unembed.b_U[model.to_single_token(' Mary')]\n",
        "\n",
        "print(f\"John bias: {john_bias.item():.4f}\")\n",
        "print(f\"Mary bias: {mary_bias.item():.4f}\")\n",
        "print(f\"Prob ratio bias: {torch.exp(john_bias - mary_bias).item():.4f}x\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I59wvswKXMBq"
      },
      "source": [
        "# Features\n",
        "\n",
        "An overview of some other important features of the library. I recommend checking out the [Exploratory Analysis Demo](https://colab.research.google.com/github/TransformerLensOrg/Easy-Transformer/blob/main/Exploratory_Analysis_Demo.ipynb) for some other important features not mentioned here, and for a demo of what using the library in practice looks like."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an3WXT1kXMBr"
      },
      "source": [
        "## Dealing with tokens\n",
        "\n",
        "**Tokenization** is one of the most annoying features of studying language models. We want language models to be able to take in arbitrary text as input, but the transformer architecture needs the inputs to be elements of a fixed, finite vocabulary. The solution to this is **tokens**, a fixed vocabulary of \"sub-words\", that any natural language can be broken down into with a **tokenizer**. This is invertible, and we can recover the original text, called **de-tokenization**.\n",
        "\n",
        "TransformerLens comes with a range of utility functions to deal with tokenization. Different models can have different tokenizers, so these are all methods on the model.\n",
        "\n",
        "get_token_position, to_tokens, to_string, to_str_tokens, prepend_bos, to_single_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W24IMvJXMBs"
      },
      "source": [
        "The first thing you need to figure out is *how* things are tokenized. `model.to_str_tokens` splits a string into the tokens *as a list of substrings*, and so lets you explore what the text looks like. To demonstrate this, let's use it on this paragraph.\n",
        "\n",
        "Some observations - there are a lot of arbitrary-ish details in here!\n",
        "* The tokenizer splits on spaces, so no token contains two words.\n",
        "* Tokens include the preceding space, and whether the first token is a capital letter. `how` and ` how` are different tokens!\n",
        "* Common words are single tokens, even if fairly long (` paragraph`) while uncommon words are split into multiple tokens (` token|ized`).\n",
        "* Tokens *mostly* split on punctuation characters (eg `*` and `.`), but eg `'s` is a single token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rESTbHc6XMBs",
        "outputId": "ec5aaa82-3a6a-4446-cebc-07179d2d3734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<|endoftext|>', 'The', ' first', ' thing', ' you', ' need', ' to', ' figure', ' out', ' is', ' *', 'how', '*', ' things', ' are', ' token', 'ized', '.', ' `', 'model', '.', 'to', '_', 'str', '_', 't', 'ok', 'ens', '`', ' splits', ' a', ' string', ' into', ' the', ' tokens', ' *', 'as', ' a', ' list', ' of', ' sub', 'strings', '*,', ' and', ' so', ' lets', ' you', ' explore', ' what', ' the', ' text', ' looks', ' like', '.', ' To', ' demonstrate', ' this', ',', ' let', \"'s\", ' use', ' it', ' on', ' this', ' paragraph', '.']\n"
          ]
        }
      ],
      "source": [
        "example_text = \"The first thing you need to figure out is *how* things are tokenized. `model.to_str_tokens` splits a string into the tokens *as a list of substrings*, and so lets you explore what the text looks like. To demonstrate this, let's use it on this paragraph.\"\n",
        "example_text_str_tokens = model.to_str_tokens(example_text)\n",
        "print(example_text_str_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K9Ldt9iXMBt"
      },
      "source": [
        "The transformer needs to take in a sequence of integers, not strings, so we need to convert these tokens into integers. `model.to_tokens` does this, and returns a tensor of integers on the model's device (shape `[batch, position]`). It maps a string to a batch of size 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJG66hJqXMBv",
        "outputId": "68247f16-bf06-4222-bda4-af9aefcbb957"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[50256,   464,   717,  1517,   345,   761,   284,  3785,   503,   318,\n",
            "          1635,  4919,     9,  1243,   389, 11241,  1143,    13,  4600, 19849,\n",
            "            13,  1462,    62,  2536,    62,    83,   482,   641,    63, 30778,\n",
            "           257,  4731,   656,   262, 16326,  1635,   292,   257,  1351,   286,\n",
            "           850, 37336, 25666,   290,   523,  8781,   345,  7301,   644,   262,\n",
            "          2420,  3073,   588,    13,  1675, 10176,   428,    11,  1309,   338,\n",
            "           779,   340,   319,   428,  7322,    13]])\n"
          ]
        }
      ],
      "source": [
        "example_text_tokens = model.to_tokens(example_text)\n",
        "print(example_text_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C95eetzkXMBv"
      },
      "source": [
        "`to_tokens` can also take in a list of strings, and return a batch of size `len(strings)`. If the strings are different numbers of tokens, it adds a PAD token to the end of the shorter strings to make them the same length.\n",
        "\n",
        "(Note: In GPT-2, 50256 signifies both the beginning of sequence, end of sequence and padding token - see the `prepend_bos` section for details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcRdbng3XMBw",
        "outputId": "73503a0e-9529-4805-a3de-97508ad3da88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[50256,   464,  3797,  3332,   319,   262,  2603,    13, 50256, 50256],\n",
            "        [50256,   464,  3797,  3332,   319,   262,  2603,  1107,  1327,    13]])\n"
          ]
        }
      ],
      "source": [
        "example_multi_text = [\"The cat sat on the mat.\", \"The cat sat on the mat really hard.\"]\n",
        "example_multi_text_tokens = model.to_tokens(example_multi_text)\n",
        "print(example_multi_text_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7Ev2UgnXMBw"
      },
      "source": [
        "`model.to_single_token` is a convenience function that takes in a string corresponding to a *single* token and returns the corresponding integer. This is useful for eg looking up the logit corresponding to a single token.\n",
        "\n",
        "For example, let's input `The cat sat on the mat.` to GPT-2, and look at the log prob predicting that the next token is ` The`.\n",
        "\n",
        "<details><summary>Technical notes</summary>\n",
        "\n",
        "Note that if we input a string to the model, it's implicitly converted to a string with `to_tokens`.\n",
        "\n",
        "Note further that the log probs have shape `[batch, position, d_vocab]==[1, 8, 50257]`, with a vector of log probs predicting the next token for *every* token position. GPT-2 uses causal attention which means heads can only look backwards (equivalently, information can only move forwards in the model.), so the log probs at position k are only a function of the first k tokens, and it can't just cheat and look at the k+1 th token. This structure lets it generate text more efficiently, and lets it treat every *token* as a training example, rather than every *sequence*.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Piy1Lgz7XMBw",
        "outputId": "ea768792-9d3c-4010-8469-20c4e27778c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Probability tensor shape [batch, position, d_vocab] == torch.Size([1, 8, 50257])\n",
            "| The| probability: 11.98%\n"
          ]
        }
      ],
      "source": [
        "cat_text = \"The cat sat on the mat.\"\n",
        "cat_logits = model(cat_text)\n",
        "cat_probs = cat_logits.softmax(dim=-1)\n",
        "print(f\"Probability tensor shape [batch, position, d_vocab] == {cat_probs.shape}\")\n",
        "\n",
        "capital_the_token_index = model.to_single_token(\" The\")\n",
        "print(f\"| The| probability: {cat_probs[0, -1, capital_the_token_index].item():.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDGF3_wcXMBx"
      },
      "source": [
        "`model.to_string` is the inverse of `to_tokens` and maps a tensor of integers to a string or list of strings. It also works on integers and lists of integers.\n",
        "\n",
        "For example, let's look up token 256 (due to technical details of tokenization, this will be the most common pair of ASCII characters!), and also verify that our tokens above map back to a string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5owR-duXMBx",
        "outputId": "4538adcb-1469-4f8b-8eb8-24de40ae4853"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token 256 - the most common pair of ASCII characters: | t|\n",
            "De-Tokenizing the example tokens: <|endoftext|>The first thing you need to figure out is *how* things are tokenized. `model.to_str_tokens` splits a string into the tokens *as a list of substrings*, and so lets you explore what the text looks like. To demonstrate this, let's use it on this paragraph.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Token 256 - the most common pair of ASCII characters: |{model.to_string(256)}|\")\n",
        "# Squeeze means to remove dimensions of length 1.\n",
        "# Here, that removes the dummy batch dimension so it's a rank 1 tensor and returns a string\n",
        "# Rank 2 tensors map to a list of strings\n",
        "print(f\"De-Tokenizing the example tokens: {model.to_string(example_text_tokens.squeeze())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9_iqlSsXMBx"
      },
      "source": [
        "A related annoyance of tokenization is that it's hard to figure out how many tokens a string will break into. `model.get_token_position(single_token, tokens)` returns the position of `single_token` in `tokens`. `tokens` can be either a string or a tensor of tokens.\n",
        "\n",
        "Note that position is zero-indexed, it's two (ie third) because there's a beginning of sequence token automatically prepended (see the next section for details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k0oFdeDXMBy",
        "outputId": "6607bba6-6220-48b6-bc70-d8acda846e4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With BOS: 2\n",
            "Without BOS: 1\n"
          ]
        }
      ],
      "source": [
        "print(\"With BOS:\", model.get_token_position(\" cat\", \"The cat sat on the mat\"))\n",
        "print(\"Without BOS:\", model.get_token_position(\" cat\", \"The cat sat on the mat\", prepend_bos=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkE8tgeqXMBy"
      },
      "source": [
        "If there are multiple copies of the token, we can set `mode=\"first\"` to find the first occurrence's position and `mode=\"last\"` to find the last"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlPZVkb4XMBy",
        "outputId": "db489a19-1c41-41ad-ecc8-dcf6cd757a1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First occurrence 2\n",
            "Final occurrence 13\n"
          ]
        }
      ],
      "source": [
        "print(\"First occurrence\", model.get_token_position(\n",
        "    \" cat\",\n",
        "    \"The cat sat on the mat. The mat sat on the cat.\",\n",
        "    mode=\"first\"))\n",
        "print(\"Final occurrence\", model.get_token_position(\n",
        "    \" cat\",\n",
        "    \"The cat sat on the mat. The mat sat on the cat.\",\n",
        "    mode=\"last\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E5YGZbcXMBz"
      },
      "source": [
        "In general, tokenization is a pain, and full of gotchas. I highly recommend just playing around with different inputs and their tokenization and getting a feel for it. As another \"fun\" example, let's look at the tokenization of arithmetic expressions - tokens do *not* contain consistent numbers of digits. (This makes it even more impressive that GPT-3 can do arithmetic!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnddyLUoXMBz",
        "outputId": "7fab7460-2fb6-4470-dc90-101b82ce36fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<|endoftext|>', '23', '42', '+', '2017', '=', '214', '45']\n",
            "['<|endoftext|>', '1000', '+', '1', '000000', '=', '9999', '99']\n"
          ]
        }
      ],
      "source": [
        "print(model.to_str_tokens(\"2342+2017=21445\"))\n",
        "print(model.to_str_tokens(\"1000+1000000=999999\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JbtDIUsXMBz"
      },
      "source": [
        "I also *highly* recommend investigating prompts with easy tokenization when starting out - ideally key words should form a single token, be in the same position in different prompts, have the same total length, etc. Eg study Indirect Object Identification with common English names like ` Tim` rather than ` Ne|el`. Transformers need to spend some parameters in early layers converting multi-token words to a single feature, and then de-converting this in the late layers, and unless this is what you're explicitly investigating, this will make the behaviour you're investigating be messier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkEkvKfQXMBz"
      },
      "source": [
        "### Gotcha: `prepend_bos`\n",
        "\n",
        "Key Takeaway: **If you get weird off-by-one errors, check whether there's an unexpected `prepend_bos`!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k71Nij8FXMB0"
      },
      "source": [
        "A weirdness you may have noticed in the above is that `to_tokens` and `to_str_tokens` added a weird `<|endoftext|>` to the start of each prompt. TransformerLens does this by default, and it can easily trip up new users. Notably, **this includes `model.forward`** (which is what's implicitly used when you do eg `model(\"Hello World\")`). This is called a **Beginning of Sequence (BOS)** token, and it's a special token used to mark the beginning of the sequence. Confusingly, in GPT-2, the End of Sequence (EOS), Beginning of Sequence (BOS) and Padding (PAD) tokens are all the same, `<|endoftext|>` with index `50256`.\n",
        "\n",
        "**Gotcha:** You only want to prepend a BOS token at the *start* of a prompt. If you, eg, want to input a question followed by an answer, and want to tokenize these separately, you do *not* want to prepend_bos on the answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6XMkiyzXMB0",
        "outputId": "3d6ed6f5-9047-499c-d9a4-f5c6a3c36c62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logits shape by default (with BOS) torch.Size([1, 3, 50257])\n",
            "Logits shape with BOS torch.Size([1, 3, 50257])\n",
            "Logits shape without BOS - only 2 positions! torch.Size([1, 2, 50257])\n"
          ]
        }
      ],
      "source": [
        "print(\"Logits shape by default (with BOS)\", model(\"Hello World\").shape)\n",
        "print(\"Logits shape with BOS\", model(\"Hello World\", prepend_bos=True).shape)\n",
        "print(\"Logits shape without BOS - only 2 positions!\", model(\"Hello World\", prepend_bos=False).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoBGpBCzXMB0"
      },
      "source": [
        "`prepend_bos` is a bit of a hack, and I've gone back and forth on what the correct default here is. The reason I do this is that transformers tend to treat the first token weirdly - this doesn't really matter in training (where all inputs are >1000 tokens), but this can be a big issue when investigating short prompts! The reason for this is that attention patterns are a probability distribution and so need to add up to one, so to simulate being \"off\" they normally look at the first token. Giving them a BOS token lets the heads rest by looking at that, preserving the information in the first \"real\" token.\n",
        "\n",
        "Further, *some* models are trained to need a BOS token (OPT and my interpretability-friendly models are, GPT-2 and GPT-Neo are not). But despite GPT-2 not being trained with this, empirically it seems to make interpretability easier.\n",
        "\n",
        "(However, if you want to change the default behaviour to *not* prepending a BOS token, pass `default_prepend_bos=False` when you instantiate the model, e.g., `model = HookedTransformer.from_pretrained('gpt2', default_prepend_bos=False)`.)\n",
        "\n",
        "For example, the model can get much worse at Indirect Object Identification without a BOS (and with a name as the first token):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyoXMpO6XMB0",
        "outputId": "66d7472b-bd7c-404b-96ca-c30eb45acbed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logit difference with BOS: 6.754\n",
            "Logit difference without BOS: 2.782\n"
          ]
        }
      ],
      "source": [
        "ioi_logits_with_bos = model(\"Claire and Mary went to the shops, then Mary gave a bottle of milk to\", prepend_bos=True)\n",
        "mary_logit_with_bos = ioi_logits_with_bos[0, -1, model.to_single_token(\" Mary\")].item()\n",
        "claire_logit_with_bos = ioi_logits_with_bos[0, -1, model.to_single_token(\" Claire\")].item()\n",
        "print(f\"Logit difference with BOS: {(claire_logit_with_bos - mary_logit_with_bos):.3f}\")\n",
        "\n",
        "ioi_logits_without_bos = model(\"Claire and Mary went to the shops, then Mary gave a bottle of milk to\", prepend_bos=False)\n",
        "mary_logit_without_bos = ioi_logits_without_bos[0, -1, model.to_single_token(\" Mary\")].item()\n",
        "claire_logit_without_bos = ioi_logits_without_bos[0, -1, model.to_single_token(\" Claire\")].item()\n",
        "print(f\"Logit difference without BOS: {(claire_logit_without_bos - mary_logit_without_bos):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdhHQ2JUXMB1"
      },
      "source": [
        "Though, note that this also illustrates another gotcha - when `Claire` is at the start of a sentence (no preceding space), it's actually *two* tokens, not one, which probably confuses the relevant circuit. (Note - in this test we put `prepend_bos=False`, because we want to analyse the tokenization of a specific string, not to give an input to the model!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CU2ZDxZkXMB1",
        "outputId": "94b77063-77ba-4335-8c2e-f8e299b63c19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| Claire| -> [' Claire']\n",
            "|Claire| -> ['Cl', 'aire']\n"
          ]
        }
      ],
      "source": [
        "print(f\"| Claire| -> {model.to_str_tokens(' Claire', prepend_bos=False)}\")\n",
        "print(f\"|Claire| -> {model.to_str_tokens('Claire', prepend_bos=False)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOV-Q4DPXMB1"
      },
      "source": [
        "## Factored Matrix Class\n",
        "\n",
        "In transformer interpretability, we often need to analyse low rank factorized matrices - a matrix $M = AB$, where M is `[large, large]`, but A is `[large, small]` and B is `[small, large]`. This is a common structure in transformers, and the `FactoredMatrix` class is a convenient way to work with these. It implements efficient algorithms for various operations on these, such as computing the trace, eigenvalues, Frobenius norm, singular value decomposition, and products with other matrices. It can (approximately) act as a drop-in replacement for the original matrix, and supports leading batch dimensions to the factored matrix.\n",
        "\n",
        "<details><summary>Why are low-rank factorized matrices useful for transformer interpretability?</summary>\n",
        "\n",
        "As argued in [A Mathematical Framework](https://transformer-circuits.pub/2021/framework/index.html), an unexpected fact about transformer attention heads is that rather than being best understood as keys, queries and values (and the requisite weight matrices), they're actually best understood as two low rank factorized matrices.\n",
        "* **Where to move information from:** $W_QK = W_Q W_K^T$, used for determining the attention pattern - what source positions to move information from and what destination positions to move them to.\n",
        "    * Intuitively, residual stream -> query and residual stream -> key are linear maps, *and* `attention_score = query @ key.T` is a linear map, so the whole thing can be factored into one big bilinear form `residual @ W_QK @ residual.T`\n",
        "* **What information to move:** $W_OV = W_V W_O$, used to determine what information to copy from the source position to the destination position (weighted by the attention pattern weight from that destination to that source).\n",
        "    * Intuitively, the residual stream is a `[position, d_model]` tensor (ignoring batch). The attention pattern acts on the *position* dimension (where to move information from and to) and the value and output weights act on the *d_model* dimension - ie *what* information is contained at that source position. So we can factor it all into `attention_pattern @ residual @ W_V @ W_O`, and so only need to care about `W_OV = W_V @ W_O`\n",
        "* Note - the internal head dimension is smaller than the residual stream dimension, so the factorization is low rank. (here, `d_model=768` and `d_head=64`)\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8CZ7iekXMB1"
      },
      "source": [
        "### Basic Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWrWAYxQXMB2"
      },
      "source": [
        "We can use the basic class directly - let's make a factored matrix directly and look at the basic operations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2TsNkI5XMB2",
        "outputId": "e96d54b5-f20d-4ab7-cc3f-33e65fb7ddf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Norms:\n",
            "tensor(9.9105)\n",
            "tensor(9.9105)\n",
            "Right dimension: 5, Left dimension: 5, Hidden dimension: 2\n"
          ]
        }
      ],
      "source": [
        "if IN_GITHUB:\n",
        "    torch.manual_seed(50)\n",
        "A = torch.randn(5, 2)\n",
        "B = torch.randn(2, 5)\n",
        "\n",
        "AB = A @ B\n",
        "AB_factor = FactoredMatrix(A, B)\n",
        "print(\"Norms:\")\n",
        "print(AB.norm())\n",
        "print(AB_factor.norm())\n",
        "\n",
        "print(f\"Right dimension: {AB_factor.rdim}, Left dimension: {AB_factor.ldim}, Hidden dimension: {AB_factor.mdim}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNxHtxOxXMB2"
      },
      "source": [
        "We can also look at the eigenvalues and singular values of the matrix. Note that, because the matrix is rank 2 but 5 by 5, the final 3 eigenvalues and singular values are zero - the factored class omits the zeros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPg6UFgWXMB2",
        "outputId": "a801c76e-8767-4fec-83ed-d82de808cb7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eigenvalues:\n",
            "tensor([-6.2877e+00+0.j,  1.9337e-07+0.j,  2.3121e+00+0.j, -5.9987e-07+0.j,\n",
            "        -1.1409e-07+0.j])\n",
            "tensor([-6.2877+0.j,  2.3121+0.j])\n",
            "\n",
            "Singular Values:\n",
            "tensor([8.3126e+00, 5.3963e+00, 1.4519e-07, 7.4293e-08, 2.1726e-09])\n",
            "tensor([8.3126, 5.3963])\n"
          ]
        }
      ],
      "source": [
        "# NBVAL_IGNORE_OUTPUT\n",
        "print(\"Eigenvalues:\")\n",
        "print(torch.linalg.eig(AB).eigenvalues)\n",
        "print(AB_factor.eigenvalues)\n",
        "print()\n",
        "print(\"Singular Values:\")\n",
        "print(torch.linalg.svd(AB).S)\n",
        "print(AB_factor.S)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7Z4CWXQXMB3"
      },
      "source": [
        "We can multiply with other matrices - it automatically chooses the smallest possible dimension to factor along (here it's 2, rather than 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lcaxO8vXMB3",
        "outputId": "9afca37a-3bcf-4694-9f2f-c016f214a6d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unfactored: torch.Size([5, 300]) tensor(160.0830)\n",
            "Factored: torch.Size([5, 300]) tensor(160.0830)\n",
            "Right dimension: 300, Left dimension: 5, Hidden dimension: 2\n"
          ]
        }
      ],
      "source": [
        "if IN_GITHUB:\n",
        "    torch.manual_seed(50)\n",
        "\n",
        "C = torch.randn(5, 300)\n",
        "\n",
        "ABC = AB @ C\n",
        "ABC_factor = AB_factor @ C\n",
        "print(\"Unfactored:\", ABC.shape, ABC.norm().round(decimals=3))\n",
        "print(\"Factored:\", ABC_factor.shape, ABC_factor.norm().round(decimals=3))\n",
        "print(f\"Right dimension: {ABC_factor.rdim}, Left dimension: {ABC_factor.ldim}, Hidden dimension: {ABC_factor.mdim}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPSjYOguXMB4"
      },
      "source": [
        "If we want to collapse this back to an unfactored matrix, we can use the AB property to get the product:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azw9ESXzXMB4",
        "outputId": "18a492f6-f87c-47a5-dc68-759fe49e70dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(True)\n"
          ]
        }
      ],
      "source": [
        "AB_unfactored = AB_factor.AB\n",
        "print(torch.isclose(AB_unfactored, AB).all())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHnwW4pzXMB5"
      },
      "source": [
        "### Medium Example: Eigenvalue Copying Scores\n",
        "\n",
        "(This is a more involved example of how to use the factored matrix class, skip it if you aren't following)\n",
        "\n",
        "For a more involved example, let's look at the eigenvalue copying score from [A Mathematical Framework](https://transformer-circuits.pub/2021/framework/index.html) of the OV circuit for various heads. The OV Circuit for a head (the factorised matrix $W_OV = W_V W_O$) is a linear map that determines what information is moved from the source position to the destination position. Because this is low rank, it can be thought of as *reading in* some low rank subspace of the source residual stream and *writing to* some low rank subspace of the destination residual stream (with maybe some processing happening in the middle).\n",
        "\n",
        "A common operation for this will just be to *copy*, ie to have the same reading and writing subspace, and to do minimal processing in the middle. Empirically, this tends to coincide with the OV Circuit having (approximately) positive real eigenvalues. I mostly assert this as an empirical fact, but intuitively, operations that involve mapping eigenvectors to different directions (eg rotations) tend to have complex eigenvalues. And operations that preserve eigenvector direction but negate it tend to have negative real eigenvalues. And \"what happens to the eigenvectors\" is a decent proxy for what happens to an arbitrary vector.\n",
        "\n",
        "We can get a score for \"how positive real the OV circuit eigenvalues are\" with $\\frac{\\sum \\lambda_i}{\\sum |\\lambda_i|}$, where $\\lambda_i$ are the eigenvalues of the OV circuit. This is a bit of a hack, but it seems to work well in practice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IvPiEPUXMB5"
      },
      "source": [
        "Let's use FactoredMatrix to compute this for every head in the model! We use the helper `model.OV` to get the concatenated OV circuits for all heads across all layers in the model. This has the shape `[n_layers, n_heads, d_model, d_model]`, where `n_layers` and `n_heads` are batch dimensions and the final two dimensions are factorised as `[n_layers, n_heads, d_model, d_head]` and `[n_layers, n_heads, d_head, d_model]` matrices.\n",
        "\n",
        "We can then get the eigenvalues for this, where there are separate eigenvalues for each element of the batch (a `[n_layers, n_heads, d_head]` tensor of complex numbers), and calculate the copying score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXgw9VmFXMB5",
        "outputId": "4b6176fc-54ed-4e18-c5db-c910c3e4c92b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FactoredMatrix: Shape(torch.Size([12, 12, 768, 768])), Hidden Dim(64)\n"
          ]
        }
      ],
      "source": [
        "OV_circuit_all_heads = model.OV\n",
        "print(OV_circuit_all_heads)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nC9OP7oXXMB5",
        "outputId": "1be7e249-fad3-470a-b6b4-73cd5de027bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([12, 12, 64])\n",
            "torch.complex64\n"
          ]
        }
      ],
      "source": [
        "OV_circuit_all_heads_eigenvalues = OV_circuit_all_heads.eigenvalues\n",
        "print(OV_circuit_all_heads_eigenvalues.shape)\n",
        "print(OV_circuit_all_heads_eigenvalues.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RX4inVh2XMB6",
        "outputId": "d434fe11-d1c5-4c9d-fe20-7f72a770bf73"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"a09834af-1357-479f-b958-ca36d205cbf8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a09834af-1357-479f-b958-ca36d205cbf8\")) {                    Plotly.newPlot(                        \"a09834af-1357-479f-b958-ca36d205cbf8\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.7775010466575623,0.3527269959449768,0.25961846113204956,0.6670257449150085,0.8384260535240173,0.5584430694580078,0.8444744944572449,0.4137910008430481,0.24488940834999084,0.028157662600278854,0.3584098219871521,0.16288265585899353],[-0.45419126749038696,-0.6529328227043152,-0.5484569072723389,-0.7990369200706482,-0.7736425995826721,-0.8522581458091736,0.9774324893951416,0.6626249551773071,-0.7303224205970764,-0.7007019519805908,-0.6946625709533691,-0.9996722340583801],[-0.7837163805961609,0.8967759013175964,0.4750954806804657,-0.667197585105896,0.7881461977958679,-0.8547751307487488,-0.9054184556007385,-0.5749384760856628,-0.32175111770629883,-0.028594352304935455,-0.9247617721557617,-0.9699268341064453],[0.5864037275314331,-0.7614347338676453,0.5971695780754089,0.7854393720626831,-0.8788883686065674,0.3908745050430298,0.044738516211509705,0.11028008162975311,-0.8169988989830017,0.22129566967487335,-0.9939578771591187,0.5774399042129517],[0.525479257106781,0.3049013912677765,-0.10729152709245682,0.9433151483535767,-0.9314428567886353,0.5273632407188416,-0.4264712631702423,-0.9984429478645325,0.5296756029129028,0.8604294061660767,-0.8895052075386047,0.9556970596313477],[0.6629186868667603,0.42956963181495667,0.9736858010292053,0.6555483937263489,0.12201889604330063,0.7442770004272461,0.5037952661514282,0.9525359272956848,-0.6507164239883423,-0.9316279292106628,0.9791510105133057,-0.9972584843635559],[0.9613031148910522,0.7501779794692993,-0.3806658685207367,0.6429786682128906,0.9557769298553467,-0.9428839683532715,-0.9948079586029053,0.785298764705658,0.9657301306724548,0.707301676273346,0.3687230050563812,0.8128011226654053],[0.9659481644630432,0.9730121493339539,0.31900617480278015,-0.30290520191192627,0.9790953397750854,0.9357923269271851,-0.5550313591957092,-0.005466493312269449,0.9867776036262512,0.8249565958976746,0.566429615020752,0.1000526174902916],[-0.9464486837387085,-0.25471997261047363,0.6522327661514282,0.1415255218744278,0.9884140491485596,0.9860583543777466,0.6949270367622375,0.9901810884475708,0.9791202545166016,-0.2359553426504135,-0.9820711612701416,0.6506689190864563],[0.9895943999290466,-0.29178157448768616,0.9714024662971497,0.9951602220535278,0.18783769011497498,-0.9460937976837158,0.47801902890205383,-0.2489192932844162,0.9437097907066345,0.11866245418787003,0.9941242933273315,-0.38088178634643555],[0.9564487934112549,0.5542725920677185,0.42118048667907715,0.6628789901733398,0.8659590482711792,0.9937117695808411,0.9069075584411621,0.39811065793037415,-0.4134220480918884,0.9971913695335388,0.34596705436706543,0.9938657283782959],[0.5891268849372864,0.9313740134239197,0.9268401861190796,0.9993564486503601,0.6227539777755737,0.8463947772979736,0.6584346294403076,0.8423126339912415,0.2978496253490448,0.8728679418563843,0.9963144659996033,0.986752450466156]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0,\"cmin\":-1.0,\"cmax\":1.0},\"title\":{\"text\":\"OV Copying Score for each head in GPT-2 Small\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a09834af-1357-479f-b958-ca36d205cbf8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "OV_copying_score = OV_circuit_all_heads_eigenvalues.sum(dim=-1).real / OV_circuit_all_heads_eigenvalues.abs().sum(dim=-1)\n",
        "imshow(utils.to_numpy(OV_copying_score), xaxis=\"Head\", yaxis=\"Layer\", title=\"OV Copying Score for each head in GPT-2 Small\", zmax=1.0, zmin=-1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF7Qtu_aXMB6"
      },
      "source": [
        "Head 11 in Layer 11 (L11H11) has a high copying score, and if we plot the eigenvalues they look approximately as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzDbgZVvXMB6",
        "outputId": "07451871-c4ce-4910-c1cc-14f6a87adf37"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"1e3711f8-c7bc-42a1-aea4-6c909a93f24e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1e3711f8-c7bc-42a1-aea4-6c909a93f24e\")) {                    Plotly.newPlot(                        \"1e3711f8-c7bc-42a1-aea4-6c909a93f24e\",                        [{\"hovertemplate\":\"Real=%{x}\\u003cbr\\u003eImaginary=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[-2.1397297382354736,1.4152636528015137,3.444455146789551,4.027669906616211,8.882655143737793,4.866769790649414,4.866769790649414,4.843714714050293,4.843714714050293,8.477535247802734,8.216809272766113,8.216809272766113,5.07860803604126,7.855461120605469,7.855461120605469,5.365756034851074,5.365756034851074,5.563426971435547,5.563426971435547,5.4217329025268555,7.769133567810059,7.769133567810059,7.0422773361206055,7.0422773361206055,5.675145626068115,5.675145626068115,7.678577423095703,7.678577423095703,6.573329925537109,6.573329925537109,7.67294979095459,7.17219877243042,7.17219877243042,7.423620223999023,7.423620223999023,7.470810413360596,6.089095115661621,6.089095115661621,6.306834697723389,6.306834697723389,6.511750221252441,6.511750221252441,5.955246448516846,5.955246448516846,5.858811378479004,5.858811378479004,7.147887229919434,7.147887229919434,7.185712814331055,7.185712814331055,6.670608043670654,6.670608043670654,6.735983848571777,6.735983848571777,6.149757385253906,6.149757385253906,6.288776874542236,6.288776874542236,6.344796657562256,6.625571250915527,6.625571250915527,6.8991899490356445,6.8991899490356445,6.85640811920166],\"xaxis\":\"x\",\"y\":[0.0,0.0,0.0,0.0,0.0,0.4185231328010559,-0.4185231328010559,0.09079001098871231,-0.09079001098871231,0.0,0.40868881344795227,-0.40868881344795227,0.0,0.7007214426994324,-0.7007214426994324,0.46421411633491516,-0.46421411633491516,0.5558239817619324,-0.5558239817619324,0.0,0.4705662131309509,-0.4705662131309509,1.0298681259155273,-1.0298681259155273,0.48253530263900757,-0.48253530263900757,0.3356489837169647,-0.3356489837169647,0.9988697171211243,-0.9988697171211243,0.0,0.7531778812408447,-0.7531778812408447,0.4257569909095764,-0.4257569909095764,0.0,0.643626868724823,-0.643626868724823,0.7701709270477295,-0.7701709270477295,0.7558017373085022,-0.7558017373085022,0.25911131501197815,-0.25911131501197815,0.013043955899775028,-0.013043955899775028,0.40166252851486206,-0.40166252851486206,0.28192126750946045,-0.28192126750946045,0.6146255135536194,-0.6146255135536194,0.5391282439231873,-0.5391282439231873,0.28234055638313293,-0.28234055638313293,0.3528330624103546,-0.3528330624103546,0.0,0.24867765605449677,-0.24867765605449677,0.15545639395713806,-0.15545639395713806,0.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Real\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Imaginary\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Eigenvalues of Head L11H11 of GPT-2 Small\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1e3711f8-c7bc-42a1-aea4-6c909a93f24e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "scatter(x=OV_circuit_all_heads_eigenvalues[-1, -1, :].real, y=OV_circuit_all_heads_eigenvalues[-1, -1, :].imag, title=\"Eigenvalues of Head L11H11 of GPT-2 Small\", xaxis=\"Real\", yaxis=\"Imaginary\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk7U_0LMXMB7"
      },
      "source": [
        "We can even look at the full OV circuit, from the input tokens to output tokens: $W_E W_V W_O W_U$. This is a `[d_vocab, d_vocab]==[50257, 50257]` matrix, so absolutely enormous, even for a single head. But with the FactoredMatrix class, we can compute the full eigenvalue copying score of every head in a few seconds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjTM8RT0XMB7",
        "outputId": "ce56180d-4f41-4bba-8f92-80d1532c6500"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FactoredMatrix: Shape(torch.Size([12, 12, 50257, 50257])), Hidden Dim(64)\n"
          ]
        }
      ],
      "source": [
        "full_OV_circuit = model.embed.W_E @ OV_circuit_all_heads @ model.unembed.W_U\n",
        "print(full_OV_circuit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzez6GijXMB8",
        "outputId": "090eb264-1294-4084-cc24-d9b2bf99e3ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([12, 12, 64])\n",
            "torch.complex64\n"
          ]
        }
      ],
      "source": [
        "full_OV_circuit_eigenvalues = full_OV_circuit.eigenvalues\n",
        "print(full_OV_circuit_eigenvalues.shape)\n",
        "print(full_OV_circuit_eigenvalues.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I52pIv9vXMB8",
        "outputId": "a82dcf10-90e0-4222-9e33-b3ab852d7b0c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"c709dad6-6ca6-4c75-8231-0ee7b1e7e752\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c709dad6-6ca6-4c75-8231-0ee7b1e7e752\")) {                    Plotly.newPlot(                        \"c709dad6-6ca6-4c75-8231-0ee7b1e7e752\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.8356368541717529,0.5853535532951355,0.5105839967727661,0.7843376398086548,0.8644158840179443,0.7026588320732117,0.8969924449920654,0.5868821740150452,0.4248652160167694,-0.16337503492832184,0.4626856744289398,0.2760537266731262],[-0.05292005464434624,-0.3177315592765808,-0.4810580015182495,-0.783806562423706,-0.6360208988189697,-0.7758680582046509,0.9681803584098816,0.8119115233421326,-0.7510465383529663,-0.6878446340560913,-0.6429886221885681,-0.9985855221748352],[-0.6598327159881592,0.9152501821517944,0.5461500883102417,-0.4874398708343506,0.7720565795898438,-0.7541061639785767,-0.8472450971603394,-0.6948987245559692,-0.1557510942220688,0.24442273378372192,-0.9106623530387878,-0.9439151287078857],[0.6486894488334656,-0.5592910647392273,0.5935594439506531,0.7843042016029358,-0.8150346875190735,0.6130048036575317,0.16785870492458344,0.35195884108543396,-0.6837263107299805,0.22237683832645416,-0.9929219484329224,0.6535818576812744],[0.5740951299667358,0.3640132546424866,0.09609055519104004,0.9359623193740845,-0.9228774309158325,0.6191076636314392,-0.33572638034820557,-0.998464822769165,0.6448631286621094,0.8468661308288574,-0.7557657361030579,0.9527971148490906],[0.7326545715332031,0.532416820526123,0.9732668995857239,0.7239248752593994,0.25538960099220276,0.815841555595398,0.6655788421630859,0.9287101030349731,-0.5660438537597656,-0.890874445438385,0.9834234118461609,-0.9981180429458618],[0.9698693156242371,0.7439671158790588,-0.35639339685440063,0.6022988557815552,0.9708116054534912,-0.9278276562690735,-0.996231734752655,0.8345208168029785,0.9714328050613403,0.8158544898033142,0.5902576446533203,0.8199342489242554],[0.9820225834846497,0.9859328269958496,0.5152459144592285,-0.5610516667366028,0.9663665890693665,0.9495159983634949,-0.5204814076423645,0.3104749917984009,0.9859084486961365,0.7797460556030273,0.6738530397415161,0.3919741213321686],[-0.906204104423523,0.11750980466604233,0.8077875375747681,0.4169303774833679,0.9829014539718628,0.9902303218841553,0.7847102880477905,0.994563102722168,0.9868024587631226,-0.26804423332214355,-0.9908866882324219,0.745792806148529],[0.9906191825866699,-0.18231149017810822,0.97578364610672,0.9986749887466431,0.2544330358505249,-0.954406201839447,0.5869243144989014,-0.23537996411323547,0.9550502896308899,0.25511977076530457,0.9929870963096619,0.09052591770887375],[0.9707273244857788,0.6956093311309814,0.6280022263526917,0.7902867794036865,0.9343841075897217,0.989579439163208,0.9436283707618713,-0.10834993422031403,-0.3431112766265869,0.9986708760261536,0.5086739659309387,0.9949507713317871],[0.8283133506774902,0.9432437419891357,0.9491766095161438,0.9995352029800415,0.5712319612503052,0.8055234551429749,0.6781864166259766,0.8272571563720703,0.8314797282218933,0.8778656721115112,0.9944958686828613,0.9973865151405334]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0,\"cmin\":-1.0,\"cmax\":1.0},\"title\":{\"text\":\"OV Copying Score for each head in GPT-2 Small\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c709dad6-6ca6-4c75-8231-0ee7b1e7e752');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "full_OV_copying_score = full_OV_circuit_eigenvalues.sum(dim=-1).real / full_OV_circuit_eigenvalues.abs().sum(dim=-1)\n",
        "imshow(utils.to_numpy(full_OV_copying_score), xaxis=\"Head\", yaxis=\"Layer\", title=\"OV Copying Score for each head in GPT-2 Small\", zmax=1.0, zmin=-1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFHUZtvmXMB_"
      },
      "source": [
        "Interestingly, these are highly (but not perfectly!) correlated. I'm not sure what to read from this, or what's up with the weird outlier heads!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWHqBhLPXMCA",
        "outputId": "944a3ee5-20d7-4c96-da7a-72264fc4eedd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"3e59929d-31e9-49b1-ad1a-9d9811d4801d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3e59929d-31e9-49b1-ad1a-9d9811d4801d\")) {                    Plotly.newPlot(                        \"3e59929d-31e9-49b1-ad1a-9d9811d4801d\",                        [{\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eFull OV Copying Score=%{x}\\u003cbr\\u003eOV Copying Score=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"L0H0\",\"L0H1\",\"L0H2\",\"L0H3\",\"L0H4\",\"L0H5\",\"L0H6\",\"L0H7\",\"L0H8\",\"L0H9\",\"L0H10\",\"L0H11\",\"L1H0\",\"L1H1\",\"L1H2\",\"L1H3\",\"L1H4\",\"L1H5\",\"L1H6\",\"L1H7\",\"L1H8\",\"L1H9\",\"L1H10\",\"L1H11\",\"L2H0\",\"L2H1\",\"L2H2\",\"L2H3\",\"L2H4\",\"L2H5\",\"L2H6\",\"L2H7\",\"L2H8\",\"L2H9\",\"L2H10\",\"L2H11\",\"L3H0\",\"L3H1\",\"L3H2\",\"L3H3\",\"L3H4\",\"L3H5\",\"L3H6\",\"L3H7\",\"L3H8\",\"L3H9\",\"L3H10\",\"L3H11\",\"L4H0\",\"L4H1\",\"L4H2\",\"L4H3\",\"L4H4\",\"L4H5\",\"L4H6\",\"L4H7\",\"L4H8\",\"L4H9\",\"L4H10\",\"L4H11\",\"L5H0\",\"L5H1\",\"L5H2\",\"L5H3\",\"L5H4\",\"L5H5\",\"L5H6\",\"L5H7\",\"L5H8\",\"L5H9\",\"L5H10\",\"L5H11\",\"L6H0\",\"L6H1\",\"L6H2\",\"L6H3\",\"L6H4\",\"L6H5\",\"L6H6\",\"L6H7\",\"L6H8\",\"L6H9\",\"L6H10\",\"L6H11\",\"L7H0\",\"L7H1\",\"L7H2\",\"L7H3\",\"L7H4\",\"L7H5\",\"L7H6\",\"L7H7\",\"L7H8\",\"L7H9\",\"L7H10\",\"L7H11\",\"L8H0\",\"L8H1\",\"L8H2\",\"L8H3\",\"L8H4\",\"L8H5\",\"L8H6\",\"L8H7\",\"L8H8\",\"L8H9\",\"L8H10\",\"L8H11\",\"L9H0\",\"L9H1\",\"L9H2\",\"L9H3\",\"L9H4\",\"L9H5\",\"L9H6\",\"L9H7\",\"L9H8\",\"L9H9\",\"L9H10\",\"L9H11\",\"L10H0\",\"L10H1\",\"L10H2\",\"L10H3\",\"L10H4\",\"L10H5\",\"L10H6\",\"L10H7\",\"L10H8\",\"L10H9\",\"L10H10\",\"L10H11\",\"L11H0\",\"L11H1\",\"L11H2\",\"L11H3\",\"L11H4\",\"L11H5\",\"L11H6\",\"L11H7\",\"L11H8\",\"L11H9\",\"L11H10\",\"L11H11\"],\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.8356368541717529,0.5853535532951355,0.5105839967727661,0.7843376398086548,0.8644158840179443,0.7026588320732117,0.8969924449920654,0.5868821740150452,0.4248652160167694,-0.16337503492832184,0.4626856744289398,0.2760537266731262,-0.05292005464434624,-0.3177315592765808,-0.4810580015182495,-0.783806562423706,-0.6360208988189697,-0.7758680582046509,0.9681803584098816,0.8119115233421326,-0.7510465383529663,-0.6878446340560913,-0.6429886221885681,-0.9985855221748352,-0.6598327159881592,0.9152501821517944,0.5461500883102417,-0.4874398708343506,0.7720565795898438,-0.7541061639785767,-0.8472450971603394,-0.6948987245559692,-0.1557510942220688,0.24442273378372192,-0.9106623530387878,-0.9439151287078857,0.6486894488334656,-0.5592910647392273,0.5935594439506531,0.7843042016029358,-0.8150346875190735,0.6130048036575317,0.16785870492458344,0.35195884108543396,-0.6837263107299805,0.22237683832645416,-0.9929219484329224,0.6535818576812744,0.5740951299667358,0.3640132546424866,0.09609055519104004,0.9359623193740845,-0.9228774309158325,0.6191076636314392,-0.33572638034820557,-0.998464822769165,0.6448631286621094,0.8468661308288574,-0.7557657361030579,0.9527971148490906,0.7326545715332031,0.532416820526123,0.9732668995857239,0.7239248752593994,0.25538960099220276,0.815841555595398,0.6655788421630859,0.9287101030349731,-0.5660438537597656,-0.890874445438385,0.9834234118461609,-0.9981180429458618,0.9698693156242371,0.7439671158790588,-0.35639339685440063,0.6022988557815552,0.9708116054534912,-0.9278276562690735,-0.996231734752655,0.8345208168029785,0.9714328050613403,0.8158544898033142,0.5902576446533203,0.8199342489242554,0.9820225834846497,0.9859328269958496,0.5152459144592285,-0.5610516667366028,0.9663665890693665,0.9495159983634949,-0.5204814076423645,0.3104749917984009,0.9859084486961365,0.7797460556030273,0.6738530397415161,0.3919741213321686,-0.906204104423523,0.11750980466604233,0.8077875375747681,0.4169303774833679,0.9829014539718628,0.9902303218841553,0.7847102880477905,0.994563102722168,0.9868024587631226,-0.26804423332214355,-0.9908866882324219,0.745792806148529,0.9906191825866699,-0.18231149017810822,0.97578364610672,0.9986749887466431,0.2544330358505249,-0.954406201839447,0.5869243144989014,-0.23537996411323547,0.9550502896308899,0.25511977076530457,0.9929870963096619,0.09052591770887375,0.9707273244857788,0.6956093311309814,0.6280022263526917,0.7902867794036865,0.9343841075897217,0.989579439163208,0.9436283707618713,-0.10834993422031403,-0.3431112766265869,0.9986708760261536,0.5086739659309387,0.9949507713317871,0.8283133506774902,0.9432437419891357,0.9491766095161438,0.9995352029800415,0.5712319612503052,0.8055234551429749,0.6781864166259766,0.8272571563720703,0.8314797282218933,0.8778656721115112,0.9944958686828613,0.9973865151405334],\"xaxis\":\"x\",\"y\":[0.7775010466575623,0.3527269959449768,0.25961846113204956,0.6670257449150085,0.8384260535240173,0.5584430694580078,0.8444744944572449,0.4137910008430481,0.24488940834999084,0.028157662600278854,0.3584098219871521,0.16288265585899353,-0.45419126749038696,-0.6529328227043152,-0.5484569072723389,-0.7990369200706482,-0.7736425995826721,-0.8522581458091736,0.9774324893951416,0.6626249551773071,-0.7303224205970764,-0.7007019519805908,-0.6946625709533691,-0.9996722340583801,-0.7837163805961609,0.8967759013175964,0.4750954806804657,-0.667197585105896,0.7881461977958679,-0.8547751307487488,-0.9054184556007385,-0.5749384760856628,-0.32175111770629883,-0.028594352304935455,-0.9247617721557617,-0.9699268341064453,0.5864037275314331,-0.7614347338676453,0.5971695780754089,0.7854393720626831,-0.8788883686065674,0.3908745050430298,0.044738516211509705,0.11028008162975311,-0.8169988989830017,0.22129566967487335,-0.9939578771591187,0.5774399042129517,0.525479257106781,0.3049013912677765,-0.10729152709245682,0.9433151483535767,-0.9314428567886353,0.5273632407188416,-0.4264712631702423,-0.9984429478645325,0.5296756029129028,0.8604294061660767,-0.8895052075386047,0.9556970596313477,0.6629186868667603,0.42956963181495667,0.9736858010292053,0.6555483937263489,0.12201889604330063,0.7442770004272461,0.5037952661514282,0.9525359272956848,-0.6507164239883423,-0.9316279292106628,0.9791510105133057,-0.9972584843635559,0.9613031148910522,0.7501779794692993,-0.3806658685207367,0.6429786682128906,0.9557769298553467,-0.9428839683532715,-0.9948079586029053,0.785298764705658,0.9657301306724548,0.707301676273346,0.3687230050563812,0.8128011226654053,0.9659481644630432,0.9730121493339539,0.31900617480278015,-0.30290520191192627,0.9790953397750854,0.9357923269271851,-0.5550313591957092,-0.005466493312269449,0.9867776036262512,0.8249565958976746,0.566429615020752,0.1000526174902916,-0.9464486837387085,-0.25471997261047363,0.6522327661514282,0.1415255218744278,0.9884140491485596,0.9860583543777466,0.6949270367622375,0.9901810884475708,0.9791202545166016,-0.2359553426504135,-0.9820711612701416,0.6506689190864563,0.9895943999290466,-0.29178157448768616,0.9714024662971497,0.9951602220535278,0.18783769011497498,-0.9460937976837158,0.47801902890205383,-0.2489192932844162,0.9437097907066345,0.11866245418787003,0.9941242933273315,-0.38088178634643555,0.9564487934112549,0.5542725920677185,0.42118048667907715,0.6628789901733398,0.8659590482711792,0.9937117695808411,0.9069075584411621,0.39811065793037415,-0.4134220480918884,0.9971913695335388,0.34596705436706543,0.9938657283782959,0.5891268849372864,0.9313740134239197,0.9268401861190796,0.9993564486503601,0.6227539777755737,0.8463947772979736,0.6584346294403076,0.8423126339912415,0.2978496253490448,0.8728679418563843,0.9963144659996033,0.986752450466156],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Full OV Copying Score\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"OV Copying Score\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"OV Copying Score for each head in GPT-2 Small\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3e59929d-31e9-49b1-ad1a-9d9811d4801d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "scatter(x=full_OV_copying_score.flatten(), y=OV_copying_score.flatten(), hover_name=[f\"L{layer}H{head}\" for layer in range(12) for head in range(12)], title=\"OV Copying Score for each head in GPT-2 Small\", xaxis=\"Full OV Copying Score\", yaxis=\"OV Copying Score\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-G27ot6aXMCA",
        "outputId": "c238eefb-3bc3-47ef-e25d-4106cf3640a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token 256 - the most common pair of ASCII characters: | t|\n",
            "De-Tokenizing the example tokens: <|endoftext|>The first thing you need to figure out is *how* things are tokenized. `model.to_str_tokens` splits a string into the tokens *as a list of substrings*, and so lets you explore what the text looks like. To demonstrate this, let's use it on this paragraph.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Token 256 - the most common pair of ASCII characters: |{model.to_string(256)}|\")\n",
        "# Squeeze means to remove dimensions of length 1.\n",
        "# Here, that removes the dummy batch dimension so it's a rank 1 tensor and returns a string\n",
        "# Rank 2 tensors map to a list of strings\n",
        "print(f\"De-Tokenizing the example tokens: {model.to_string(example_text_tokens.squeeze())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuZYjQb4XMCB"
      },
      "source": [
        "## Generating Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly_1Pz7WXMCB"
      },
      "source": [
        "TransformerLens also has basic text generation functionality, which can be useful for generally exploring what the model is capable of (thanks to Ansh Radhakrishnan for adding this!). This is pretty rough functionality, and where possible I recommend using more established libraries like HuggingFace for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "f16e699caef243e3bd730cd876600c4a"
          ]
        },
        "id": "XcFW0o4mXMCB",
        "outputId": "4cfda428-0be2-4edc-906d-16149efe8dff"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f16e699caef243e3bd730cd876600c4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'(CNN) President Barack Obama caught in embarrassing new scandal\\n\\nAmerican voters who backed Hillary Clinton gave President Barack Obama a 9.5-point lead over Republican Mitt Romney in the latest CNN/ORC International poll, his lowest level since the last CNN-ORC poll in 2006.\\n\\nRepublican voters'"
            ]
          },
          "execution_count": 344,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# NBVAL_IGNORE_OUTPUT\n",
        "model.generate(\"(CNN) President Barack Obama caught in embarrassing new scandal\\n\", max_new_tokens=50, temperature=0.7, prepend_bos=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vbSNpA6XMCC"
      },
      "source": [
        "## Hook Points\n",
        "\n",
        "The key part of TransformerLens that lets us access and edit intermediate activations are the HookPoints around every model activation. Importantly, this technique will work for *any* model architecture, not just transformers, so long as you're able to edit the model code to add in HookPoints! This is essentially a lightweight library bundled with TransformerLens that should let you take an arbitrary model and make it easier to study."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJUWtH0IXMCD"
      },
      "source": [
        "This is implemented by having a HookPoint layer. Each transformer component has a HookPoint for every activation, which wraps around that activation. The HookPoint acts as an identity function, but has a variety of helper functions that allows us to put PyTorch hooks in to edit and access the relevant activation.\n",
        "\n",
        "There is also a `HookedRootModule` class - this is a utility class that the root module should inherit from (root module = the model we run) - it has several utility functions for using hooks well, notably `reset_hooks`, `run_with_cache` and `run_with_hooks`.\n",
        "\n",
        "The default interface is the `run_with_hooks` function on the root module, which lets us run a forwards pass on the model, and pass on a list of hooks paired with layer names to run on that pass.\n",
        "\n",
        "The syntax for a hook is `function(activation, hook)` where `activation` is the activation the hook is wrapped around, and `hook` is the `HookPoint` class the function is attached to. If the function returns a new activation or edits the activation in-place, that replaces the old one, if it returns None then the activation remains as is.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5SwpPCbXMCD"
      },
      "source": [
        "### Toy Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5sKwJb-XMCE"
      },
      "source": [
        "\n",
        "Here's a simple example of defining a small network with HookPoints:\n",
        "\n",
        "We define a basic network with two layers that each take a scalar input $x$, square it, and add a constant:\n",
        "$x_0=x$, $x_1=x_0^2+3$, $x_2=x_1^2-4$.\n",
        "\n",
        "We wrap the input, each layer's output, and the intermediate value of each layer (the square) in a hook point.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hj8evP-uXMCE"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformer_lens.hook_points import HookedRootModule, HookPoint\n",
        "\n",
        "\n",
        "class SquareThenAdd(nn.Module):\n",
        "    def __init__(self, offset):\n",
        "        super().__init__()\n",
        "        self.offset = nn.Parameter(torch.tensor(offset))\n",
        "        self.hook_square = HookPoint()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # The hook_square doesn't change the value, but lets us access it\n",
        "        square = self.hook_square(x * x)\n",
        "        return self.offset + square\n",
        "\n",
        "\n",
        "class TwoLayerModel(HookedRootModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = SquareThenAdd(3.0)\n",
        "        self.layer2 = SquareThenAdd(-4.0)\n",
        "        self.hook_in = HookPoint()\n",
        "        self.hook_mid = HookPoint()\n",
        "        self.hook_out = HookPoint()\n",
        "\n",
        "        # We need to call the setup function of HookedRootModule to build an\n",
        "        # internal dictionary of modules and hooks, and to give each hook a name\n",
        "        super().setup()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # We wrap the input and each layer's output in a hook - they leave the\n",
        "        # value unchanged (unless there's a hook added to explicitly change it),\n",
        "        # but allow us to access it.\n",
        "        x_in = self.hook_in(x)\n",
        "        x_mid = self.hook_mid(self.layer1(x_in))\n",
        "        x_out = self.hook_out(self.layer2(x_mid))\n",
        "        return x_out\n",
        "\n",
        "\n",
        "model = TwoLayerModel()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_ucR5c3XMCE"
      },
      "source": [
        "\n",
        "We can add a cache, to save the activation at each hook point\n",
        "\n",
        "(There's a custom `run_with_cache` function on the root module as a convenience, which is a wrapper around model.forward that return model_out, cache_object - we could also manually add hooks with `run_with_hooks` that store activations in a global caching dictionary. This is often useful if we only want to store, eg, subsets or functions of some activations.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4S9TJfvfXMCF",
        "outputId": "d2f86a03-6351-4cd5-a142-5b00c9a14c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model output: 780.0\n",
            "Value cached at hook hook_in 5.0\n",
            "Value cached at hook layer1.hook_square 25.0\n",
            "Value cached at hook hook_mid 28.0\n",
            "Value cached at hook layer2.hook_square 784.0\n",
            "Value cached at hook hook_out 780.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "out, cache = model.run_with_cache(torch.tensor(5.0))\n",
        "print(\"Model output:\", out.item())\n",
        "for key in cache:\n",
        "    print(f\"Value cached at hook {key}\", cache[key].item())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxEBGZjLXMCG"
      },
      "source": [
        "\n",
        "We can also use hooks to intervene on activations - eg, we can set the intermediate value in layer 2 to zero to change the output to -5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx4yHBy1XMCG",
        "outputId": "d1926a44-43df-4887-bbee-b935b475fe38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layer2.hook_square\n",
            "Output after intervening on layer2.hook_scaled -4.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def set_to_zero_hook(tensor, hook):\n",
        "    print(hook.name)\n",
        "    return torch.tensor(0.0)\n",
        "\n",
        "\n",
        "print(\n",
        "    \"Output after intervening on layer2.hook_scaled\",\n",
        "    model.run_with_hooks(\n",
        "        torch.tensor(5.0), fwd_hooks=[(\"layer2.hook_square\", set_to_zero_hook)]\n",
        "    ).item(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrM2Pz1DXMCG"
      },
      "source": [
        "## Loading Pre-Trained Checkpoints\n",
        "\n",
        "There are a lot of interesting questions combining mechanistic interpretability and training dynamics - analysing model capabilities and the underlying circuits that make them possible, and how these change as we train the model.\n",
        "\n",
        "TransformerLens supports these by having several model families with checkpoints throughout training. `HookedTransformer.from_pretrained` can load a checkpoint of a model with the `checkpoint_index` (the label 0 to `num_checkpoints-1`) or `checkpoint_value` (the step or token number, depending on how the checkpoints were labelled)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3zbqsJoXMCG"
      },
      "source": [
        "\n",
        "Available models:\n",
        "* All of my interpretability-friendly models have checkpoints available, including:\n",
        "    * The toy models - `attn-only`, `solu`, `gelu` 1L to 4L\n",
        "        * These have ~200 checkpoints, taken on a piecewise linear schedule (more checkpoints near the start of training), up to 22B tokens. Labelled by number of tokens seen.\n",
        "    * The SoLU models trained on 80% Web Text and 20% Python Code (`solu-6l` to `solu-12l`)\n",
        "        * Same checkpoint schedule as the toy models, this time up to 30B tokens\n",
        "    * The SoLU models trained on the pile (`solu-1l-pile` to `solu-12l-pile`)\n",
        "        * These have ~100 checkpoints, taken on a linear schedule, up to 15B tokens. Labelled by number of steps.\n",
        "        * The 12L training crashed around 11B tokens, so is truncated.\n",
        "* The Stanford Centre for Research of Foundation Models trained 5 GPT-2 Small sized and 5 GPT-2 Medium sized models (`stanford-gpt2-small-a` to `e` and `stanford-gpt2-medium-a` to `e`)\n",
        "    * 600 checkpoints, taken on a piecewise linear schedule, labelled by the number of steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SyonakAXMCH"
      },
      "source": [
        "The checkpoint structure and labels is somewhat messy and ad-hoc, so I mostly recommend using the `checkpoint_index` syntax (where you can just count from 0 to the number of checkpoints) rather than `checkpoint_value` syntax (where you need to know the checkpoint schedule, and whether it was labelled with the number of tokens or steps). The helper function `get_checkpoint_labels` tells you the checkpoint schedule for a given model - ie what point was each checkpoint taken at, and what type of label was used.\n",
        "\n",
        "Here are graphs of the schedules for several checkpointed models: (note that the first 3 use a log scale, latter 2 use a linear scale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGeg22dRXMCH",
        "outputId": "61f0c8fb-95a3-4d61-af03-679faf73117b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"9670aaf8-c497-4268-aefd-f91bf035117f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9670aaf8-c497-4268-aefd-f91bf035117f\")) {                    Plotly.newPlot(                        \"9670aaf8-c497-4268-aefd-f91bf035117f\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162],\"xaxis\":\"x\",\"y\":[262144,2621440,4718592,7077888,9175040,11272192,13631488,15728640,18087936,20185088,22282240,33292288,44302336,55312384,66322432,77332480,88342528,99352576,110362624,121372672,132382720,143392768,154402816,165412864,176422912,187432960,198443008,209453056,220463104,264503296,308281344,352321536,396361728,440401920,484442112,528482304,572522496,616300544,660340736,704380928,748421120,792461312,836501504,880279552,924319744,968359936,1012400128,1056440320,1100480512,1144520704,1188298752,1232338944,1276379136,1320419328,1364459520,1408499712,1452277760,1496317952,1540358144,1584398336,1628438528,1672478720,1716518912,1760296960,1804337152,1848377344,1892417536,1936457728,1980497920,2024275968,2068316160,2112356352,2156396544,2200436736,2420375552,2640314368,2860515328,3080454144,3300392960,3520331776,3740270592,3960471552,4180410368,4400349184,4620288000,4840488960,5060427776,5280366592,5500305408,5720506368,5940445184,6160384000,6380322816,6600523776,6820462592,7040401408,7260340224,7480279040,7700480000,7920418816,8140357632,8360296448,8580497408,8800436224,9020375040,9240313856,9460514816,9680453632,9900392448,10120331264,10340270080,10560471040,10780409856,11000348672,11220287488,11440488448,11660427264,11880366080,12100304896,12320505856,12540444672,12760383488,12980322304,13200523264,13420462080,13640400896,13860339712,14080278528,14300479488,14520418304,14740357120,14960295936,15180496896,15400435712,15620374528,15840313344,16060514304,16280453120,16500391936,16720330752,16940269568,17160470528,17380409344,17600348160,17820286976,18040487936,18260426752,18480365568,18700304384,18920505344,19140444160,19360382976,19580321792,19800522752,20020461568,20240400384,20460339200,20680278016,20900478976,21120417792,21340356608,21560295424,21780496384],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Checkpoint Values for attn-only-2l (Log scale)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9670aaf8-c497-4268-aefd-f91bf035117f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"87db2943-c842-478c-8c64-5289a60ba868\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"87db2943-c842-478c-8c64-5289a60ba868\")) {                    Plotly.newPlot(                        \"87db2943-c842-478c-8c64-5289a60ba868\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162],\"xaxis\":\"x\",\"y\":[196608,3342336,6291456,9240576,12386304,15335424,18284544,21233664,24379392,27328512,30277632,45219840,60358656,75300864,90243072,105381888,120324096,135266304,150208512,165347328,180289536,195231744,210370560,225312768,240254976,255197184,270336000,285278208,300220416,360382464,420347904,480313344,540278784,600244224,660209664,720371712,780337152,840302592,900268032,960233472,1020198912,1080360960,1140326400,1200291840,1260257280,1320222720,1380384768,1440350208,1500315648,1560281088,1620246528,1680211968,1740374016,1800339456,1860304896,1920270336,1980235776,2040201216,2100363264,2160328704,2220294144,2280259584,2340225024,2400387072,2460352512,2520317952,2580283392,2640248832,2700214272,2760376320,2820341760,2880307200,2940272640,3000238080,3300261888,3600285696,3900309504,4200333312,4500357120,4800380928,5100208128,5400231936,5700255744,6000279552,6300303360,6600327168,6900350976,7200374784,7500201984,7800225792,8100249600,8400273408,8700297216,9000321024,9300344832,9600368640,9900392448,10200219648,10500243456,10800267264,11100291072,11400314880,11700338688,12000362496,12300386304,12600213504,12900237312,13200261120,13500284928,13800308736,14100332544,14400356352,14700380160,15000207360,15300231168,15600254976,15900278784,16200302592,16500326400,16800350208,17100374016,17400201216,17700225024,18000248832,18300272640,18600296448,18900320256,19200344064,19500367872,19800391680,20100218880,20400242688,20700266496,21000290304,21300314112,21600337920,21900361728,22200385536,22500212736,22800236544,23100260352,23400284160,23700307968,24000331776,24300355584,24600379392,24900206592,25200230400,25500254208,25800278016,26100301824,26400325632,26700349440,27000373248,27300200448,27600224256,27900248064,28200271872,28500295680,28800319488,29100343296,29400367104,29700390912],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Checkpoint Values for solu-12l (Log scale)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('87db2943-c842-478c-8c64-5289a60ba868');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"a5b83399-2637-48e9-980b-098ce30dc2fd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a5b83399-2637-48e9-980b-098ce30dc2fd\")) {                    Plotly.newPlot(                        \"a5b83399-2637-48e9-980b-098ce30dc2fd\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608],\"xaxis\":\"x\",\"y\":[0,10,20,30,40,50,60,70,80,90,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000,1050,1100,1150,1200,1250,1300,1350,1400,1450,1500,1550,1600,1650,1700,1750,1800,1850,1900,1950,2000,2100,2200,2300,2400,2500,2600,2700,2800,2900,3000,3100,3200,3300,3400,3500,3600,3700,3800,3900,4000,4100,4200,4300,4400,4500,4600,4700,4800,4900,5000,5100,5200,5300,5400,5500,5600,5700,5800,5900,6000,6100,6200,6300,6400,6500,6600,6700,6800,6900,7000,7100,7200,7300,7400,7500,7600,7700,7800,7900,8000,8100,8200,8300,8400,8500,8600,8700,8800,8900,9000,9100,9200,9300,9400,9500,9600,9700,9800,9900,10000,10100,10200,10300,10400,10500,10600,10700,10800,10900,11000,11100,11200,11300,11400,11500,11600,11700,11800,11900,12000,12100,12200,12300,12400,12500,12600,12700,12800,12900,13000,13100,13200,13300,13400,13500,13600,13700,13800,13900,14000,14100,14200,14300,14400,14500,14600,14700,14800,14900,15000,15100,15200,15300,15400,15500,15600,15700,15800,15900,16000,16100,16200,16300,16400,16500,16600,16700,16800,16900,17000,17100,17200,17300,17400,17500,17600,17700,17800,17900,18000,18100,18200,18300,18400,18500,18600,18700,18800,18900,19000,19100,19200,19300,19400,19500,19600,19700,19800,19900,20000,21000,22000,23000,24000,25000,26000,27000,28000,29000,30000,31000,32000,33000,34000,35000,36000,37000,38000,39000,40000,41000,42000,43000,44000,45000,46000,47000,48000,49000,50000,51000,52000,53000,54000,55000,56000,57000,58000,59000,60000,61000,62000,63000,64000,65000,66000,67000,68000,69000,70000,71000,72000,73000,74000,75000,76000,77000,78000,79000,80000,81000,82000,83000,84000,85000,86000,87000,88000,89000,90000,91000,92000,93000,94000,95000,96000,97000,98000,99000,100000,101000,102000,103000,104000,105000,106000,107000,108000,109000,110000,111000,112000,113000,114000,115000,116000,117000,118000,119000,120000,121000,122000,123000,124000,125000,126000,127000,128000,129000,130000,131000,132000,133000,134000,135000,136000,137000,138000,139000,140000,141000,142000,143000,144000,145000,146000,147000,148000,149000,150000,151000,152000,153000,154000,155000,156000,157000,158000,159000,160000,161000,162000,163000,164000,165000,166000,167000,168000,169000,170000,171000,172000,173000,174000,175000,176000,177000,178000,179000,180000,181000,182000,183000,184000,185000,186000,187000,188000,189000,190000,191000,192000,193000,194000,195000,196000,197000,198000,199000,200000,201000,202000,203000,204000,205000,206000,207000,208000,209000,210000,211000,212000,213000,214000,215000,216000,217000,218000,219000,220000,221000,222000,223000,224000,225000,226000,227000,228000,229000,230000,231000,232000,233000,234000,235000,236000,237000,238000,239000,240000,241000,242000,243000,244000,245000,246000,247000,248000,249000,250000,251000,252000,253000,254000,255000,256000,257000,258000,259000,260000,261000,262000,263000,264000,265000,266000,267000,268000,269000,270000,271000,272000,273000,274000,275000,276000,277000,278000,279000,280000,281000,282000,283000,284000,285000,286000,287000,288000,289000,290000,291000,292000,293000,294000,295000,296000,297000,298000,299000,300000,301000,302000,303000,304000,305000,306000,307000,308000,309000,310000,311000,312000,313000,314000,315000,316000,317000,318000,319000,320000,321000,322000,323000,324000,325000,326000,327000,328000,329000,330000,331000,332000,333000,334000,335000,336000,337000,338000,339000,340000,341000,342000,343000,344000,345000,346000,347000,348000,349000,350000,351000,352000,353000,354000,355000,356000,357000,358000,359000,360000,361000,362000,363000,364000,365000,366000,367000,368000,369000,370000,371000,372000,373000,374000,375000,376000,377000,378000,379000,380000,381000,382000,383000,384000,385000,386000,387000,388000,389000,390000,391000,392000,393000,394000,395000,396000,397000,398000,399000,400000],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Checkpoint Values for stanford-gpt2-small-a (Log scale)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a5b83399-2637-48e9-980b-098ce30dc2fd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"4c28ffe1-8565-4e92-babd-d57cc8bc847d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4c28ffe1-8565-4e92-babd-d57cc8bc847d\")) {                    Plotly.newPlot(                        \"4c28ffe1-8565-4e92-babd-d57cc8bc847d\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"xaxis\":\"x\",\"y\":[832,1664,2496,3328,4160,4992,5824,6656,7488,8320,9152,9984,10816,11648,12480,13312,14144,14976,15808,16640,17472,18304,19136,19968,20800,21632,22464,23296,24128,24960,25792,26624,27456,28288,29120,29952,30784,31616,32448,33280,34112,34944,35776,36608,37440,38272,39104,39936,40768,41600],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Checkpoint Values for solu-1l-pile (Linear scale)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4c28ffe1-8565-4e92-babd-d57cc8bc847d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"d92c9f04-9700-4de1-9237-9cba28fcdafb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d92c9f04-9700-4de1-9237-9cba28fcdafb\")) {                    Plotly.newPlot(                        \"d92c9f04-9700-4de1-9237-9cba28fcdafb\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"xaxis\":\"x\",\"y\":[326,652,978,1304,1630,1956,2282,2608,2934,3260,3586,3912,4238,4564,4890,5216,5542,5868,6194,6520,6846,7172,7498,7824,8150,8476,8802,9128,9454,9780,10106,10432,10758,11084,11410,11736,12062,12388,12714,13040,13366,13692,14018,14344,14670,14996,15322,15648,15974,16300,16626,16952,17278,17604,17930,18256,18582,18908,19234,19560,19886,20212,20538,20864,21190,21516,21842,22168,22494,22820,23146,23472,23798,24124,24450,24776,25102,25428,25754,26080,26406,26732,27058,27384,27710,28036,28362,28688,29014,29340,29666,29992,30318,30644,30970,31296,31622,31948,32274,32600],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Checkpoint Values for solu-6l-pile (Linear scale)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d92c9f04-9700-4de1-9237-9cba28fcdafb');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformer_lens.loading_from_pretrained import get_checkpoint_labels\n",
        "for model_name in [\"attn-only-2l\", \"solu-12l\", \"stanford-gpt2-small-a\"]:\n",
        "    checkpoint_labels, checkpoint_label_type = get_checkpoint_labels(model_name)\n",
        "    line(checkpoint_labels, xaxis=\"Checkpoint Index\", yaxis=f\"Checkpoint Value ({checkpoint_label_type})\", title=f\"Checkpoint Values for {model_name} (Log scale)\", log_y=True, markers=True)\n",
        "for model_name in [\"solu-1l-pile\", \"solu-6l-pile\"]:\n",
        "    checkpoint_labels, checkpoint_label_type = get_checkpoint_labels(model_name)\n",
        "    line(checkpoint_labels, xaxis=\"Checkpoint Index\", yaxis=f\"Checkpoint Value ({checkpoint_label_type})\", title=f\"Checkpoint Values for {model_name} (Linear scale)\", log_y=False, markers=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RB_yHnTOXMCH"
      },
      "source": [
        "### Example: Induction Head Phase Transition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlBBPK0PXMCI"
      },
      "source": [
        "One of the more interesting results analysing circuit formation during training is the [induction head phase transition](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html). They find a pretty dramatic shift in models during training - there's a brief period where models go from not having induction heads to having them, which leads to the models suddenly becoming much better at in-context learning (using far back tokens to predict the next token, eg over 500 words back). This is enough of a big deal that it leads to a visible *bump* in the loss curve, where the model's rate of improvement briefly increases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VA4TsTYXMCI"
      },
      "source": [
        "As a brief demonstration of the existence of the phase transition, let's load some checkpoints of a two layer model, and see whether they have induction heads. An easy test, as we used above, is to give the model a repeated sequence of random tokens, and to check how good its loss is on the second half. `evals.induction_loss` is a rough util that runs this test on a model.\n",
        "(Note - this is deliberately a rough, non-rigorous test for the purposes of demonstration, eg `evals.induction_loss` by default just runs it on 4 sequences of 384 tokens repeated twice. These results totally don't do the paper justice - go check it out if you want to see the full results!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZICOvaKXMCJ"
      },
      "source": [
        "In the interests of time and memory, let's look at a handful of checkpoints (chosen to be around the phase change), indices `[10, 25, 35, 60, -1]`. These are roughly 22M, 200M, 500M, 1.6B and 21.8B tokens through training, respectively. (I generally recommend looking things up based on indices, rather than checkpoint value!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUTm9MRCXMCL"
      },
      "outputs": [],
      "source": [
        "from transformer_lens import evals\n",
        "# We use the two layer model with SoLU activations, chosen fairly arbitrarily as being both small (so fast to download and keep in memory) and pretty good at the induction task.\n",
        "model_name = \"solu-2l\"\n",
        "# We can load a model from a checkpoint by specifying the checkpoint_index, -1 means the final checkpoint\n",
        "checkpoint_indices = [10, 25, 35, 60, -1]\n",
        "checkpointed_models = []\n",
        "tokens_trained_on = []\n",
        "induction_losses = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E13zj8OXMCL"
      },
      "source": [
        "We load the models, cache them in a list, and"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYbv_JzoXMCL"
      },
      "outputs": [],
      "source": [
        "if not IN_GITHUB:\n",
        "    for index in checkpoint_indices:\n",
        "        # Load the model from the relevant checkpoint by index\n",
        "        model_for_this_checkpoint = HookedTransformer.from_pretrained(model_name, checkpoint_index=index, device=device)\n",
        "        checkpointed_models.append(model_for_this_checkpoint)\n",
        "\n",
        "        tokens_seen_for_this_checkpoint = model_for_this_checkpoint.cfg.checkpoint_value\n",
        "        tokens_trained_on.append(tokens_seen_for_this_checkpoint)\n",
        "\n",
        "        induction_loss_for_this_checkpoint = evals.induction_loss(model_for_this_checkpoint, device=device).item()\n",
        "        induction_losses.append(induction_loss_for_this_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPFdfc2zXMCM"
      },
      "source": [
        "We can plot this, and see there's a sharp shift from ~200-500M tokens trained on (note the log scale on the x axis). Interestingly, this is notably earlier than the phase transition in the paper, I'm not sure what's up with that.\n",
        "\n",
        "(To contextualise the numbers, the tokens in the random sequence are uniformly chosen from the first 20,000 tokens (out of ~48,000 total), so random performance is at least $\\ln(20000)\\approx 10$. A naive strategy like \"randomly choose a token that's already appeared in the first half of the sequence (384 elements)\" would get $\\ln(384)\\approx 5.95$, so the model is doing pretty well here.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hv7UchBXXMCM",
        "outputId": "eee0c1c6-c56f-429c-9066-6d68db0142d3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"1b82f6dc-4619-4786-ac45-c3cf11921de0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1b82f6dc-4619-4786-ac45-c3cf11921de0\")) {                    Plotly.newPlot(                        \"1b82f6dc-4619-4786-ac45-c3cf11921de0\",                        [],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"},\"type\":\"log\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Induction Loss over training: solu-2l\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1b82f6dc-4619-4786-ac45-c3cf11921de0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "line(induction_losses, x=tokens_trained_on, xaxis=\"Tokens Trained On\", yaxis=\"Induction Loss\", title=\"Induction Loss over training: solu-2l\", markers=True, log_x=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "eb812820b5094695c8a581672e17220e30dd2c15d704c018326e3cc2e1a566f1"
      }
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "43cd0b33ca9c466485f03bf50e9141f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80bd8efd5d3c40fe99ce06e8c23dbb0f",
              "IPY_MODEL_293ffe3f2f5f424d9411df7d1009fcaa",
              "IPY_MODEL_9ef6ee5be48c42bfa3cbfd3b796a70f7"
            ],
            "layout": "IPY_MODEL_7475273ff53b4de58b9caf1b5edd9081"
          }
        },
        "80bd8efd5d3c40fe99ce06e8c23dbb0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b52aa3f56dad4dd5829c494253247e7d",
            "placeholder": "​",
            "style": "IPY_MODEL_65957d50c9ac4792b694d34dc327cc0b",
            "value": "config.json: 100%"
          }
        },
        "293ffe3f2f5f424d9411df7d1009fcaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34b8971066fc45b0b27889c4ff8d75ea",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_571ada3caee24dfca05b13fa1eb120b2",
            "value": 665
          }
        },
        "9ef6ee5be48c42bfa3cbfd3b796a70f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aebc419e8364dfc904e4aae05c77bab",
            "placeholder": "​",
            "style": "IPY_MODEL_008bf292c9a3414797f19c44a20f48a9",
            "value": " 665/665 [00:00&lt;00:00, 27.8kB/s]"
          }
        },
        "7475273ff53b4de58b9caf1b5edd9081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b52aa3f56dad4dd5829c494253247e7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65957d50c9ac4792b694d34dc327cc0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34b8971066fc45b0b27889c4ff8d75ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "571ada3caee24dfca05b13fa1eb120b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6aebc419e8364dfc904e4aae05c77bab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "008bf292c9a3414797f19c44a20f48a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a0658f6d1704d858ba5092255361f46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27af9271f6fd4b9db308f3a103a91d3d",
              "IPY_MODEL_4ce58fddf2d84307868174bd4bc888ae",
              "IPY_MODEL_740382a84674498e9a7745260c4cbe5c"
            ],
            "layout": "IPY_MODEL_1139ba895d784871b74882e31ae3d3f9"
          }
        },
        "27af9271f6fd4b9db308f3a103a91d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fee90c5b1a44e3189f7dba265a3aba6",
            "placeholder": "​",
            "style": "IPY_MODEL_c6272b4a70de49e0b6510e7ba6691f0b",
            "value": "model.safetensors: 100%"
          }
        },
        "4ce58fddf2d84307868174bd4bc888ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dbafc3a471b4a54808cc8dbe440e266",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7cf41517920b4bd7810e09d1a246f637",
            "value": 548105171
          }
        },
        "740382a84674498e9a7745260c4cbe5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_221dc13faec442f999f257e1c727cb7d",
            "placeholder": "​",
            "style": "IPY_MODEL_760afdd9ecf4429c99e110e527f169b6",
            "value": " 548M/548M [00:05&lt;00:00, 129MB/s]"
          }
        },
        "1139ba895d784871b74882e31ae3d3f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fee90c5b1a44e3189f7dba265a3aba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6272b4a70de49e0b6510e7ba6691f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dbafc3a471b4a54808cc8dbe440e266": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cf41517920b4bd7810e09d1a246f637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "221dc13faec442f999f257e1c727cb7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "760afdd9ecf4429c99e110e527f169b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e595c76f97b42c197551272f919ddf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1658ea3a7f44c1da4a3b97504946793",
              "IPY_MODEL_07284d28626d490b9774cc744111245f",
              "IPY_MODEL_dcfac4378bd24d59a8f7a7e8186eae26"
            ],
            "layout": "IPY_MODEL_109ec2de5ca0425fac33c40f7de83e4b"
          }
        },
        "a1658ea3a7f44c1da4a3b97504946793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b30f37728cb46e4a6b8bfb8e034dd45",
            "placeholder": "​",
            "style": "IPY_MODEL_2cf8899304324911960210999a330fe7",
            "value": "generation_config.json: 100%"
          }
        },
        "07284d28626d490b9774cc744111245f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d955ae0965bd47f1b7027ca6d5fa0355",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6548edfe79d44f0e863e6b24ee08d285",
            "value": 124
          }
        },
        "dcfac4378bd24d59a8f7a7e8186eae26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff603d44b07348c18f89cc844ff91efa",
            "placeholder": "​",
            "style": "IPY_MODEL_1a15fc4962834aa5aeb6ee6fc79bc0f0",
            "value": " 124/124 [00:00&lt;00:00, 10.3kB/s]"
          }
        },
        "109ec2de5ca0425fac33c40f7de83e4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b30f37728cb46e4a6b8bfb8e034dd45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cf8899304324911960210999a330fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d955ae0965bd47f1b7027ca6d5fa0355": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6548edfe79d44f0e863e6b24ee08d285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff603d44b07348c18f89cc844ff91efa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a15fc4962834aa5aeb6ee6fc79bc0f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c067a4118242408786694746418375f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0913c57c32e64399b23461924961cf42",
              "IPY_MODEL_2cfc395895fb40ab963004900e5a71e8",
              "IPY_MODEL_21b1369bc4b34bb7bac6fe450fdec214"
            ],
            "layout": "IPY_MODEL_ea617c52c3544041bb539ff962369985"
          }
        },
        "0913c57c32e64399b23461924961cf42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c6c8c07e7a44677a1c420bc9a4972e2",
            "placeholder": "​",
            "style": "IPY_MODEL_a4e8a322b6cd4482a3557050a2f6c108",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2cfc395895fb40ab963004900e5a71e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b560e13f2c24d2e8d57afe1f12d2a04",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f397e9aae274f36a6e9352569db4005",
            "value": 26
          }
        },
        "21b1369bc4b34bb7bac6fe450fdec214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8656fc80d2f48fab3fdc1a4e47da333",
            "placeholder": "​",
            "style": "IPY_MODEL_862dec4fdb16463b9384fc9f6ddf475b",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.88kB/s]"
          }
        },
        "ea617c52c3544041bb539ff962369985": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c6c8c07e7a44677a1c420bc9a4972e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4e8a322b6cd4482a3557050a2f6c108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b560e13f2c24d2e8d57afe1f12d2a04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f397e9aae274f36a6e9352569db4005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8656fc80d2f48fab3fdc1a4e47da333": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "862dec4fdb16463b9384fc9f6ddf475b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eccb3e044a2541cea77d4d20ad072d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ba02eee14ac471abf8b459af297c4c3",
              "IPY_MODEL_37d752ab8b5042a48afd0eff4a147148",
              "IPY_MODEL_70fbcbe2639841b7b234f7047bd7a702"
            ],
            "layout": "IPY_MODEL_ee33dcf5dfb04c30992db0cee602c73b"
          }
        },
        "6ba02eee14ac471abf8b459af297c4c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3d8a83cee884c7a990fb0cc98149f62",
            "placeholder": "​",
            "style": "IPY_MODEL_e571d20332bf41988cd6aa4a0eaec4bb",
            "value": "vocab.json: 100%"
          }
        },
        "37d752ab8b5042a48afd0eff4a147148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d7bc80752364b1fb9bede6f0238cdd5",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_654ab34c049c4b69b2954065b42cf99e",
            "value": 1042301
          }
        },
        "70fbcbe2639841b7b234f7047bd7a702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c7473afbebd4a96a015e4b6664bb0c2",
            "placeholder": "​",
            "style": "IPY_MODEL_3fc5f8f1af8343b5a5bc768b06a814e7",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 10.0MB/s]"
          }
        },
        "ee33dcf5dfb04c30992db0cee602c73b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3d8a83cee884c7a990fb0cc98149f62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e571d20332bf41988cd6aa4a0eaec4bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d7bc80752364b1fb9bede6f0238cdd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "654ab34c049c4b69b2954065b42cf99e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c7473afbebd4a96a015e4b6664bb0c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fc5f8f1af8343b5a5bc768b06a814e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2fc0056de1b49dca7167669df172663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c3d3eb95aef4555b04ea4ab5566a9b1",
              "IPY_MODEL_b3bd2bb5e809469bbf45b0a117358266",
              "IPY_MODEL_06a49a3971cd40c885d09153ec784185"
            ],
            "layout": "IPY_MODEL_1aa3882c02074c8f8ea0a39b6d7ce6a4"
          }
        },
        "9c3d3eb95aef4555b04ea4ab5566a9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38d902ed4ad2452891ea992edddfa9c0",
            "placeholder": "​",
            "style": "IPY_MODEL_67440f1c148c4f75a584a3e65fbcc66a",
            "value": "merges.txt: 100%"
          }
        },
        "b3bd2bb5e809469bbf45b0a117358266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a7a8d2d9d1343bfb1c4cde1891dbdc8",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e2b4cb6183940ef8f2eae86b221d56a",
            "value": 456318
          }
        },
        "06a49a3971cd40c885d09153ec784185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a0c32fce0a44a50bc5b9ca5810e04fe",
            "placeholder": "​",
            "style": "IPY_MODEL_5b940d21b0f940a49066dd2fe973c215",
            "value": " 456k/456k [00:00&lt;00:00, 8.20MB/s]"
          }
        },
        "1aa3882c02074c8f8ea0a39b6d7ce6a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38d902ed4ad2452891ea992edddfa9c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67440f1c148c4f75a584a3e65fbcc66a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a7a8d2d9d1343bfb1c4cde1891dbdc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e2b4cb6183940ef8f2eae86b221d56a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a0c32fce0a44a50bc5b9ca5810e04fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b940d21b0f940a49066dd2fe973c215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25fe3524a5b040cea7e8d8d3f9597084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a77d29ab4d9e4abeb25751cf0f0ec228",
              "IPY_MODEL_abc2adb5616e4f449f29e10bcc036e8b",
              "IPY_MODEL_788b88ff567d4c4aa6615f0ef45ae2d9"
            ],
            "layout": "IPY_MODEL_7aeec7a31adc44c79dd6e0b6c11f93d0"
          }
        },
        "a77d29ab4d9e4abeb25751cf0f0ec228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e4a1e68e12f4e05ae61bda4d997b9b1",
            "placeholder": "​",
            "style": "IPY_MODEL_9da9b719afb54bc98cdf2ccbb93e39e3",
            "value": "tokenizer.json: 100%"
          }
        },
        "abc2adb5616e4f449f29e10bcc036e8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aec3bc18d284ca28f09186ffa0a0dce",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27f1df92a8a046849539cb34e3182db1",
            "value": 1355256
          }
        },
        "788b88ff567d4c4aa6615f0ef45ae2d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_517f1bb51eab4bf5b83b9bf1e7270b2b",
            "placeholder": "​",
            "style": "IPY_MODEL_9ec056376427430eb53f6865b29c5270",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 12.8MB/s]"
          }
        },
        "7aeec7a31adc44c79dd6e0b6c11f93d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e4a1e68e12f4e05ae61bda4d997b9b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9da9b719afb54bc98cdf2ccbb93e39e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7aec3bc18d284ca28f09186ffa0a0dce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27f1df92a8a046849539cb34e3182db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "517f1bb51eab4bf5b83b9bf1e7270b2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ec056376427430eb53f6865b29c5270": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4da3304b76944c7b77a5a0283c26b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf6836f1e74c486bb54d1953fb2de847",
              "IPY_MODEL_7f11c7ec377c407f82d32f43852fcd41",
              "IPY_MODEL_c0eeb1e756f84219983f1d90727628ad"
            ],
            "layout": "IPY_MODEL_5ff330f7c5a943f2a9bf4b752a6e4f4f"
          }
        },
        "bf6836f1e74c486bb54d1953fb2de847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75e0a891703449d5a42b22631739add3",
            "placeholder": "​",
            "style": "IPY_MODEL_f11869041c2a4a48ac3fa97e98a623b3",
            "value": "100%"
          }
        },
        "7f11c7ec377c407f82d32f43852fcd41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_169adb50059e460bbc3d254669cc6294",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_692bc0f171c147e9a17158b5195979c5",
            "value": 12
          }
        },
        "c0eeb1e756f84219983f1d90727628ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5eaa6013e1e245a19bc07159037a09bb",
            "placeholder": "​",
            "style": "IPY_MODEL_12bcf7a24ea94eb6810c6e2205e9d176",
            "value": " 12/12 [00:53&lt;00:00,  4.54s/it]"
          }
        },
        "5ff330f7c5a943f2a9bf4b752a6e4f4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75e0a891703449d5a42b22631739add3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f11869041c2a4a48ac3fa97e98a623b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "169adb50059e460bbc3d254669cc6294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "692bc0f171c147e9a17158b5195979c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5eaa6013e1e245a19bc07159037a09bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12bcf7a24ea94eb6810c6e2205e9d176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}